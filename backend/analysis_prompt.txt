{'https://www.qbitai.com/2025/04/278868.html': {'title': 'Qwen3真香！通义App满血接入，一手实测在此', 'url': 'https://www.qbitai.com/2025/04/278868.html', 'date': '2025-04-30', 'content': 'Qwen3真香！通义App满血接入，一手实测在此\n网友：RIP Llama\n开源大模型新王者，正在受到空前关注。\nQwen3预告一出，直接开启不眠夜模式。\n△来自编辑部本部\n等到深夜正式上线并宣布登顶全球最强开源模型，更是瞬间引爆全网热议。\n网友们的反应在meme中尽数体现（doge）。\n毕竟，单看纸面参数，Qwen3就是个妥妥的大工程：\n- 8款混合推理模型全部开源，参数量从0.6B到235B全面覆盖；\n- 32B模型就有超越OpenAI o1、DeepSeek R1的性能表现，在编程基准测评中还超过了风头正盛的Gemini 2.5 Pro；\n- 支持思考和非思考模式，支持119种语言和方言、加强对MCP支持……\n还有网友认为，这是“又一个DeepSeek时刻”。\n这一次模型开源，通义App和网页版也赶在第一时间满血上线Qwen3，并且有专属智能体体验。\n新王究竟表现如何，我们第一时间深度实测，以见真章。\nQwen3住进App，还能这样玩儿\n打开通义App/通义网页版首页，目前有两种方式可以体验到Qwen3模型：\n- 直接用输入框对话（代码/数学/翻译类问题默认调用Qwen3-235B，其它问题不调用Qwen3）\n- 选用“千问大模型”智能体（默认使用旗舰版Qwen3-235B-A22B）\nBTW，通义网页版近期上线了新域名tongyi.com，不要走错。\nOK，接下来进入正题。\n官方强调了新模型在Agent、编码方面的能力提升，还增强了对MCP的支持。具体表现如何，我们直接在通义App里全方位实测。\n第一关：代码生成\n先来个新模型“入门挑战”——空间内弹小球。\n这个经典测试在考验模型代码能力的同时，还重点关注了它对物理世界的理解，几乎每一个新模型都会被拉出来遛一遛。\n提示词如下（p5.js脚本、25个粒子、圆柱形容器）：\n而第一次接受挑战的旗舰版Qwen3模型，用时1分钟，唰唰唰就生成了一百多行代码：\n将上述代码实际运行一下，结果be like：\n虽然一眼看去没有“小球直接冲出圆圈”这样明显的错误，但也确实缺少3D空间感。\n作为对比，我们拉出官方测评图中，和满血Qwen3代码实力最相近的Grok 3模型。\n重复相同操作，让Grok 3基于同一提示词生成代码，并实际运行：\n二者的区别相当明显，后者（Grok 3）的空间感肉眼可见更强。\n为了进一步探究两段代码的差别，我们又直接让Qwen3“自己找找差距”（doge）。\n结果，它真的很认真地进行了全方位对比，包括渲染模式、容器结构、粒子运动与碰撞测试等等。\n最终结论也用表格进行了呈现，一目了然：\n甚至，基于它提出的改进意见，我们继续让它出了一个新版本。\n实际运行后，这次的结果已经非常符合我们的要求了。\n事实上，深扒Qwen3的思考过程，我们才发现原来第一版的2D效果是它“深思熟虑”后的选择。\n这里主要考虑到了兼容性问题，所以简化成了俯视图来呈现。\n从上面这个简单测试，我们已经能够窥见Qwen3的程序员素养确实不错。\n接下来难度升级，直接让它帮打工人设计一个提醒喝水的电脑端App。\n注意，为了能快速在浏览器端预览生成效果，这里我们采用了“极简模式”，仅保留最基础的功能，不涉及使用任何第三方库。\n结果生成的App有模有样，还能真实点击交互。\n一旦让具备工程能力的童鞋们上手，估计能实现更多复杂效果。\n第二关：逻辑推理\n接下来我们考查一下Qwen3的逻辑推理能力。\n老规矩，先上一道经典逻辑陷阱题：\n农夫要把一头狼、一只羊和一盆菜带过一条河。河边只有一艘小船，农夫每次只能带一样东西过河。如果农夫不在场时，狼会吃羊，羊会吃菜。如何安排农夫的安全过河方案？\n在故意关闭联网模式后，Qwen3经过一步步推理最终给出了正确答案。\n农夫应按照以下顺序操作：\n带羊过河，返回。\n带狼过河，带回羊。\n带白菜过河，返回。\n带羊过河。\n此方案通过7次移动（4次过河，3次返回），确保所有物品安全抵达对岸。\n而且从Qwen3的思考过程能够看到，其思维方式和人类一样，是通过不断推翻各种方案来找出可行路径。\n再来一道超高难度专业数学题。\n原题来自今年的普特南数学竞赛，该竞赛号称最难本科数学考试，人类要考6小时，并且所选取的题目据称前500名选手均未能完整作答。\n而扔给Qwen3后，可以看到整体的思考时间确实明显变长，最终用时5分38秒给出了正确答案。\np.s. 千问智能体无法直接上传图片，最终选择从App首页上传图片，提取文字后继续使用千问智能体作答。\n更有趣的是，扒一扒其思考过程，还能看到模型在线表演“崩溃”：\n当然，虽然AI的解读速度和正确率明显胜于人类，但还是要和同类来比。\n在国外网友的测试中，同一道题Grok 3（Think）在约8分钟内找到了解决方案。\n所以对比下来，这一局算Qwen3略胜一筹。\n第三关：多语言能力\n另外据介绍，Qwen3的一大亮点是支持119种语言和方言，被网友戏称“AI届多邻国”（doge）。\n别的不说，直接让它来挑战一把国内专业译者的地位试试。\n将莎士比亚《哈姆雷特》的经典选段丢给它，让它按照“信达雅”翻译成中文。\n它还知道参考优秀译本，并且注意避免直接抄袭造成侵权。\n最终生成的结果如下（左侧），对比我们熟知的朱生豪经典译本（右侧），你觉得AI味儿浓度如何？\n第四关：赛博闺蜜、shopping比价、写歌一网打尽\n除了以上更侧重模型基础能力的考查，当Qwen3被塞进App后，我们还解锁了更多玩法。\n做旅游规划这种就不必多说了，关键还能充当“赛博闺蜜”，帮忙选择更适合发朋友圈的游客照。\n日常也能用来购物比价，比如分析出当下最值得入手的3000元预算内平板。\n不仅用表格清晰列出了各品牌的核心参数，还按照不同需求进行了推荐，一整个造福伸手党。\n此外，最近火上热搜的“AI写歌”，我们也用Qwen3尝试了一把。\n五一版·大张伟嗨歌这就新鲜出炉，光看歌词确实有内味儿了：\nOkk，以上为我们的全部实测。\n小结一下，通过在通义App使用Qwen3专属智能体，我们能明显感受到以下几点：\n- Qwen3旗舰模型的生成速度非常快，体验很丝滑；\n- 模型擅长推理，能够解决经典逻辑陷阱和复杂数学题；\n- 代码能力方面，已经能够快速实现一些简单需求；\n- 由于载体是App，可拓展的玩法很多。\n而且，通义App自上个月页面改版后，整体设计更简洁，交互也更加完善了。\n更多网友实测\n与此同时，随着Qwen3模型的爆火，更多网友也第一时间进行了试玩。\n有和“空间内弹小球”类似效果的页面设计：\n还有用阿拉伯语、法语和印地语解释爱因斯坦相对论的玩法，该博主声称：\n简单到连十岁的小孩都能理解。\n当然，大家一直尤为钟爱的小游戏开发也安排上了：\n开源界的新王者\nQwen3引发热议背后，可以看到的是，在开源影响力上，以Qwen为代表的国产大模型，已经有超越Llama之势。\n这一点，从reddit LocalLLaMA等开发者聚集的板块的最新话题中，亦可见一斑。\n不仅是基准评测数据的纸面超越，实测越多，模型实力究竟几何就越能被客观公允地认知。\n而如今的开源格局之变，并非一蹴而就。前有DeepSeek，今有Qwen3，背后体现的是来自中国的开源力量一以贯之的努力，和一如既往的“中国速度”。\n以Qwen为例：\n2024年11月底，开源推理模型QwQ；\n2025年春节档，连发Qwen2.5百万上下文版本、视觉理解模型Qwen2.5-VL，还有超大规模MoE模型Qwen-2.5 Max；\n2025年3月，QwQ-32B以1/10成本比肩DeepSeek-R1；\n多模态方面，还有万相Wan的持续开源和迭代……\n这还只是短短5个月内的进展。\n再加上更加开放和商用友好的Apache 2.0协议，开发者们的转向，自然在情理之中。\n作为普通用户，一方面，可以在通义App这样的官方应用上更快感知到满血模型的能力。\n另一方面，也可以期待开源，带来更多衍生应用的可能性。\n那么，再次打开传送门：\ntongyi.com\n如果你探索到了什么新鲜玩法，也欢迎在评论区跟大家分享~\n- 用多模态LLM超越YOLOv3！强化学习突破多模态感知极限｜开源2025-05-03\n- OpenAI最新技术报告：GPT-4o变谄媚的原因万万没想到2025-05-03\n- 数学家们仍在追赶天才拉马努金2025-04-27\n- 不到2年，AI PPT赛道第一！像素绽放CEO赵充：今年是AI应用创业最佳时期 | 中国AIGC产业峰会2025-04-27'}, 'https://www.qbitai.com/2025/05/279839.html': {'title': '量子位', 'url': 'https://www.qbitai.com/2025/05/279839.html', 'date': '2025-05-03', 'content': '大模型终于通关《宝可梦蓝》！网友：Gemini 2.5 Pro酷爆了\n首个大模型宝可梦联盟冠军\n鱼羊 发自 凹非寺\n量子位 | 公众号 QbitAI\n就在刚刚，Gemini 2.5 Pro在直播中通关了《宝可梦蓝》！\n谷歌CEO劈柴哥第一时间兴奋官宣，放出通关时刻珍贵影像：\n大模型这一小步，把网友们也整嗨了。\n满屏画风皆是：泰！酷！辣！\n这回，Gemini的自我介绍里可以多一条了：首个成为宝可梦联盟冠军、登入《宝可梦蓝》名人堂的大模型。（doge）\n要知道，一年前的旧模Claude 3.5还只能勉强走出新手村到达常磐森林，2个月前，Claude 3.7倒是终于能击败道馆主了，但也并未通关宝可梦。\nGemini 2.5 Pro通关宝可梦\n游戏已通关，但直播仍继续。\n画面是酱婶的：\n有一说一，过程看上去是有那么点无聊，因为每动一步Gemini都要深思熟虑……\n左边的文本框里显示了Gemini每个行动背后的详细思考过程。\n在上面这个片段中，Gemini的主要目标是探索华蓝洞穴，寻找和捕获超梦。\n直播中可以看到，在完成了一长串行动，走到了目标位置之后，Gemini 2.5 Pro足足思考了40多秒，消耗76011个token，才开启下一步的行动规划。\n（因为有点迷路，Gemini后面还想了很久很久……）\n不过从这些思考过程中，可以清晰地看到大模型是怎么理解宝可梦游戏的。\n总结起来，Gemini玩宝可梦的基本步骤如下：\n- 截取屏幕截图并检索游戏状态数据\n- 用网格覆盖处理图像，以辅助空间推理\n- 将屏幕截图和游戏信息发送给模型\n- AI决定是直接响应还是调用专门的智能体\n- 解析响应内容，以确定按下哪个按钮\n- 执行按钮按下操作，并等待游戏更新\n- 对下一帧重复该过程\n如果你对Gemini的宝可梦直播感兴趣，可以在twitch上搜索“gemini plays pokemon”，传送门我们也会在文末奉上~\n宝可梦难在哪儿？\n尽管已经是联盟冠军，但可以看出的是，在宝可梦这样一款最初主要面向儿童和青少年推出的游戏中，大模型的表现明显不如人类（经常一整个大迷路什么的……）。\n参照Claude Plays Pokémon项目研究人员的说法，这主要是因为大模型“视力不佳”。\n以Claude为例，模型很难像人类一样去解读Game Boy屏幕里展现出的低分辨率、像素化的世界。\n同时，游戏中的二维地图看上去对未经专门训练的大模型而言也充满挑战性。\n我们很容易理解（游戏中）的建筑物就是建筑物，是无法穿过的。\n这对Claude来说却相当有挑战性。\n△图源：Anthropic\n另外，模型上下文的限制也影响了它们在游戏中的表现。\n不过，在游戏中偏文本的部分，此前Claude就已经有惊艳表现。\n比如，在宝可梦对战中，当游戏提示电属性宝可梦的攻击对岩石属性对手“效果不佳”时，Claude能马上get到其中的意思，并在此后将这些知识整合到自己的战斗策略里。\n现在，谷歌率先实现了新的突破，并表示还将在这个有趣的挑战中进行更多探索（直播将至少持续数天）。\n或许真的像网友所说：\n以后测试大模型的基准要变成谁能更快通关宝可梦了。\n直播地址：\nhttps://www.twitch.tv/gemini_plays_pokemon\n参考链接：\n[1]https://x.com/sundarpichai/status/1918455766542930004\n[2]https://arstechnica.com/ai/2025/03/why-anthropics-claude-still-hasnt-beaten-pokemon/\n— 完 —\n- 10秒生成官网，WeaveFox重塑前端研发生产力 | 蚂蚁徐达峰@中国AIGC产业峰会2025-04-30\n- 粉笔CTO：大模型打破教育「不可能三角」，因材施教真正成为可能｜中国AIGC产业峰会2025-04-18\n- GPT-4.1淘汰了4.5！全系列百万上下文，主打一个性价比2025-04-15\n- SOTA自动绑骨开源框架来了！3D版DeepSeek开源月大礼包持续开箱ing2025-04-11'}, 'https://www.qbitai.com/2025/05/279412.html': {'title': '微软CEO和奥特曼失了和，OpenAI被"断粮"', 'url': 'https://www.qbitai.com/2025/05/279412.html', 'date': '2025-05-02', 'content': '微软CEO和奥特曼失了和，OpenAI被“断粮”\n衡宇 发自 凹非寺\n量子位 | 公众号 QbitAI\n就很突然。\n许久没有同框的奥特曼和微软CEO纳德拉，刚刚在推特上“大秀恩爱”，还透露正在讨论合作新进展。\n这没由来的操作，难道是有新发布？\n但仔细一扒，或许更可能是回应新八卦。\n就在这两天，《华尔街日报》放出猛料：\n奥特曼和纳德拉，这对昔日让两家公司合作共赢的big name，在诸多事情上分歧日渐加大，渐行渐远。\n奥特曼是谁？OpenAI的掌舵者；纳德拉是谁？微软的现任话事人。\n在大多数人模糊的概念里，OpenAI是掀起这一波大模型浪潮的弄潮儿，而微软是其背后的支持者。\n在ChatGPT出现之前，微软就为当时还略显透明的OpenAI注入巨额资金，支持其在AI领域的研究。后来又不断加码，给钱，给云服务器……\n但本月月初，微软暂停了美国俄亥俄州中部10亿美元投资计划的三个数据中心园区建设。不只是这一个，微软正在“放缓或暂停”部分AI数据中心项目，这么看来，OpenAI的算力助力或将因此惨遭骤减。\n如今《华尔街日报》一记重锤，直接「揭发」：两人之间还是逐渐生出嫌隙。\n——更准确地说，是OpenAI和微软的关系日益变得微妙，甚至紧张起来。\n奥特曼和纳德拉，离心离德\n要知道，在OpenAI最抓马的八卦，也就是奥特曼被董事会逐出公司，又迅速“熹妃回宫”的故事里，纳德拉妥妥站在奥特曼这一边。\n且奥特曼也对外放话，OpenAI与微软拥有堪称“科技界最好的合作关系”。\n然而抓马事变到今天，不过一年半的光景，奥特曼和纳德拉的关系，它变了。\n表面上看，两人代表着的两家公司还一直保持着紧密合作，但细心的吃瓜群众发现，经常有双方起争执的实锤或者八卦流传开来。\n总之动不动就有双方闹别扭的传闻出现，呈现出一种“争吵不休”的局面。\n而据知情人士透露，现在，大约有三件事情让两家big name之间的裂缝越来越大。\n1）计算需求和访问权限。\n2）何时通往AGI的问题。\n3）内部竞争添变数。\n计算需求和访问权限\n据接近OpenAI和微软的知情人士透露，奥特曼和纳德拉之间，在微软为OpenAI提供的计算能力、初创公司向科技巨头开放其模型的权限等问题上，分歧日益加剧。\n比如OpenAI曾向微软寻求更多的资金支持，但微软在奥特曼被短暂罢免后重新考虑了这一投资。\n比如计算资源支持方面，OpenAI希望从微软获得更多的计算资源和顶级芯片的使用权，但微软表示已经提供了所能提供的一切，并放宽了排他性条款限制。\n又比如模型使用权限方面，双方在OpenAI给予微软使用其模型的权限上存在分歧，微软希望减少对OpenAI的依赖，并秘密启动了为微软开发AI模型的项目。\n再比如微软部分研究人员抱怨OpenAI不愿开放技术细节，限制了他们对模型的理解和改进。\n诸如此类，不胜枚举。\n双方看似是在AI 2.0浪潮中并肩作战的战友，但其实心里都有自己的小九九。\n虽然都是从自身利益出发，无谓对错，但时间久了，员工之间、公司之间，难免有怨言。\n何时通往AGI的问题\n《华尔街日报》同时指出，微软对OpenAI能否抵达AGI这个事情越来越犹豫。\n我们从OpenAI近一年来的一举一动，来感受一下为什么微软会发生态度转变——\n一个是Ilya离开后，外界就对OpenAI没有技术型灵魂人物该怎么办长期持怀疑态度。而且几乎每个月都有新的技术型人才宣布主动离职，或投奔他人，或自己创业，或回归学术——这都成了“不是新闻的新闻”了。\n也因如此，OpenAI的技术领先地位开始受到质疑。\n另一个是从去年年底OpenAI十二日连续直播，结果并没有公布如前作一样惊艳的模型作品（唯一一个o3事后还被爆出作弊刷分），就已经让人怀疑它是不是江郎才尽。\n而年初DeepSeek一声巨响，明显炸得OpenAI有点手忙脚乱。\n4o模型虽然在图片生成方面带领了一波“吉卜力风格”狂欢，但这并不是追逐AGI的朋友们想看到的技术进展速度和产品落地效果。\n但奥特曼的表现还是信心满满——他公开表示，相信OpenAI团队很快就能构建出这种功能。\n然而微软这边可不这么想。\n在微软这方看来，目前的技术远远没有站在叩响AGI之门的位置上。\n去年年底，纳德拉在年终访谈就吐露心声：\n从古希腊到现代硅谷，只有一件事会导致文明和公司的衰落，那就是傲慢。\n纳德拉还在2月的一个热门博客中驳斥了这种想法，他说：“我们自称取得了一些（AGI的）里程碑，但在我看来，这只是无意义的基准黑客攻击。”\n对此，本来就没有把鸡蛋放在同一个篮子里的微软，更不可能没有新的应对措施。\n纳德拉的做法很明显，不管是技术推进还是对外销售方面，他都提高了微软内部Copilot的优先级。\n内部竞争添变数\n更明显的一点是，纳德拉将目光投向了谷歌DeepMind的三位联合创始人之一Mustafa Suleyma（穆斯塔法·苏莱曼），把他揽入麾下。\n具体来说，在OpenAI不知情的情况下，微软掏了6.5亿美元巨款，买来了Suleyma及其初创公司Inflection的同事。\n知情人士透露，Suleyma加入后，开始着手构建一个大型语言模型，旨在与当时OpenAI公开发布的最先进的技术GPT-4相抗衡。\n虽然，这个项目起初并不太顺利（手动狗头）：\n一次早期的训练结果显示，训练出一个与OpenAI相当的模型比预期的要困难得多，这使得微软不得不延长对OpenAI的依赖。\n但不妨碍Suleyma有鲜明的个人行事风格，例如在一次关于共享知识产权的会议上，他当着OpenAI高官（当时的CTO Mira），对OpenAI的律师一顿疯狂输出。\nSuleyma虽然没站出来公开说过什么，但大家细品，不难发现微软在各个方面都着手尝试减少其对OpenAI的依赖。\n昔日共同追逐AGI的亲密伙伴\n目前，纳德拉和奥特曼的日常联系，主要通过每周固定的电话会议来进行。\n但以前不是这样的！《华尔街日报》透露：\n在双方关系最为亲密的时期，纳德拉一天给阿尔特曼发五、六条短信，而奥特曼也会同样回复。\n这样的情况在两人认识的六年内的大多数时候，并不罕见。\n没错，微软和OpenAI牵手的契机，除了微软作为科技巨头对AI领域的重金押注，看好当时还是毛头小子的OpenAI，或许还和纳德拉和奥特曼的揭示密不可分。\n2018年夏天，爱达荷州一场年度会议上，两人在楼梯间偶遇，仓促地交谈了五分钟，并从那天开始保持联系。\n在那次邂逅一年后，微软向OpenAI投资了10亿美元。\n这笔投资为微软提供了对OpenAI技术的独家访问权，而微软则成为OpenAI的独家云服务提供商。\n或许没有人想到，时至今日，微软前前后后向OpenAI提供了数十亿美金支持。\n也没有人想到，当时Ilya丢下PDF炸弹，导致奥特曼被OpenAI毕业后，纳德拉非常迅速站出来力挺他。\n简单回顾一下！\n在奥特曼被解雇事变前一个月，被视为灵魂人物的Ilya整理好了两份PDF，一份关于奥特曼，一份关于Brockman，发给了董事会其他独立董事，从而引起了后面的OpenAI海啸。\n（果然，无论中外，吃瓜时刻还得是PDF上场，doge）\n当时外界吃瓜群众还不知道发生了什么，只知道奥特曼一夜被解雇。\n但纳德拉很快在上发了推文，公开站队：\n我们希望继续与OpenAI保持合作，并希望看到奥特曼和Brockman能够继续在OpenAI的领导岗位上发挥作用。\n言下之意非常明显，就是微软还很重视和信任奥特曼领导的OpenAI呗～\n还有什么「隐藏款」指向关系恶化？\n但今天，纳德拉和微软可能成为奥特曼推动OpenAI转向非营利组织的绊脚石。\n怎么说呢，大家都知道去年12月底的时候，OpenAI突然在官网发布声明，宣布其将从“非营利主导营利公司”的结构中脱离出来，并新建一家可盈利的、注册于特拉华州的公益公司。\n不过如果到今年年底仍未实现重组，OpenAI可能会损失数百亿美元。\n然而，微软可以阻止OpenAI重组为独立盈利公司的努力，虽然种种迹象表明微软目前还没打算这么做。\n但微软不是没有行动来表达自己的态度～\n今年1月，当奥特曼和软银孙正义等打开星际之门（Stargate），计划投资5000亿美元用于建设AI基础设施，纳德拉没有出现，微软一言不发。\n转观另一边，OpenAI的司马昭之心也很明显。\n或许有人不知道，OpenAI的董事会可以触发双方合作合同中的一项条款，阻止微软获取其最先进的技术。\n据透露，过去一年中，OpenAI的高层已经提出了这样做的可能性。\n而且这段摇摇欲坠的“硅谷婚姻”中还不断有其他人搅局，比如AI进展一直令人不甚满意的苹果。\n去年夏天，苹果曾计划在OpenAI董事会中担任观察员以加强双方在人工智能领域的合作。\n由于监管压力，这一计划最终未能实现。\n尽管如此，苹果与OpenAI的合作关系仍在继续，双方通过其他方式保持紧密联系，比如OpenAI仍定期与微软、苹果等合作伙伴举行会议啥的。\nOne More Thing\n就在本月，有新闻爆出，微软正在“放缓或暂停”部分AI数据中心项目。\n不过，微软云计算业务总裁诺Noelle Walsh表示，虽然微软可能会战略性地调整计划，但会根据业务优先级和客户需求分配投资。\n在经济环境不确定、AI需求弱于预期、低成本大模型成为趋势的情况下，这家科技巨头不得不重新评估其基础设施需求。\n有分析师表示，这些变化和微软的商业合作伙伴OpenAI有关：\nOpenAI优先开发更先进的人工智能系统，这需要大量计算资源来训练数据，而“微软可能没有朝着同一个方向发展”。\n参考链接：\n[1]https://www.wsj.com/tech/ai/sam-altman-satya-nadella-rift-307cb7f5\n[2]https://spyglass.org/microsoft-openai-ai-jealousy/\n- 大模型竞技场再被锤！Llama4私下测试27个版本，只取最佳成绩2025-05-02\n- 多邻国全面AI First！AI能胜任的工作，都不会再新招人2025-04-30\n- 中关村科金喻友平： 平台+应用＋服务是企业大模型落地的最佳路径2025-04-28\n- 阿里Qwen3问鼎开源王座！8款模型全面开放，最大杯全方位超越R12025-04-29'}, 'https://www.qbitai.com/2025/05/279263.html': {'title': '上海车展见证历史：从「西为中用」到「中为西用」，行业风向标携手Momenta', 'url': 'https://www.qbitai.com/2025/05/279263.html', 'date': '2025-05-01', 'content': '上海车展见证历史：从「西为中用」到「中为西用」，行业风向标携手Momenta\n中国汽车「技术逆差」时代的终结\n一凡 发自 上海车展\n量子位 | 公众号 QbitAI\n历史性的时刻，发生时往往显得随机漫不经心，但连点成线之下，却又戏剧得好像经过精心安排。\n上汽大众，1984年诞生的中国首家轿车合资车企，代表着中国汽车面向西方先进汽车工业“技术输血”的开端。41年后，2025年的上海车展现场，AI智能化成为汽车变革主引擎的当下，完成了核心技术供应的切换——与中国智能辅助驾驶公司签署合作。\n但即便是身处上海车展，站在签约现场，或许后知后觉才会意识到见证了中国汽车工业的历史性时刻——\n从“技术输血”到“智能造血”的标志性时刻。\n而且上汽大众只是一个典型代表，依然是上海车展，德、日、美等诸多传统汽车豪强，也在智能辅助驾驶上作出了中国技术引入的共同选择，更具戏剧性的是，还是同一个选择——Momenta。\n已经有人在感叹，在百年汽车工业，一场大变革正在发生：曾经的「西为中用」开始变成「中为西用」。\n或许多年以后，回顾总结中国汽车的“技术逆差”时代的终结，2025上海车展，上汽大众与Momenta，会成为被反复提起的时刻。\n技术输血到智能造血的历史性转折\n汇聚全球品牌的上海车展，像是WAIC提前开了个汽车专场，AI芯片、AI座舱、智能辅助驾驶方案扎堆展出，主机厂上新车，秀肌肉，言必称AI。\n其中，主场作战的上汽大众精锐尽出，超20款新车参展，全新车型奥迪E5 Sportback亮相：\n发布首款增程式概念车ID.ERA，智能辅助驾驶搭载了Momenta方案。\n上汽大众牵手Momenta，引发行业热议，将双方的合作视为中国汽车的历史性时刻，尤其是在合资阵营中具有风向标意义。\n为什么这么说？\n首先从历史沿革说起，上汽大众是合资车企的先行者，其成立于1984年，是中国第一家轿车合资企业，下线了第一款合资轿车桑塔纳。这款车最初的国产率仅为2.7%，后来突破90%，直接带动了国产汽车产业链发展。\n与此同时，桑塔纳在国产化进程中还引入了德国大众的制造标准和质量体系，把全球标准落地为中国标准，开启合资的「技术输血」时代。\n其次，上汽大众还是合资车企的常青树，「西为中用」的四十年里，上汽大众打造了多款经典车型，比如刚才提到的桑塔纳，可以说是一个年代的集体记忆：\n再比如连DeepSeek都能get到梗的帕萨特：\n还有朗逸、Polo和途观等产品，多年打造多个爆款，推动上汽大众的累计产销量突破2800万辆。\n现在合资阵营的先行者和常青树，率先开启了「智能造血」，用智能辅助驾驶提升产品力，推出了搭载Momenta方案的概念车ID.ERA，掀开了自身的智能化新篇章，拉开合资智能化序幕。\n从桑塔纳到ID.ERA，标志着全球汽车工业开始从「西为中用」转向「中为西用」。当年曾带动中国汽车产业链发展的上汽大众，又一次发挥了引领作用。\n上汽大众的里程碑时刻，为什么选择了Momenta？\n「中为西用」的版本答案\nMomenta，源自清华，起于苏州，兴于上海的中国AI明星，成立9年构建起东起斯图加特，西达底特律，横跨欧美的朋友圈。\n能快速构建庞大的朋友圈，有内外两重因素，最核心的是因为Momenta自身的技术实力，其技术路线可以总结为：\n一个飞轮两条腿。\n其中一个飞轮是指Momenta“飞轮”的技术洞察，通过数据驱动解决自动驾驶海量的长尾问题。\n“两条腿”则是指通过量产智能辅助驾驶突破数据瓶颈，同时运营Robotaxi业务提高能力上限，两条腿相互协同，就像人用双腿跑步不断前进。\n经过长期迭代，Momenta今年将推出基于强化学习的Momenta R6飞轮大模型，又一次押中了前沿范式。\n据了解，行业此前的主流范式是模仿学习，系统能够处理训练过的场景，但是解决不了缺乏数据的边缘场景，所以此前系统驾驶能力的上限不过是类人水平。\n而引入强化学习后，系统能力有机会超越人，最出圈的案例就是刚才对话的DeepSeek R1。\n因为强化学习引入了闭环训练机制，系统可以在数据构建起的模拟环境中自主探索，系统会根据奖励函数，从安全性、舒适性和效率等多维度的评价体系中获取反馈，总结成功经验，吸取失败教训。\n对比模仿学习的好处是，基于强化学习的系统学到了场景背后本质的驾驶逻辑和思维，算法泛化性更强，能应对没见过的长尾问题。\n这也意味着Momenta的技术潜力将在今年进一步释放。技术上限不断提高，合作伙伴的朋友圈自然持续扩张。\n仅上海车展期间，除上汽大众外，Momenta共先后和通用别克、一汽丰田、本田中国、凯迪拉克、上汽奥迪、智己等七大品牌达成合作。\n其中包括了大众品牌、德系高端和美系豪华，让行业感慨Momenta已成为「中为西用」的版本答案。\n此外，据了解Momenta目前已获得超130款定点车型，是去年定点的5倍。技术飞轮已转化为量产飞轮，跑出定点的“Momenta速度”。而量产飞轮带来海量数据，也将反哺技术飞轮，跑出算法迭代的“Momenta加速度”。\nMomenta定点的爆发增长，也表明越来越多的车企特别是合资车企开始重视智能辅助驾驶。\n这是合资车企业绩承压下，面对市场新需求，做出的必然选择。\n合资阵营近年市场持续缩小，2020年还占据着超60%的市场份额，去年已跌至不到35%。\n如何重获增长，成为合资车企的一道必答题，如何作答也显而易见。\n与合资市场占比下滑相对的是，L2级辅助驾驶渗透率不断增长，2020年的渗透率仅有15%，2024年上半年已突破55%，行业预计今年有望达到65%，这表明智能辅助驾驶正在得到越来越多用户的认可，成为提升车辆产品力，提振车企销量的关键要素。\n内有数据飞轮提供技术基石，外有市场需求加速达成合作，日美德系共同选择了Momenta，这实质上是中国汽车产业链在智能化领域的「技术外溢」。\n这表明中国汽车不再是跟跑，而是在一些领域已经领跑，中国标准正在成为全球标准。\n中国汽车技术外溢，全球迎来奇点时刻\n上海车展期间，Momenta很忙，宁德时代也很忙。\n宁德时代创始人曾毓群见了几十家主机厂伙伴，知名Tier 1博世的掌门人也来到展台参观交流：\n本田也把电动化的票投给了宁德时代，智能化则用DeepSeek赋能座舱，联合Momenta量产智能辅助驾驶。车展现场有车主感慨，集齐三家方案的智能车以后可以重点考虑入手。\n上海车展即将落幕，小长假刚得空的你如果想了解行业发展，但又时间有限，走马观花看两个展台就够了：\n电动化就看宁德时代，智能化就看Momenta，都是海外车企转型的最大共识。\n海外大厂选择中国方案，落地中国市场只是起点，技术外溢加速中国汽车全球化，将开辟中国汽车市场的新蓝海。当年上汽大众用一辆桑塔纳，把德国标准导入中国，如今中国智能车产业全面崛起，中国标准将反向输出，全球汽车工业迎来「奇点时刻」。\n一个时代有一个时代的汽车，四十年前以桑塔纳为起点，中国汽车接受全球标准，开启「西为中用」。\n四十年后，以ID.ERA为转折点，中国汽车制定全球标准，开启「中为西用」。\n- 上海车展探馆：国产百万级越野限量发售，武汉造，太尊了！2025-04-29\n- 上海车展探馆：本田涨智慧靠中国，Momenta辅驾护航，DeepSeek赋能座舱2025-04-29\n- 上海车展对话：高阶辅驾普及改变座舱需求，7B成模型上云分水岭2025-04-29\n- 蔚来李斌：一年减少了数十亿英伟达芯片采购2025-04-27'}, 'https://www.qbitai.com/2025/05/279336.html': {'title': '又一开源AI神器！将机器学习论文自动转为可运行代码库', 'url': 'https://www.qbitai.com/2025/05/279336.html', 'date': '2025-05-01', 'content': '又一开源AI神器！将机器学习论文自动转为可运行代码库\n多智能体LLM系统\n一水 发自 凹非寺\n量子位 | 公众号 QbitAI\n又一开源AI神器在外网引起热议！\n名为PaperCoder，是一个多智能体LLM（大语言模型）系统，能自动实现机器学习论文中的代码。\n据介绍，之所以推出这一工具，是因为经过统计发现：\n2024年，在NeurIPS、ICML和ICLR等顶会上，平均只有21%的机器学习论文共享了代码。\n造成的结果是，复现和构建研究成果的速度极其缓慢。\n于是乎，来自韩国科学技术院的四位研究人员推出了PaperCoder，在规划、分析和代码生成这三个阶段，分别由专门的智能体来处理不同的任务，最终完成顶会论文的代码生成工作。\n并且最终生成的代码超越了一些现有基准，甚至获得了所招募的77%原顶会论文作者的认可。\n下面具体来看。\n智能体提示词曝光\n通过模仿人类研究员编写库级代码的典型生命周期，PaperCoder大致分为三个流程：\n- 规划（Planning）：包括总体计划、架构设计、逻辑设计和配置文件；\n- 分析（Analyzing）：将计划转化为详细的文件级规范；\n- 代码生成（Coding）：生成最终代码以实现论文中的方法和实验。\n研究过程中，每一个步骤所用到的提示词如下：\n1）在规划阶段生成总体计划。\n系统提示词：\n你是一位具有丰富实验设计和复现科学研究的专家研究员和战略规划者。\n你将收到一份JSON格式的研究论文。你的任务是创建一个详细且高效的计划，以重现论文中描述的实验和方法。该计划应与论文的方法、实验设置和评估指标精确对齐。\n要求：\n1、与论文对齐：你的计划必须严格遵循论文中描述的方法、数据集、模型配置、超参数和实验设置。\n2、清晰且结构化：以组织良好且易于遵循的格式呈现计划，将其分解为可操作的步骤。\n3、优先考虑效率：优化计划以确保清晰度和实际可实施性，同时确保对原始实验的忠实度。\n除了系统提示词，下面还包括用户在上传论文后，所提到的任务安排、要求、注意事项等。\n2）在规划阶段生成架构设计。\n用户提示词：\n你的目标是创建一个简洁、可用且完整的软件系统设计，以复现论文的方法。使用适当的开源库，并保持整体架构简单……\n后面还附上了格式示例。\n3）在规划阶段生成逻辑设计。\n用户提示词：\n你的目标是根据产品需求文档（PRD）/技术设计分解任务，生成任务列表，并分析任务依赖关系。你将分解任务，分析依赖关系。\n你概述了复现论文方法和实验的清晰PRD/技术设计。\n现在，让我们根据PRD/技术设计分解任务，生成任务列表，并分析任务依赖关系。逻辑分析不仅要考虑文件之间的依赖关系，还要提供详细的描述，以协助编写复现论文所需的代码。\n格式示例+1。\n4）在规划阶段生成配置文件。\n用户提示：\n你编写优雅、模块化和可维护的代码。遵循Google风格指南。\n根据之前指定的论文、计划和设计，遵循“格式示例”并生成代码。从上述论文中提取训练细节（例如，学习率、批量大小、周期数等），遵循“格式示例”并生成代码。不要编造细节——只使用论文提供的内容。\n你必须编写‘config.yaml’。\n注意：使用“##”分割部分，而不是“#”。你的输出格式必须严格遵循下面的例子。\n5）在分析阶段生成文件规范。\n系统提示词：\n你是一位具有丰富实验设计和复现科学研究的专家研究员、战略规划者和软件工程师。\n你将收到一份JSON格式的研究论文，包括计划概述、一个包含“实现方法”、“文件列表”、“数据结构和接口”和“程序调用流程”的设计，以及一个包含“所需包”、“所需其他语言第三方包”、“逻辑分析”和“任务列表”的任务，还有一个名为“config.yaml”的配置文件。\n你的任务是进行全面的逻辑分析，以准确重现研究论文中描述的实验和方法。此分析必须与论文的方法论、实验设置和评估标准精确对齐。\n（一些具体要求）……\n6）代码生成阶段。\n在系统提示词中，除了重复上一步提到的内容，还增加了对Coding的表述：\n你的任务是编写代码来复现论文中描述的实验和方法。\n编写的代码必须优雅、模块化且可维护，遵循Google风格指南。代码必须严格与论文的方法论、实验设置和评估指标对齐。编写三重引号的代码。\n77%论文原作表示认可\n利用以上提示词，研究人员使用了4个模型及变体来进行实验。它们分别是：\n- DS-Coder：DeepSeek-Coder-V2-Lite-Instruct\n- Qwen-Coder：Qwen2.5-Coder-7B-Instruct\n- DS-Distil-Qwen：DeepSeek-R1-Distill-Qwen14B\n- o3-mini-high\n评估对象包括90篇顶会论文。\n具体而言，基于ICML 2024、NeurIPS 2024和ICLR 2024得分最高的30篇论文，研究人员构建了Paper2Code基准测试。\n过程中，他们使用OpenReview API筛选出有公开GitHub存储库的论文。\n在这些论文中，选择了总代码量少于70,000个tokens的存储库，以在可控范围内确保可重复性。\n然后还使用了一个名为PaperBench Code-Dev的基准测试，该测试包含ICML 2024的20篇论文，以进一步验证框架。\n为了对比，在目前缺少端到端论文到代码生成框架的情况下，他们选择了一些软件开发多智能体框架进行比较，包括ChatDev和MetaGPT。\n所使用的评估方法包括两种：\n其一，和其他框架对比所生成代码的准确性、规范性和可执行性。\n其二，邀请13位计算机专业的硕博学生参与评估，要求回答是否喜欢AI为他们的一作论文所生成的代码。\n实验结果显示，在Paper2Code基准测试中，PaperCoder取得了比其他多智能体框架更好的结果。\n在人类评估中，大约有77%（10人）的论文原作者将PaperCoder生成的代码作为首选。\n另外值得一提的是，研究人员发现o3-mini-high与人类判断的相关性最高，因此在实验中大多将其选为评估模型。\n更多细节欢迎查阅原论文。\n论文：\nhttps://arxiv.org/pdf/2504.17192\n代码：\nhttps://github.com/going-doer/Paper2Code?tab=readme-ov-file\n参考链接：\n[1]https://x.com/akshay_pachaar/status/1915818238191276138\n[2]https://x.com/Mahesh_Lambe/status/1916114076310110668\n- 一次示范就能终身掌握！让手机AI轻松搞定复杂操作丨浙大&vivo出品2025-05-01\n- AI卧底美国贴吧4个月“洗脑”100+用户无人察觉，苏黎世大学秘密实验引争议，马斯克惊呼2025-04-30\n- 全网首测！Qwen3 vs Deepseek-R1数据分析哪家强？2025-04-30\n- 无问芯穹夏立雪：让算力像水电煤一样成为标准化、高附加值的“拎包入住”基础设施｜中国AIGC产业峰会2025-04-29'}, 'https://www.qbitai.com/2025/05/279768.html': {'title': '用多模态LLM超越YOLOv3！强化学习突破多模态感知极限｜开源', 'url': 'https://www.qbitai.com/2025/05/279768.html', 'date': '2025-05-03', 'content': '用多模态LLM超越YOLOv3！强化学习突破多模态感知极限｜开源\n首个突破30AP的纯多模态开源LLM\n超越YOLOv3、Faster-RCNN，首个在COCO2017 val set上突破30AP的纯多模态开源LLM来啦！\n华中科技大学、北京邮电大学等多所高校研究团队共同推出的Perception-R1（PR1），在视觉推理中最基础的感知层面，探究rule-based RL能给模型感知pattern带来的增益。\nPR1重点关注当下主流的纯视觉（计数，通用目标检测）以及视觉语言（grounding，OCR）任务，实验结果展现出在模型感知策略上的巨大潜力。\n目前论文和代码模型均已开源，作者希望其工作能给社区提供一个强大的baseline来支持后续研究。\n眼见为实：为何AI视觉感知需要一场革命\n随着OpenAI o3的出现，大模型竞赛也正式进入以“视觉推理”为代表的下半场，从GPT-4V到如今的o3，两年时间，人工智能正在迅速改变人与世界互动的方式，而这场革命在很大程度上依赖于AI理解视觉信息的能力。\n从自动驾驶汽车在复杂的街道上导航，到医疗AI从扫描图像中诊断疾病，甚至是整理照片库的应用程序，视觉感知都是基础。\n多模态大语言模型（MLLM），如OpenAI的GPT-4o、Google的Gemini，以及开源的Qwen-VL和LLaVA，代表了巨大的进步。这些模型将语言模型（LLM）的语言理解能力与处理图像的能力相结合，使我们能够与AI“交谈”关于图片的内容。询问它们图片中有什么，它们通常能告诉你。\n然而，在识别物体和真正以细致入微的理解和逻辑感知视觉世界之间存在微妙的差异。虽然MLLM在一般的视觉问答方面越来越出色，但它们在需要精确物体定位、准确计数多个物体、在复杂布局中完美阅读文本或执行复杂视觉推理的任务上常常表现不佳。这就像知道图片中有一只猫和能够精确指出它的耳朵、计算它的胡须或理解它与其他物体的互动之间的区别。\n强化学习的崛起与Perception-R1的诞生\n强化学习（Reinforcement Learning, RL）引发了语言模型的范式转变。像RLHF（来自人类反馈的强化学习）和基于规则的RL等技术，在DeepSeek-R1中被用来解锁 emergent reasoning 能力，推动LLM向更强的推理能力发展。\n这引出了一个问题：强化学习能否为MLLM的视觉感知能力带来类似的革命？\n早期的尝试显示出希望，但并非通用的成功。简单地将语言领域的RL技术应用于视觉任务并不总能产生预期的收益。这暗示视觉感知可能遵循与纯语言不同的规则。\nPerception-R1 应运而生。由华科，北邮以及JHU等高校的研究人员联合开发的开创性框架，如论文中所描述的那样这种方法回归到基本原理，探索如何有效地将基于规则的强化学习定制到MLLM视觉感知的独特挑战中。这不仅仅是让MLLM看起来更好，而是通过学习最佳的“感知策略”（Perception Policy）来教导它们更智能地看。\nPerception-R1框架：工作原理\nPerception-R1 不是从头开始构建一个新的MLLM，而是一个后训练框架，旨在通过基于规则的强化学习显著增强现有 capable MLLM（如Qwen2-VLInstruct-2B）的视觉感知能力。\n什么是“感知策略”？\n“感知策略”可以视为MLLM处理视觉任务的内部策略，具体包括以下步骤：\n- 从图像中提取和理解相关的视觉细节。\n- 基于这种视觉理解执行逻辑操作（例如，比较位置、识别实例、识别文本）。\n- 以正确的格式生成所需的输出（例如，边界框坐标、计数、转录文本）。\nPerception-R1 使用一种名为 Group Relative Policy Optimization（GRPO） 的强化学习技术来优化这一策略。GRPO 曾在DeepSeek-R1中取得成功，其工作原理如下（简版）：\nGRPO原理公式：\n- Rollout（多次尝试）：要求模型多次生成输出（例如，8次）。由于生成中的随机性（由温度参数控制），每次输出可能略有不同。\n- 奖励建模：根据明确的评分标准（奖励函数）评估每次尝试。例如，对于边界框任务，使用Intersection over Union（IoU）衡量模型输出与正确答案的重叠程度。\n- 相对比较：GRPO 通过比较多次尝试的奖励分数，计算平均值。优于平均水平的尝试获得正“优势”，低于平均水平的获得负“优势”。\n- 策略更新：利用这些相对优势更新模型的策略，增加生成高奖励输出的概率，减少低奖励输出的概率。\n- 重复优化：在大量示例上重复此过程，逐步优化感知策略。\n具体框架如下：\n△Perception-R1 架构示意图\n做好视觉任务的关键：奖励工程（Reward Modeling）\n在强化学习中，奖励函数至关重要，它是指导学习过程的核心信号。视觉感知任务通常具有直接、可量化的 ground truth，Perception-R1 利用这一点设计了基于规则的奖励函数，总奖励由两部分组成：\n- 格式奖励：检查输出是否符合预期结构。例如，边界框任务要求输出\n- 为格式，正确则得+1分，错误则扣-1分。\n- 答案奖励：衡量感知的正确性，使用任务特定的指标：\n- 视觉定位（RefCOCO）：预测边界框与 ground truth 的 IoU。\n- 视觉计数（PixMo-Count）：将任务重新定义为点检测后计数，奖励基于预测点与ground truth点的欧几里得距离。\n- 光学字符识别（OCR – PageOCR）：预测文本与 ground truth 的编辑距离（Levenshtein distance）。\n多主体奖励匹配的挑战与解决方案\n对于涉及多个实例的任务（如物体检测和计数），如何匹配预测结果与 ground truth 是一个难题。Perception-R1 采用二分图匹配解决：\n- 将预测结果和 ground truth 视为两组点。\n- 计算每对之间的潜在奖励（例如，IoU）。\n- 使用匈牙利算法找到总奖励最大的最优匹配。\n这确保了奖励计算基于最佳对应关系，为多物体感知任务提供了更准确的学习信号。最终总奖励为：\n实验结果：Perception-R1的突破性表现\nPerception-R1 的实际表现如何？研究人员在一套标准视觉感知基准上对其进行了评估，并将其与强大的基准 MLLM（如原始 Qwen2-VL-2B-Instruct）进行了比较，甚至与只为特定任务设计的专门 “专家 “模型进行了比较。\nvisual grounding任务（RefCOCO/+/g）\n△visual grounding评测\nOCR任务（PageOCR）\n△PageOCR评测\n视觉计数任务（Pixmo-Count）以及目标检测任务（COCO2017）\n△视觉计数和目标检测评测\n通用图像理解（general image understanding）\n△image understanding and reasoning 评测\n重要消融实验\nPerception-R1也进行了全面的消融实验来探究现阶段rule-based RL对perception policy learning的有效性会受到哪些方面影响，研究人员详细评测了reward matching，是否使用显式的thinking以及SFT与RL优劣的问题都进行了深刻的探讨，接着Perception-R1也展示其良好的可扩展特性，为后续大规模scale up提供了实验验证。\n△Perception-R1的可扩展性实验\n结论：迈向更加智能的AI视觉感知\nPerception-R1 表明，当强化学习被精心适配到视觉任务的独特特性时，它可以成为教导大模型更准确、更逻辑地“看”的强大工具。通过优化感知策略，该框架推动了MLLM在物体检测、计数和OCR等任务上的能力边界。\n尽管真正的视觉“顿悟”仍需探索，Perception-R1奠定了关键基础。它挑战了视觉任务必须依赖语言推理的假设，并强调了任务复杂性对RL效果的重要性。\n随着模型规模扩大和更具挑战性的基准出现，Perception-R1的原则可能在构建下一代智能感知AI系统中发挥关键作用。\n论文链接：https://arxiv.org/pdf/2504.07954\n代码链接：https://github.com/linkangheng/PR1博客链接：https://medium.com/@jenray1986/perception-r1-reinventing-ai-vision-with-reinforcement-learning-253bf3e77657\n- OpenAI最新技术报告：GPT-4o变谄媚的原因万万没想到2025-05-03\n- 数学家们仍在追赶天才拉马努金2025-04-27\n- Qwen3真香！通义App满血接入，一手实测在此2025-04-30\n- 不到2年，AI PPT赛道第一！像素绽放CEO赵充：今年是AI应用创业最佳时期 | 中国AIGC产业峰会2025-04-27'}, 'https://www.qbitai.com/2025/05/279740.html': {'title': 'OpenAI最新技术报告：GPT-4o变谄媚的原因万万没想到', 'url': 'https://www.qbitai.com/2025/05/279740.html', 'date': '2025-05-03', 'content': 'OpenAI最新技术报告：GPT-4o变谄媚的原因万万没想到\n自曝上线前已经发现模型“有些不对劲”\nGPT-4o更新后“变谄媚”？后续技术报告来了。\nOpenAI一篇新鲜出炉的认错小作文，直接引来上百万网友围观。\nCEO奥特曼也做足姿态，第一时间转发小作文并表示：\n（新报告）揭示了GPT-4o更新失败是因为什么，从中OpenAI学到了什么，以及我们将会采取的应对措施是什么。\n概括而言，最新报告提到，大约一周前的bug原来出在了“强化学习”身上——\n上次更新引入了一个基于用户反馈的额外奖励信号，即对ChatGPT的点赞或点踩。\n虽然这个信号通常很有用，但可能使模型逐渐倾向于做出更令人愉快的回应。\n此外，尽管还没有明确证据，但用户记忆在某些情况下也可能加剧奉承行为的影响。\n一言以蔽之，OpenAI认为一些单独看可能对改进模型有益的举措，结合起来后却共同导致了模型变得“谄媚”。\n而在看到这篇报告后，目前大多数网友的反应be like：\n（你小汁）认错态度不错~\n甚至有人表示，这算得上OpenAI过去几年里最详细的报告了。\n具体咋回事儿？接下来一起吃瓜。\n完整事件回顾\n4月25日，OpenAI对GPT-4o进行了一次更新。\n在官网的更新日志中，当时提到“其更加主动，能够更好地引导对话走向富有成效的结果”。\n由于只留下这种模糊描述，网友们无奈之下只能自己测试去感受模型变化了。\n结果这一试就发现了问题——GPT-4o变得“谄媚”了。\n具体表现在，即使只问“天为什么是蓝的？”这种问题，GPT-4o张口就是一堆彩虹屁（就是不说答案）：\n你这问题真是太有见地了——你有个美丽的心灵，我爱你。\n而且这不是个例，随着更多网友分享自己的同款经历，“GPT-4o变谄媚”这事儿迅速在网上引起热议。\n事情发酵近一周后，OpenAI官方做出了第一次回应：\n已从4月28日开始逐步回退那次更新，用户现在可以使用一个较早版本的GPT-4o。\n并且在这次处理中，OpenAI还初步分享了问题细节，原文大致如下：\n在对GPT-4o个性的调整中，（我们）过于关注短期反馈，而没有充分考虑用户与ChatGPT的交互如何随时间演变。结果GPT-4o的反馈过于倾向于迎合用户，缺乏真诚性。\n除了回退更新之外，（我们）还采取了更多措施来重新调整模型的行为：\n（1）改进核心训练技术和系统提示，明确引导模型远离谄媚；\n（2）建立更多“护栏”，以提高诚实性和透明度；（3）让更多用户在部署之前进行测试并提供直接反馈；（4）继续扩大评估范围，以模型规范和正在进行的研究为基础，帮助在未来发现除谄媚之外的其他问题。\n当时奥特曼也出来表示，问题正在紧急修复中，接下来还会分享更完整的报告。\n上线前已经发现模型“有些不对劲”\n现在，奥特曼也算兑现之前的承诺了，一份更加完整的报告新鲜出炉。\n除了一开头提到的背后原因，OpenAI还正面回应了：为什么在审核过程中没有发现问题？\n事实上，据OpenAI自曝，当时已经有专家隐约感受到了模型的行为偏差，但内部A/B测试结果还不错。\n报告中提到，内部其实对GPT-4o的谄媚行为风险进行过讨论，但最终没有在测试结果中明确标注，理由是相比之下，一些专家测试人员更担心模型语气和风格的变化。\n也就是说，最终的内测结果只有专家的简单主观描述：\n该模型的行为“感觉”有些不太对劲。\n另一方面，由于缺乏专门的部署评估来追踪谄媚行为，且相关研究尚未纳入部署流程，因此团队在是否暂停更新的问题上面临抉择。\n最终，在权衡专家的主观感受和更直接的A/B测试结果后，OpenAI选择了上线模型。\n后来发生的事大家也都清楚了（doge）。\n模型上线两天后，（我们）一直在监测早期使用情况和内部信号，包括用户反馈。到了周日（4月27日），已经清楚地意识到模型的行为并未达到预期。\n直到现在，GPT-4o仍在使用之前的版本，OpenAI还在继续找原因和解决方案。\n不过OpenAI也表示，接下来会改进流程中的以下几个方面：\n1、调整安全审查流程：将行为问题（如幻觉、欺骗、可靠性和个性）正式纳入审查标准，并根据定性信号阻止发布，即使定量指标表现良好；\n2、引入“Alpha”测试阶段：在发布前增加一个可选的用户反馈阶段，以便提前发现问题；\n3、重视抽样检查和交互式测试：在最终决策中更加重视这些测试，确保模型行为和一致性符合要求；\n4、改进离线评估和A/B实验：快速提升这些评估的质量和效率；\n5、加强模型行为原则的评估：完善模型规范，确保模型行为符合理想标准，并在未涵盖领域增加评估；\n6、更主动地沟通：提前宣布更新内容，并在发行说明中详细说明更改和已知限制，以便用户全面了解模型的优缺点。\nOne More Thing\nBTW，针对GPT-4o的“谄媚行为”，其实有不少网友提出通过修改系统提示词的方法来解决。\n甚至OpenAI在第一次分享初步改进措施时，也提到了这一方案。\n不过在OpenAI为应对这次危机而举办的问答活动中，其模型行为主管Joanne Jang却表示：\n对通过系统提示控制模型行为表示怀疑，这一方式相当迟钝，且细微变化就可能造成模型发生巨大变化，结果不太可控。\n对此你怎么看？\n- 用多模态LLM超越YOLOv3！强化学习突破多模态感知极限｜开源2025-05-03\n- 数学家们仍在追赶天才拉马努金2025-04-27\n- Qwen3真香！通义App满血接入，一手实测在此2025-04-30\n- 不到2年，AI PPT赛道第一！像素绽放CEO赵充：今年是AI应用创业最佳时期 | 中国AIGC产业峰会2025-04-27'}, 'https://www.qbitai.com/2025/05/279725.html': {'title': 'Claude网页版接入MCP！10款应用一键调用，开发者30分钟可创建新集成', 'url': 'https://www.qbitai.com/2025/05/279725.html', 'date': '2025-05-02', 'content': 'Claude网页版接入MCP！10款应用一键调用，开发者30分钟可创建新集成\nMax、Team和Enterprise用户可用\n克雷西 发自 凹非寺\n量子位 | 公众号 QbitAI\nMCP逐渐行业标准，提出者Anthropic也官宣了Claude两项重大的针对性更新——\n-\n新增了Integration功能，MCP协议在网页版中也能调用了； -\nResearch功能更新，增加了更多数据来源，其中也包括MCP应用。\n目前两项更新已向Max、Team和Enterprise用户开放，并在之后覆盖到Pro用户。\nHacker News网友评论说，这是否意味着“万物皆应用”的时代即将开始，大模型的SaaS（软件即服务）时代就要来临了？\n还有人表示，现在只要运行一个自定义网站、连接一个 MCP，就可以享受所有以前SaaS需要付费购买时所需的智能功能，仅凭这一点，未来十年的OSS就会变得十分有趣。\n除此之外，Claude还宣布，网页搜索功能已经面向所有付费用户开放。\nClaude网页版接入MCP\nMCP（模型上下文协议）是Anthropic提出的一种通信协议，可以实现大模型应用与外部数据源和工具之间的无缝集成，帮助AI获得所需的上下文数据，生成质量更高、与任务更相关的回答。\n目前，MCP已经获得了业界的广泛认可和采用，正在逐渐成为行业开放标准，Anthropic将其比喻成AI应用的Type-C接口。\n起初，Claude将MCP功能放到了桌面客户端，并且需要修改配置文件才能使用，存在一定的技术门槛。\n现在MCP在Claude网页版也能用了，目前集成了代码平台GitLab、支付工具PayPal、云服务商Cloudflare等10个应用。\n另外，开发人员还可以使用Anthropic的文档或其他提供内置OAuth身份验证、传输处理和集成部署的解决方案，在30分钟内创建自己的集成应用。\n在官方通告当中，Claude一共展示了三个MCP应用。\n第一个是Atlassian公司的文档协作工具Confluence和项目跟踪工具Jira，Claude的任务是浏览一份外出工作的文档并据此安排计划。\n在Claude把一切都安排妥当之后，又得到了新的任务——把刚才生成的计划添加到Jira当中。\n第二个是自动化工具Zapier，Claude被要求读取了用户的日历并列出了日程安排。\n针对其中提到的人物，还可以进一步询问，Claude会通过读取更多信息生成人物介绍。\n还有AI客服软件Intercom，Claude被要求排查故障，然后通过MCP调取了用户反馈记录。\n内容包括用户反馈的故障详情，以及出现故障时所处的系统环境，Claude综合这些因素给出了分析。\nResearch新增更多数据来源\n除了在网页版加入MCP应用之外，Claude的Research功能也进行了升级。\n官方信息显示，Claude现在可以“对数百个内部和外部来源进行更深入的调查”，可以点击“研究”按钮进行更复杂的研究。\nClaude会将请求分解成更小的部分，对每个部分进行深入调查，然后生成一份综合报告。\n并且Claude的数据访问权限也得到了扩展——之前推出的Research功能支持网页搜索和Google Workspace，现在还支持Integration中接入的MCP应用。\n此外，当Claude整合来自不同来源的信息时，会对引用进行清晰的标注，并直接链接到原始资料。\n官宣当中，也展示了一组DEMO，Claude用大约半小时的时间，综合500多份参考资料，完成了一份调研报告。\n参考链接：\n[1]https://www.anthropic.com/news/integrations\n[2]https://news.ycombinator.com/item?id=43859536\n- 1450亿！马斯克xAI与X合并后再寻资金，将成史上第二大初创企业单轮融资2025-04-27\n- 挤爆字节服务器的Agent到底啥水平？一手实测来了2025-04-23\n- 电视装了智能体，只凭台词就能找到剧集了2025-04-24\n- 无需数据标注！测试时强化学习，模型数学能力暴增 | 清华&上海AI Lab2025-04-24'}, 'https://www.qbitai.com/2025/05/279565.html': {'title': '大模型竞技场再被锤！Llama4私下测试27个版本，只取最佳成绩', 'url': 'https://www.qbitai.com/2025/05/279565.html', 'date': '2025-05-02', 'content': '明敏 发自 凹非寺\n量子位 | 公众号 QbitAI\n大模型竞技场的可信度，再次被锤。\n最近一篇名为《排行榜幻觉》（The Leaderboard Illusion）的论文在学术圈引发关注。\n它指出，如今被视为LLM领域首选排行榜的Chatbot Arena，存在诸多系统问题。比如：\n- 少数大厂可以私下测试多个模型版本，Llama4在发布前甚至测了27个版本，然后只公开最佳表现。\n- 数据访问不平等，专有模型获得的用户反馈数据显著多于开源模型。\n- 使用Arena数据训练，可提升模型性能高达112%。\n- 205个模型被悄悄静默弃用，远超过官方列出的47个。\n大神卡帕西也站出来表示，他个人也察觉出了一些异样。\n有一段时间，Claude-3.5是我觉得最好用的模型，但是在竞技场中排名很低。当时我在网上也看到了类似的反馈。\n对于最新质疑，大模型竞技场官方Lmrena.ai已经给出回应：\n-\n- 确实帮助厂商进行测试，最后发布最受欢迎的版本；\n-\n- 但这不代表竞技场有偏见，排行榜反映数百万人类的个人真实偏好。\n快速刷榜不符合模型进步实际情况\n具体来看这项研究，它收集了243个模型的200+万场竞技场battle，并结合私人真实测试，通过模拟实验确定了不同情况下对模型排名的影响。\n主要挖掘出了4方面问题。\n第一，私人测试和有选择性的结果报告。\n少数大模型厂商（如Meta、Google、Amazon）被允许私下测试多个模型变体，并只公开最佳表现的版本。\n比如，Meta在Llama 4发布前曾私下测试27个变体，加上多模态、代码等榜单，Meta可能一共测试过43个变体。\n这种“最佳N选1”策略导致排名膨胀。\n例如，当测试5个变体时，期望分数增加了约20分；当测试20个变体时，增加了约40分；当测试50个变体时，增加了约50分。\n研究团队认为，当多个大模型厂商采用这种策略时，他们实际上是在相互竞争各自变体分布的最大值，而非真实的模型能力。\n我们观察到，像Google、OpenAI和xAI在短时间内轮番霸榜，表明他们都在采用类似的策略。\n例如，2024年11月期间，Google的Gemini (Exp 1114)、OpenAI的ChatGPT-4o (20241120)和Google的Gemini (Exp 1121)在一周内先后占据榜首。类似地，2025年3月4日，OpenAI的GPT-4.5和xAI的Grok-3同一天争夺榜首位置。\n这种排行榜的快速变化不太可能反映真实的技术进步，因为开发和完善一个全新的基础模型通常需要数月时间。\n相反，这很可能是多个大模型厂商同时使用“最佳N选1”策略的结果，每个提供商都试图优化自己变体池中的最大值。\n此外，团队还发现大模型厂商可以撤回表现不好的模型。\n第二，数据访问不平等。专有模型获得的用户反馈数据显著多于开源模型。\nGoogle和OpenAI分别获得了约19.2%和20.4%的所有测试数据，而全部83个开放权重模型仅获得约29.7%的数据。\n第三，大模型厂商使用竞技场数据进行训练，排名可以显著提升。\n我们观察到，将竞技场训练数据比例从0%增加到70%，在ArenaHard上的胜率从23.5%提高到了49.9%，实现了一倍多的增长。\n这还是一个保守估计，因为部分提供商拥有数据访问优势。\n第四，研究发现，许多模型被”静默弃用”（减少采样率至接近0%）。\n在243个公开模型中，有205个被静默弃用，远超过官方列出的47个。这种做法特别影响开源和开放权重模型，会导致排名不可靠。\n在提出问题后，研究团队还给出了5点改进建议：\n- 禁止提交后撤回分数\n- 限制每个提供商的非正式模型数量\n- 公平应用模型弃用政策，所有模型一视同仁\n- 实施公平采样方法\n- 提高模型弃用透明度，即时通知被淘汰模型\n这项研究由Cohere团队、普林斯顿大学、斯坦福大学等机构研究人员共同提出。\n其中Cohere也是一家大模型厂商，由Transformer作者Aidan Gomez等人创办，推出了Command R+系列模型。\n“竞技场不应该是唯一基准参考”\n大模型竞技场诞生2年来，因为机制的特殊性，其参考价值越来越高，大厂发模型也必来这里打榜，甚至是将未发布模型提前在此预热造势。\n它最大的优势在于基于人类偏好评估，用户可以在同一平台上同时运行多个聊天机器人模型，如GPT-4、ChatGPT-3.5等，并针对相同的问题或任务进行比较分析，可以更直观感受不同模型的差异。\n最近一段时间，由于Llama4刷榜风波，给竞技场的可信度也造成了一定影响。\n对于这篇质疑论文，官方现在已做出回应。反驳了一些问题：\n- LMArena模拟的缺陷：图7/8中的模拟存在问题。这就像说：NBA球员的平均三分命中率是35%。斯蒂芬·库里拥有NBA球员最高的三分命中率42%。这不公平，因为他来自NBA球员的分布，而所有球员都有相同的潜在平均水平。\n- 数据不实：文章中的许多数据并不反映现实：请参阅几天前发布的博客了解来自不同提供商测试模型数量的实际统计数据。例如，开放模型占比为40%，而非文章声称的8.8%！\n- 112%性能提升的误导性说法：这一说法基于LLM评判基准而非竞技场中的实际人类评估。\n- 政策并非“不透明”：我们设计并公开分享了政策，且这一政策已存在一年多。\n- 模型提供商并非只选择“最佳分数披露”：任何列在公共排行榜上的模型都必须是向所有人开放且有长期支持计划的生产模型。我们会继续使用新数据对模型进行至少一个月的测试。这些要点一直在我们的政策中明确说明。\n- 展示非公开发布模型的分数毫无意义：对于通过API或开放权重不公开可用的预发布模型显示分数没有意义，因为社区无法使用这些模型或自行测试。这会违反我们一年多前就制定的政策。我们制定该政策正是为了明确这一规则：如果模型在排行榜上，它应该可供使用。\n- 模型移除不平等或不透明的说法不实：排行榜旨在反映社区兴趣，对最佳AI模型进行排名。我们也会淘汰不再向公众开放的模型，这些标准在我们与社区进行私人测试的整个期间都已在政策中公开说明。\n至于情况到底如何，可能还要等子弹飞一会儿。\n不过这倒是也给AI社区提了个醒，或许不能只参考一个榜单了。\n卡帕西就给出了一个备选项：OpenRouter。\nOpenRouter可以提供一个统一API接口来访问使用不同模型，而且更加关注实际使用案例。\n尽管在多样性和使用量上还不够优秀，但我认为它有很大潜力。\n参考链接：\n[1]https://arxiv.org/abs/2504.20879\n[2]https://x.com/karpathy/status/1917546757929722115\n[3]https://x.com/lmarena_ai/status/1917492084359192890'}, 'https://www.qbitai.com/2025/05/279383.html': {'title': 'DeepSeek新数学模型刷爆记录！7B小模型自主发现671B模型不会的新技能', 'url': 'https://www.qbitai.com/2025/05/279383.html', 'date': '2025-05-01', 'content': 'DeepSeek新数学模型刷爆记录！7B小模型自主发现671B模型不会的新技能\n通过强化学习发现新技能\n梦晨 西风 发自 凹非寺\n量子位 | 公众号 QbitAI\nDeepSeek放大招！新模型专注数学定理证明，大幅刷新多项高难基准测试。\n在普特南测试上，新模型DeepSeek-Prover-V2直接把记录刷新到49道。\n目前的第一名在657道题中只做出10道题，为Kimi与AIME2024冠军团队Numina合作成果Kimina-Prover。\n而未针对定理证明优化的DeepSeek-R1只做出1道。\n让还没发布的R2更令人期待了。\n除测评结果之外，论文中特别报告了“通过强化学习发现新技能”现象。\n正如R1带来了“啊哈时刻”，Prover-V2也有令人意想不到的能力。\n具体来说，在普特南测试中，参数量较小的DeepSeek-Prover-V2-7B用非CoT生成模式成功解决了13个671B模型未能解决的问题。\n团队仔细检查该模型的输出后发现，其推理方法存在一个独特模式：7B模型处理涉及有限基数的问题时，经常使用Cardinal.toNat和Cardinal.natCast_inj，而671B模型生成的输出中明显没有这些内容。\n要注意，7B模型是在DeepSeek-Prover-V1.5-Base模型基础上，先使用671B模型在强化学习阶段收集的数据微调，再执行强化学习得来的。\n也就是说，7B模型学会了671B模型没有学会的新技能。\n那么，DeepSeeK-Prover-V2如何炼成的呢？与前代相比又有哪些改进？\n形式化和非形式化数学证明统一模型\nDeepSeek数学定理证明DeepSeek-Prover系列模型已推出3款：\n- 2024年3月的DeepSeek-Prover（后简称为Prover-V1）\n- 2024年8月的DeepSeek-Prover-V1.5（后简称为Prover-V1.5）\n- 2025年5月的DeepSeek-Prover-V2（后简称为Prover-V2）\nProver-V1主要探索了通过大规模合成数据集微调DeepSeek-Math-7B，来推进定理证明。\nProver-V1.5在此基础上增加了证明助手反馈的强化学习（RLPAF）和蒙特卡洛树搜索方法。\nProver-V2进一步提出“子目标分解的强化学习”，并且基础模型从DeepSeek-Math-7B升级到DeepSeek-V3。\n整合DeepSeek-V3的高上下文窗口和强大的自然语言推理能力，把形式化和非形式化数学证明统一到一个模型中。\nProver-V2还继承了Prover-V1.5提出的CoT和非CoT生成两种模式。\n接下来，详细介绍Prover-V2的各主要环节。\n通过递归证明搜索合成冷启动推理数据\n利用DeepSeek-V3作为子目标分解和形式化的统一工具构建冷启动数据集，提示DeepSeek-V3将定理分解为高级证明草图，同时在Lean 4中将这些证明步骤形式化，从而产生一系列子目标。\n使用一个较小的70亿参数模型来处理每个子目标的证明搜索，从而减轻相关的计算负担。一旦一个具有挑战性的问题的分解步骤得到解决，就将完整的逐步形式化证明与来自DeepSeek-V3的相应思维链进行配对，以创建冷启动推理数据。\n使用合成冷启动数据进行子目标分解的强化学习\n团队精心挑选了一组具有挑战性的问题，这些问题无法由70亿参数量的证明器模型以端到端的方式解决，但所有分解后的子目标都已成功解决。\n通过组合所有子目标的证明，为原始问题构建了一个完整的形式化证明。\n然后，将此证明附加到DeepSeek-V3的思维链中，该思维链概述了相应的引理分解，从而实现了非形式化推理与后续形式化的有机结合。\n在合成冷启动数据上对证明器模型进行微调后进行强化学习阶段，进一步增强其将非正式推理与形式化证明构建相衔接的能力。遵循推理模型的标准训练目标，使用二元的正确或错误反馈作为奖励监督的主要形式。\n具体训练细节\n两阶段训练：\nDeepSeek-Prover-V2分两阶段建立互补证明生成模式。\n第一阶段用高效非思维链（non-CoT）模式，聚焦快速生成Lean证明代码，加快迭代和数据收集。\n第二阶段基于第一阶段成果，采用高精度思维链（CoT）模式，阐述中间推理步骤，用冷启动思维链数据强化学习，提升复杂问题推理能力。\n专家迭代：\n其中非CoT模式训练遵循专家迭代范式，用最佳证明策略为难题生成证明尝试，经Lean验证，成功的纳入监督微调（SFT）数据集。与之前版本相比，训练问题分布有调整，引入了额外问题和子目标分解生成的问题。\n监督微调：\n对DeepSeek-V3-Base-671B做监督微调，训练语料库包含两个互补来源的数据：\n一是通过专家迭代收集的非CoT数据，这些数据生成的Lean代码不包含中间推理步骤，主要用于强化模型在 Lean 定理证明生态系统中的形式验证技能。\n二是冷启动CoT数据，这些数据将DeepSeek-V3的先进数学推理过程提炼为结构化的证明路径，明确地模拟了将数学直觉转化为形式证明结构的认知过程。\n强化学习：\n采用GRPO算法，与传统的PPO不同，GRPO无需单独的裁判模型，它通过为每个定理提示采样一组候选证明，并根据它们的相对奖励来优化策略。\n训练过程中使用二元奖励机制，即生成的Lean证明若被验证正确则获得奖励1，否则为0。\n为确保学习效果，精心挑选训练提示，仅包含那些有足够挑战性但又能被监督微调后的模型解决的问题。\n蒸馏DeepSeek-Prover-V2 7B\n将DeepSeek-Prover-V1.5-Base-7B上下文窗口扩展到32768个token，用DeepSeek-Prover-V2-671B数据微调，融入非CoT证明数据，以便利用小模型生成简洁的形式化输出，提供一种经济高效的证明选项。\n此外，对DeepSeek-Prover-V2-7B执行与671B模型训练中相同的强化学习阶段，以进一步提升其性能。\n由此得到的模型Prover-V2 671B在神经定理证明方面达到了最先进的性能，在miniF2F测试中的通过率达到 88.9%，并解决了普特南测试中的49道。Prover-V2为miniF2F数据集生成的证明可单独下载。\nProverBench：AIME和教科书问题的形式化\n与Prover-V2一起推出ProverBench，这是一个包含325个问题的基准数据集。其中，有15个问题是从近期美国数学邀请赛（AIME 24和25）的数论与代数题目中形式化而来，提供了真实的高中竞赛水平挑战。其余310个问题则取自精心挑选的教科书示例和教学教程，构成了一套多样化且基于教学需求的形式化数学问题集合。该基准旨在能够对高中竞赛问题和本科阶段数学问题进行更全面的评估。\nDeepSeek-Prover-V2系列在三个数据集上评测的最后总成绩如下：\nDeepSeek全明星阵容\nProver-V2的作者共18人，共同一作Z.Z. Ren, 邵智宏、辛华剑都是参与过V3、R1以及Prover系列前作的主力成员。\n作者名单中出现了几位未参与前两代版本（Prover-V1、Prover-V1.5）的研究者。\n比如Shirong Ma，清华本硕。公开资料显示，他于去年毕业后即加入DeepSeek，现为DeepSeek研究员，此前参与了从DeepSeek LLM v1到R1以及DeepSeek-Coder等工作。\n还有Zhe Fu、Yuxuan Liu。\n虽然他们都没出现在Prover-V1、Prover-V1.5的作者名单中，但均为DeepSeek资深成员。\n在Prover-V1/V1.5同一期发布的《Fire-Flyer AI-HPC》研究中可见其署名。\n该研究提出的Fire-Flyer AI-HPC架构，通过软硬件协同设计降低训练成本，解决传统超算架构在AI训练需求上的不足。\n不过这次Prover-V2的论文中并未提及在训练或推理基础设施具体有哪些优化策略。\n最后还有一位新面孔Hongxuan Tang，暂未了解到具体信息。\nProver-V2发布后迅速引发社区关注，GitHub仓库12小时内即获得350+星标。\n在X（原Twitter）、抱抱脸等平台，网友们展开热烈讨论。\nProver-V2核心贡献者邵智宏在个人账号主动推介研究成果。\nX工程师@kache特别赞赏道：\n感谢你们对开放科学研究的奉献。\n普林斯顿大学助理教授Chi Jin表示：\n恭喜这项惊人的工作！在miniF2F上攻克最后10%-20%的问题标志着能力上的重大飞跃。当前形式化数学领域的竞争态势堪称激烈，难以置信Kimina仅保持了两周SOTA就被DeepSeek超越。\n就连Kimina-Prover核心贡献者@Marco Dos Santos都来送上了祝贺：\n祝贺DeepSeek AI团队将miniF2F任务的SOTA提升到了89%！\n很高兴看到长思维链方法正在被其他团队独立探索且呈现出一些有趣的差异。形式数学如今比以往任何时候都更受欢迎！\n另外，网友们最关注的问题仍然是：R2什么时候发布啊～\n论文：\nhttps://github.com/deepseek-ai/DeepSeek-Prover-V2/blob/main/DeepSeek_Prover_V2.pdf\n模型：\nhttps://huggingface.co/deepseek-ai/DeepSeek-Prover-V2-671B\nDeepSeek-Prover\nhttps://arxiv.org/abs/2405.14333\nDeepSeek-Prover-V1.5\nhttps://arxiv.org/abs/2408.08152\n- 自动化所：基于科学基础大模型的智能科研平台ScienceOne正式发布2025-04-30\n- 小扎回应Llama4对比DeepSeek：榜单有缺陷，等推理模型出来再比2025-04-30\n- 蚂蚁数科发布智能体开发平台Agentar 金融机构可“零代码”搭建专业智能体应用2025-04-29\n- RAG性能暴增20%！清华等推出以笔记为中心的深度检索增强生成框架2025-04-29'}, 'https://www.qbitai.com/2025/05/279354.html': {'title': '一次示范就能终身掌握！让手机AI轻松搞定复杂操作丨浙大&vivo出品', 'url': 'https://www.qbitai.com/2025/05/279354.html', 'date': '2025-05-01', 'content': '一次示范就能终身掌握！让手机AI轻松搞定复杂操作丨浙大&vivo出品\n步发布的LearnGUI基准，首次构建了面向移动端示范学习的评估体系\nLearnAct团队投稿\n量子位 | 公众号 QbitAI\n想让手机AI像人类一样快速学习？\n浙大与vivo联手突破！全新LearnAct框架仅需一次示范，就能教会AI完成复杂操作。\n研究同步发布的LearnGUI基准，首次构建了面向移动端示范学习的评估体系，为AI智能体的实用化部署提供了关键技术支撑。\n本文的作者来自浙江大学和vivo AI lab。本文的共同第一作者为浙江大学硕士生刘广义和赵鹏翔，主要研究方向为大语言模型驱动的GUI智能体技术。项目leader 为vivo AI lab 算法专家刘亮。本文的通信作者为浙江大学孟文超研究员。\n手机GUI智能体：潜力与挑战并存\n随着大型语言模型（LLMs）的快速发展，手机图形用户界面（GUI）智能体作为一种能够通过环境交互自主完成人类任务的前沿技术，正逐渐引发人们的关注。这些智能体通过观察手机屏幕（截图或UI Tree）感知手机状态，并生成相应的动作（如点击、输入、滑动等）来实现任务自动化。\n然而，手机GUI智能体在实际部署场景中仍面临重大挑战。\n移动应用和用户界面的多样性创造了许多长尾场景，截至2025年仅Google Play上就有168万个应用，现有智能体在长尾场景中难以有效执行任务。\n目前主流的智能体构建方法依赖通用LLMs的内在能力或通过大量数据微调，但面对以数百万的移动应用及数十亿用户各自独特的任务需求，这些方法难以覆盖如此庞大的多样性，导致在未见场景中表现不佳，阻碍了手机GUI智能体的广泛应用。\n从「示范中学习」的新范式\n为解决上述限制，浙江大学和vivo AI lab联合提出了LearnAct多智能体框架和LearnGUI基准致力于通过「少样本示范学习」解决手机GUI智能体的「长尾问题」。\n与传统方法不同，这种基于示范的方法能够在少量用户提供的示例基础上实现稳健性和个性化，从而弥合预训练模型无法覆盖的“个性化鸿沟”。\n实现结果表明，单个示范就能使Gemini-1.5-Pro的准确率从19.3%提升至51.7%，UI-TARS-7B-SFT的在线任务成功率从18.1%提升至32.8%。LearnAct多智能体框架和LearnGUI基准的提出为设计更加智能、更加个性化的手机 GUI 智能体开辟全新的方向，让我们的手机操作变得更加便捷、高效。\n研究团队认识到，手机用户通常有独特且重复性的任务，同时具有内在变化性——例如智能家居控制、健康监测或企业软件。\n这些场景结合了稳定模式和可变元素，通过用户特定的示范，该方法使智能体能够学习一致模式和适应策略，获取一般训练数据集无法覆盖的任务特定知识。\nLearnGUI：首个专为研究示范学习设计的基准\n为填补高质量示范数据的空白，研究团队构建了LearnGUI基准。\n这是首个专为研究移动 GUI 代理从少量示范中学习能力而设计的基准。基于AMEX和AndroidWorld构建，LearnGUI 包含 2,252 个离线少样本任务和 101 个在线任务，均附带高质量人类示范。\n该基准不仅支持对不同数量示范对代理性能影响的研究，还系统分析了示范任务与目标任务之间不同类型相似性（指令相似性、UI 相似性和动作相似性）对学习效果的影响。\nLearnAct：多智能体框架自动理解和利用示范\n研究团队进一步提出了LearnAct多智能体框架，能够自动理解人类示范、生成指导性知识，并使用这些知识帮助手机GUI智能体推理未见场景。LearnAct由DemoParser、KnowSeeker和ActExecutor三个专业智能体组成。\nDemoParser智能体将原始的人类示范转化为结构化的示范知识。\n它以原始动作序列（包括基于坐标的点击、滑动和文本输入等）以及相应的屏幕截图和任务指令作为输入。\n随后，它利用视觉-语言模型生成具有语义描述性的动作描述，捕捉每个演示步骤的本质（例如，“在搜索页面上，点击搜索框，输入关键词”）。\n基于这些描述，它构建了一个结构化的知识库，记录了高层次的动作语义。\nKnowSeeker智能体是LearnAct框架中的检索组件，负责识别与当前任务上下文最相关的演示知识。\nKnowSeeker充当由DemoParser生成的知识库与ActExecutor执行环境之间的桥梁，专精于高效地访问和选择针对特定任务最适用的知识。\nActExecutor智能体是LearnAct框架中的执行组件，它将检索到的演示知识转化为目标环境中有效的操作。\nActExecutor是LearnAct流程的最终环节，它整合了用户指令、实时的图形用户界面感知信息以及演示知识，能够熟练的操作长尾场景下的手机界面。\n当DemoParser创建结构化知识，而KnowSeeker检索到相关的演示后，ActExecutor则运用这些知识来解决实际任务。\n这种多智能体架构使LearnAct能够系统地从人类示范中提取、检索和利用知识，通过最少的示范实现对新场景的有效适应。\n实验结果：示范学习显著提升性能\n实验结果揭示了示范学习对手机GUI智能体能力的显著增强。\n在离线评估中，单个示范就能大幅提升模型性能，最引人注目的是Gemini-1.5-Pro的准确率从19.3%提升至51.7%（相对提升198.9%）。\n在复杂应用如CityMapper和To-Do应用中，性能提升尤为明显，分别从14.1%提升至69.4%和从17.4%提升至69.2%。\n在真实世界的在线评估中，LearnAct框架表现出色。\n下表展示了在LearnGUI-Online基准上的在线评估结果，LearnAct 框架显著提升了所评估的两种模型的性能，其中 Qwen2-VL-7B从 9.9% 提升至 21.1%（+11.2%），UI-TARS-7B-SFT从 18.1% 提升至 32.8%（+14.7%）。\n这些显著的提升表明，基于示范的学习方法能够有效地转化为现实交互场景中的优势。\n下图中给出了LearnAct和Baseline方法在ExpenseDeleteMultiple任务上的表现。\n在这样的长尾场景下，Baseline方法中GUI 智能体无法正确规划任务执行路径最终以失败告终。\n相比之下只需要给出一个演示案例，LearnAct框架就能自动识别ExpenseDeleteMultiple任务中的执行模式并进行学习，面对相似的任务与不同的UI界面，顺利完成了操作任务。\n结论：示范学习引领手机GUI智能体发展新方向\n这项研究提出的基于示范学习的新范式，为应对手机GUI智能体的长尾挑战开辟了新路径。\n作为首个全面的示范学习研究基准，LearnGUI与LearnAct多智能体框架，有力证明了示范学习在开发更具适应性、个性化和实用性的手机GUI智能体方面的巨大潜力。\n随着移动设备在现代生活中的广泛应用，这种能够从少量示范中高效学习的方法，为打造真正智能的手机助手奠定了坚实基础，让我们在现实世界中距离科幻电影中“J.A.R.V.I.S.”般的智能体验更近一步。\n论文地址：\nhttps://arxiv.org/abs/2504.13805\n项目地址：\nhttps://lgy0404.github.io/LearnAct/\nGitHub：\nhttps://github.com/lgy0404/LearnAct\nHuggingFace：\nhttps://huggingface.co/datasets/lgy0404/LearnGUI\n- 又一开源AI神器！将机器学习论文自动转为可运行代码库2025-05-01\n- AI卧底美国贴吧4个月“洗脑”100+用户无人察觉，苏黎世大学秘密实验引争议，马斯克惊呼2025-04-30\n- 全网首测！Qwen3 vs Deepseek-R1数据分析哪家强？2025-04-30\n- 无问芯穹夏立雪：让算力像水电煤一样成为标准化、高附加值的“拎包入住”基础设施｜中国AIGC产业峰会2025-04-29'}, 'https://www.qbitai.com/2025/05/279082.html': {'title': '当购物用上大模型！阿里妈妈首发世界知识大模型，破解推荐难题', 'url': 'https://www.qbitai.com/2025/05/279082.html', 'date': '2025-05-01', 'content': '当购物用上大模型！阿里妈妈首发世界知识大模型，破解推荐难题\n在商家的投放效果和消费者的购物体验等指标上均带来了显著提升。\n允中 发自 凹非寺\n量子位 | 公众号 QbitAI\n在推荐、广告场景，如何利用好大模型的能力？这是个很有挑战的命题。\n背后主要有两个核心难点：\n1）LLM虽然具备丰富的世界知识和推理能力，但缺乏电商领域的专业知识，在直接应用中往往表现欠佳。\n2）LLM的交互方式多为文本，而直接将用户历史行为以文本格式描述会导致输入信息冗长、信息密度低等问题，对建模和推理都造成了困扰。\n为了解决以上问题，阿里妈妈提出了一种世界知识大模型URM，通过知识注入和信息对齐，让LLM成为兼顾世界知识和电商知识的专家。相比于传统的推荐模型，URM通过对用户兴趣的全面理解，可实现基于推理认知能力的用户兴趣推荐。\n为了在低时延、高QPS要求的实际系统中上线应用，阿里妈妈技术团队设计了一套面向用户行为动态捕捉的异步推理链路。\n目前，URM已经在阿里妈妈展示广告场景上线，在商家的投放效果和消费者的购物体验等指标上均带来了显著提升。\n以下面这个例子为例，一个对嵌入式家电、收纳用品有过历史行为的用户，系统推测用户在关注装修且处于硬装的早期阶段，且根据点击商品推断用户比较注重生活品质，因此推荐了一些全屋定制类产品以及高品质的家电。\n在传统推荐任务之外，通过特定的文字引导，URM可结合用户的历史兴趣产出更适合当前情境的结果。通过用户行为我们推测用户是一位男童的母亲，并且关注过儿童的新年衣服和女士牛仔裤。\n当引导词增加新年时，推荐结果以儿童新年服装为主，而传统任务下系统会倾向于推荐用户近期浏览较多的女式牛仔裤。\n本届互联网技术领域国际顶级学术会议-国际万维网大会（International World Wide Web Conference,简称WWW）于4月28日在悉尼召开。\n会议期间，淘天集团的阿里妈妈共同主持一个计算广告算法技术相关的Tutorial（讲座），内容为介绍计算广告领域的技术发展脉络，以及阿里妈妈在该领域的最新技术突破——\n阿里妈妈LMA2广告大模型系列中的URM（Universal Recommendation Model）世界知识大模型，首次重磅亮相。\n世界知识大模型URM\n个性化推荐在人们的日常生活中出现频率越来越高。为了满足用户的多样化需求，推荐系统中的任务定义也更加多元化，如多场景推荐、多目标推荐、发现性推荐等等。\n参考LLM在自然语言处理领域的巨大成功，阿里妈妈技术团队希望基于LLM构建电商领域的世界知识大模型，使得它能同时具备LLM的世界知识和电商领域的专业知识，且能够轻松应对上述全部任务。\n基于此，阿里妈妈技术团队提出了世界知识大模型Universal Recommendation Model（以下称URM），以预训练的LLM为基座，将多任务设计融入Prompt设计中，通过ID表征的知识注入和电商领域的任务对齐，实现对用户历史兴趣的理解和推理并最终推荐出符合用户兴趣的结果。\n以下将从任务定义、整体架构、离线实验三方面详细展开。\n任务定义\n参考LLM的训练范式，在URM中，阿里妈妈技术团队利用文本来定义不同的推荐任务。\n考虑到推荐场景用户行为的重要性和丰富性，为了充分刻画用户的历史行为，避免商品标题的冗长和低密度，URM将商品ID作为一种特殊的token注入文本描述，实现用户行为序列的高效表达。\n考虑到工业场景落地的效率，URM直接生成商品ID，同时在输出结果中保留了文本，在对齐电商任务的同时保留LLM本身的知识。\n多任务会通过输入中的任务描述体现，部分示例参考下表。\n整体架构\n为了保留LLM的预训练知识，阿里妈妈技术团队保留多层Transformer结构不变，对输入层和输出层的结构进行修改，如下图所示。\n输入端，输入序列由用户行为中的商品ID、任务提示中的文本token以及[UM]、[LM]等特定查询符组成。商品ID通过分布式商品Embedding模块映射为商品Embedding，其他文本映射为Token Embedding，商品 Embedding或Token Embedding与Postion Embedding相加后输入到 LLM的主干网络（对于使用RoPE的模型而言则不存在显式的Position Embedding）。\n输出端，为了避免产出推荐结果和推理文本相互干扰，阿里妈妈技术团队在输入中增加了[UM]和[LM] 2种特殊字符来表示当前应该输出用户表征还是开始生成文本。与[UM]符号对应的输出通过用户建模头hUM映射到用户表示空间，用于候选商品的生成；与[LM]符号及其后续符号对应的输出通过语言模型头hLM映射到文本空间，用于文本token的生成。\n△URM整体架构\nURM架构区别于传统LLM主要有2个模块，1是商品多模态融合的表征方式，2是兼顾效果和效率的Sequence-In-Set-Out生成方式。\n以下会分别介绍这两部分。最后介绍URM的训练方式。\n商品多模态融合表征。\n在传统推荐模型中，ID表征是面向特定任务的数据分布学习的，代表了商品间的相似关系，压缩了电商领域的协同信息。而LLM中通常采用文本、图像等语义表征，描述内容信息间的相似性。\n为了提升LLM对电商信号的理解，同时保留LLM的知识，表征层设计了 ID表征和语义表征的融合模块来表达商品，并通过可学习MLP层实现ID 表征和文本、图像等语义表征的对齐。\n同时，这套融合表征的设计具备较强的可扩展性，如语义ID等token均可作为新增模态引入，来不断强化商品的表达能力。\n△商品融合表征，输入ID/Text/Image表征固定，MLP层可学习\nSeqence-In-Set-Out生成方式\n推荐的目标是从一个千万级别的候选库中找到曝光/点击概率最大的K个商品，它和语言模型LM从十万规模的词表空间中生成语言概率最大的 Token，是类似的问题。\n因此若不考虑计算成本，可以通过下述方式获得结果：\n其中U是大语言模型生成的用户表征，对应LM中的隐藏层特征，W是所有商品的融合表征，对应LLM中的最后一层的参数。考虑到工业界的落地可行性，阿里妈妈技术团队使用生成的用户表征和候选商品表征的内积作为分数并采样分数TopK的商品作为最终生成的结果。\n在这种内积计算的范式下，模型的表达能力相对受限，对用户和商品的建模能力较差且推荐集合的多样性也会较差，难以发挥大语言模型的优势。函数逼近理论的一个结论是，特征的多个内积的线性组合可以逼近任意复杂的函数。因此通过增加[UM]token的数量使URM在一次前向过程中并行生成多个用户表征U=（U1，……，UH），最终用户和商品之间的打分为\n这种Set-Out的多输出方式不仅能够保持仅需一次前向计算的相同推理效率，而且随token数上涨召回指标显著提升，同时解决了单一用户表征兴趣覆盖度有限的问题。\n△不同[UM] Token输出的可视化\n训练方式\n整体训练损失包括商品推荐任务损失和文本生成任务损失。\n输出序列表示为\n目标文本表示为\n目标商品表示为\n商品推荐任务通过噪声对比估计（NCE）损失来优化：\n其中用户建模头hUM输出的用户表征：\n在每个批次中，负样本N是从商品候选中基于其出现频率采样得到的。\n文本生成任务可以通过目标文本序列的负对数似然来优化：\n其中P= softmax(hLM (ψ(⋅))是由语言模型头hLM输出的概率。\n最终的训练目标是：\n其中η是权衡超参数。考虑到URM对LLM的输入和输出层进行了显著修改，阿里妈妈技术团队采用完整参数的有监督微调（SFT），仅冻结商品的原始表征。\n离线实验\nURM使用多任务融合数据集训练，并在生产数据集上取得了平均11.0%的Recall提升，在6个子任务（共9个任务）中都超越了线上使用 Target-Attention结构的传统推荐模型。\n△URM在多任务上的表现 vs 传统模型\n进一步的消融实验，验证了表征融合模块的有效性，也验证了随UM token数量上涨召回Recall呈显著上涨。Figure6验证了URM仍具有良好的文本理解能力和泛化能力，对已知的query文本和未知的query都有良好的推荐表现。\n△商品多模态表征融合模块消融实验\n△UM头输出数量对效果的影响\n高QPS低时延约束下的落地方案\n考虑到LLM的推理时延较长，无法满足在线请求的时延约束，阿里妈妈技术团队建设了一套异步推理的大模型召回链路。\n如下图所示，在用户有淘系行为时异步触发URM推理，并将结果做持久化存储，供在线召回阶段读取使用。\n在模型推理服务上，由于URM在商品多模态融合表征模块和User表征检索方式的改造，需要在LLM推理中增加HashTable支持，并支持推理表征的向量检索。\n为了进一步提升资源利用率，阿里妈妈技术团队实现了多instance在同一容器的部署，将URM推理的并发qps提升200%。\n结语\n本文主要介绍了阿里妈妈LMA 2广告大模型系列中的世界知识大模型URM在建模和落地方面的思考和进展。通过结合大模型的通用知识和电商领域的专家知识，URM能够更加精准地预测用户的潜在兴趣和购物需求，为商家和消费者提供更优质的服务。\n更多URM的细节欢迎关注后续“阿里妈妈技术”的公众号文章或参考论文。\n论文链接：\nhttps://arxiv.org/pdf/2502.03041\n- 人人可用的超级智能体！100+MCP工具随便选，爬虫小红书效果惊艳2025-04-29\n- OceanBase全员信：全面拥抱AI，打造AI时代的数据底座2025-04-27\n- 网易有道张艺：AI教育的规模化落地，以C端应用反推大模型发展2025-04-27\n- 英伟达H20不让用？全国产算力推理模型升级，4张华为卡即可部署2025-04-22'}, 'https://www.qbitai.com/2025/04/279194.html': {'title': '全球第一车企，集齐中美双版Waymo', 'url': 'https://www.qbitai.com/2025/04/279194.html', 'date': '2025-04-30', 'content': '全球第一车企，集齐中美双版Waymo\n「中国Waymo」量产Robotaxi刚刚亮相上海车展\n贾浩楠 发自 副驾寺\n智能车参考 | 公众号 AI4Auto\n全球最大车企丰田，刚刚官宣了和全球自动驾驶“先驱”Waymo的合作意向。\n算起来这已经是丰田在L4赛道一周之内的第二次出手了。\n就在丰田和Waymo达成意向的100多个小时前，它和「中国Waymo」——小马智行合作的最新一代Robotaxi量产车亮相，量产在即。\n种种迹象表明，Robotaxi的iPhone时刻正在来临。\n丰田官宣“牵手”Waymo\n丰田和Waymo的这次官宣挺有意思。\n一般都是确定合作的范围、形式，协议签署后才正式官宣。但这次双方显得好像比较仓促。\n双方都明确定义为“潜在合作”，目前状态是“达成初步协议”。\n可以看出Waymo对这次合作的定性表述更模糊，明显对未来的期待更多：\n双方将合作开发新的自动驾驶平台，但未来合作范围将通过持续的讨论不断演变。\n上周谷歌母公司Alphabet在第一季度财报会议上说的话，揭示了丰田和Waymo合作状态的背景。\n官方认为“Waymo尚未完全确定其长期商业模式”，而未来不排除“将Waymo自动驾驶技术引入私家车”。\nWaymo朝商业化落地的目标的努力，今年开始频繁起来。比如之前Waymo负责Robotaxi的各个层面，包括技术、应用程序、维护和叫车运营等等。\n而最近，Waymo尝试在不同地区合作不同网约车平台或出租车公司，把Robotaxi运营业务外包…\nL4技术下放量产车，官方是第一次明确表态，与丰田的搭上线也是Waymo向这一目标迈出的第一步。\n毕竟Waymo眼下不缺前装量产Robotaxi，比如和极氪合作的“宝宝巴士”原型车。但极氪已经走在了智能化自研道路上。\n相比之下，丰田对这次与Waymo的合作表态就淡定得多：\n丰田致力于实现零交通事故社会，成为一家为所有人提供出行服务的出行公司，我们与Waymo有着共同的目标和愿景。\n哪个自动驾驶玩家的愿景不是这样呢？\n那些年，丰田押注过的自动驾驶公司\n对于电动车，丰田一直颇有微词，但对自动驾驶的价值前景，丰田从来没有过怀疑，甚至是最早开始押注投资的主机厂。\n早在2016年，丰田就首次对Uber投资5亿美元，成为其股东之一，双方在网约车服务和自动驾驶技术领域展开初步合作。\n丰田获得的回报，是Uber承诺将自动驾驶算法整合到丰田车型中，并且按照丰田要求调整硬件方案。\n后续，丰田联合软银再向Uber注资10亿美元，同时通过和软银的合资公司Monet在日本落地Robotaxi服务。\n但2018年Uber在亚利桑那州的自动驾驶测试车出现严重事故后，出于安全考虑Uber暂停了在北美的公共道路测试。\n这一暂停，却是永不相见。后面丰田频繁与各个技术公司开展自动驾驶合作，但再未提及Uber。\n2020年，Uber出售了自家自动驾驶部门，接手的是Uber、Waymo元老创办的Aurora。丰田也迅速和Aurora达成协议，一同开发L4自动驾驶平台。\n一开始的计划是把Aurora系统集成到塞那车型上，2022年在得州启动路测。但此时，Waymo已经在凤凰城推出限定区域的无人驾驶服务，Aurora的Robotaxi开局就面临技术验证与规模化压力。\n后续Aurora宣布将自己的业务重心转移到自动驾驶卡车赛道，今年一月份宣布接入英伟达DRIVE平台，计划2027年实现L4级卡车量产。\n而和丰田合作Robotaxi项目消息，2022年之后就再没有过更新。\n这几年间，丰田旗下基金Woven Capital还投资过朱家俊的Nuro、丰田自家研究院老同事创办的May Mobility等等。\n但这些玩家集中在低速、封闭场景，Robotaxi的积累和实力明显不足。\n可以说，丰田押注自动驾驶赛道，瞄准的是“皇冠上的明珠”——Robotaxi，技术难度最高但潜力也最大。但兜兜转转近十年下来，或因时局或因意外，少有积极正向的结果反馈。\n只有一个例外，那就是有“中国版Waymo”之称的小马智行。\n2019年8月，丰田与小马智行宣布建立战略合作伙伴关系，共同开发面向移动出行服务的自动驾驶车辆。双方首次采用丰田雷克萨斯RX车型与小马智行的自动驾驶系统，在中国公开道路开展测试项目。\n后续又有了资本绑定。2020年2月，丰田领投小马智行B轮融资，金额达4.62亿美元，成为其最大单轮产业投资者。\n2023年4月，搭载小马智行第六代L4自动驾驶软硬件系统的丰田赛那Autono-MaaS车辆在北京和广州启动公开道路测试，并于同年正式开展车内无人出行服务商业化试点，不仅验证了其车辆在复杂城市环境中的可靠性，也标志着自动驾驶产业正式进入造血阶段。\n同年8月，丰田中国、广汽丰田与小马智行宣布共同投资超10亿元成立合资公司“骓丰智能科技”，推动L4级Robotaxi前装量产。其中广汽丰田负责生产车辆平台，丰田提供冗余系统设计，小马智行负责自动驾驶系统与运营平台。\n这也是中国自动驾驶玩家探索，并被全行业模仿复刻的Robotaxi落地模式。\n在此期间，小马智行还在北京、上海、广州、深圳四大一线城市全部获得全无人驾驶测试与运营许可，4500万公里，每辆全无人Robotaxi日均订单量超15单……\n还在进行中的上海车展上，小马智行首次对外官宣了自己的Robotaxi量产项目——昆仑计划，在第七代自动驾驶软硬件系统套件上采用100%车规级零部件，设计寿命长达10年60万公里，并且采用平台化设计，具有极强的跨车辆跨车型的适配能力。\n小马智行也对外一次性发布了三款昆仑计划的Robotaxi车型，其中，丰田铂智4X是首位家族成员。\n从L4商业模型成立的角度出发，小马智行经过实践测算得出，1000辆左右车队规模，每车每天15单左右，就能支持Robotaxi的持续运营。\n而就在丰田官宣合作Waymo的前100小时左右，小马智行与丰田的第七代Robotaxi已在广汽丰田南沙工厂启动量产，2025年起计划部署规模突破千台。\n所以对于丰田来说，小马智行仍然是迄今为止在L4、Robotaxi赛道上唯一成功，且有规模，距离商业落地“最后一公里”的伙伴和案例。\n如何看待丰田此时提速Robotaxi？\n主观上，丰田需要在全球范围内不断寻找优质的合作伙伴。\n如果说小马智行是丰田对中国优秀自动驾驶标的投资，那么Waymo也一样，是丰田对北美优秀自动驾驶标的押注。\n甚至对于丰田这样的全球No.1主机厂来说，曲折反复这么多年才与Waymo建立合作关系，反而是一件令人诧异的事。\n当然，如果对Robotaxi的全球布局和竞争提速有关注，或许就更容易感知作为前沿黑科技，在地域和地缘环境下的挑战。\n换句话来说，丰田应该是在中国看到了Robotaxi规模化商用时刻正在到来，才如此紧迫地在美国落子布局。\n并且选择的也不是别人，正是Waymo——集齐了中国版Waymo和美国Waymo。\n除了Robotaxi，L4级自动驾驶技术带来的成果和双赢，实际也被丰田和小马智行在上海车展作出了宣示，双方在最大的出行市场——中国，展现出了不可替代性。\n首先是技术层面，中国复杂场景，对于任何自动驾驶玩家来说，都是不可替代的数据宝藏。\n其次是小马智行已经在这个场景最丰富、挑战最复杂、供应链最成熟的中国，巩固了自己的L4实力地位。\n第七代Robotaxi车型不光有丰田，还有和广汽、北汽合作的车型，而小马智行已经实现自动驾驶套件成本较前代下降70%，并实现前装量产（产线预装70%-80%的自动驾驶硬件）。\n尤其是自动驾驶核心部件（如激光雷达、计算单元）通过车规级认证。小马向我们透露，全车100%车规Robotaxi，目前是行业唯一。\n运营层面，北上广深全无人牌照全覆盖，2024年每辆车的日均订单量达到了15单，随着运营范围扩大，商业化运营增速明显提高，验证Robotaxi是真实出行需求而非技术尝鲜。\n第三个“不可替代”，是小马和丰田开创的车企新合资模式，以及由此而生的三角生态：车辆平台（丰田）+技术方案（小马）+运营服务（骓丰科技）。\n对于丰田来说，和小马智行合作，是技术反哺、商业变现的主体。小马智行已验证的商业模式+量产能力，是支撑丰田“智慧出行科技公司”转型的重要一环。\n丰田也在合作中，从有钱不知道怎么投的Robotaxi门外汉，到逐渐熟悉L4技术、商业命门，积累L4闭环流程经验，为如今和Waymo的合作提供了样板。\n这又怎么不算是中国自动驾驶玩家的标准、模式输出呢？\n从加州101公路到广州天河CBD，挂丰田标的Robotaxi背后，站着两个时代的影子：一个是硅谷的技术理想，一个是中国技术的商业领跑。\nRobotaxi的iPhone时刻正在来临，丰田不算“起个大早”，但在最关键的转折点，同时布局完成了中美“双版Waymo”。\n- 14.9万元，满血流畅运行DeepSeek一体机抱回家！清华90后初创出品2025-04-29\n- 全栈AI基础设施支撑，跑出全球首个开放使用视频生成DiT模型2025-04-28\n- 亚马逊云计算Troy Cui：敦煌网飙升AppStore第二，企业如何应对激增流量是关键 | 中国AIGC产业峰会2025-04-27\n- 智能车速度刷新：仅10个月，首个纯端侧大模型上车量产！2025-04-24'}, 'https://www.qbitai.com/2025/04/279173.html': {'title': '全球第一车企，集齐中美双版Waymo', 'url': 'https://www.qbitai.com/2025/04/279173.html', 'date': '2025-04-30', 'content': '全球第一车企，集齐中美双版Waymo\n「中国Waymo」量产Robotaxi刚刚亮相上海车展\n贾浩楠 发自 副驾寺\n智能车参考 | 公众号 AI4Auto\n全球最大车企丰田，刚刚官宣了和全球自动驾驶“先驱”Waymo的合作意向。\n算起来这已经是丰田在L4赛道一周之内的第二次出手了。\n就在丰田和Waymo达成意向的100多个小时前，它和「中国Waymo」——小马智行合作的最新一代Robotaxi量产车亮相，量产在即。\n种种迹象表明，Robotaxi的iPhone时刻正在来临。\n丰田官宣“牵手”Waymo\n丰田和Waymo的这次官宣挺有意思。\n一般都是确定合作的范围、形式，协议签署后才正式官宣。但这次双方显得好像比较仓促。\n双方都明确定义为“潜在合作”，目前状态是“达成初步协议”。\n可以看出Waymo对这次合作的定性表述更模糊，明显对未来的期待更多：\n双方将合作开发新的自动驾驶平台，但未来合作范围将通过持续的讨论不断演变。\n上周谷歌母公司Alphabet在第一季度财报会议上说的话，揭示了丰田和Waymo合作状态的背景。\n官方认为“Waymo尚未完全确定其长期商业模式”，而未来不排除“将Waymo自动驾驶技术引入私家车”。\nWaymo朝商业化落地的目标的努力，今年开始频繁起来。比如之前Waymo负责Robotaxi的各个层面，包括技术、应用程序、维护和叫车运营等等。\n而最近，Waymo尝试在不同地区合作不同网约车平台或出租车公司，把Robotaxi运营业务外包…\nL4技术下放量产车，官方是第一次明确表态，与丰田的搭上线也是Waymo向这一目标迈出的第一步。\n毕竟Waymo眼下不缺前装量产Robotaxi，比如和极氪合作的“宝宝巴士”原型车。但极氪已经走在了智能化自研道路上。\n相比之下，丰田对这次与Waymo的合作表态就淡定得多：\n丰田致力于实现零交通事故社会，成为一家为所有人提供出行服务的出行公司，我们与Waymo有着共同的目标和愿景。\n哪个自动驾驶玩家的愿景不是这样呢？\n那些年，丰田押注过的自动驾驶公司\n对于电动车，丰田一直颇有微词，但对自动驾驶的价值前景，丰田从来没有过怀疑，甚至是最早开始押注投资的主机厂。\n早在2016年，丰田就首次对Uber投资5亿美元，成为其股东之一，双方在网约车服务和自动驾驶技术领域展开初步合作。\n丰田获得的回报，是Uber承诺将自动驾驶算法整合到丰田车型中，并且按照丰田要求调整硬件方案。\n后续，丰田联合软银再向Uber注资10亿美元，同时通过和软银的合资公司Monet在日本落地Robotaxi服务。\n但2018年Uber在亚利桑那州的自动驾驶测试车出现严重事故后，出于安全考虑Uber暂停了在北美的公共道路测试。\n这一暂停，却是永不相见。后面丰田频繁与各个技术公司开展自动驾驶合作，但再未提及Uber。\n2020年，Uber出售了自家自动驾驶部门，接手的是Uber、Waymo元老创办的Aurora。丰田也迅速和Aurora达成协议，一同开发L4自动驾驶平台。\n一开始的计划是把Aurora系统集成到塞那车型上，2022年在得州启动路测。但此时，Waymo已经在凤凰城推出限定区域的无人驾驶服务，Aurora的Robotaxi开局就面临技术验证与规模化压力。\n后续Aurora宣布将自己的业务重心转移到自动驾驶卡车赛道，今年一月份宣布接入英伟达DRIVE平台，计划2027年实现L4级卡车量产。\n而和丰田合作Robotaxi项目消息，2022年之后就再没有过更新。\n这几年间，丰田旗下基金Woven Capital还投资过朱家俊的Nuro、丰田自家研究院老同事创办的May Mobility等等。\n但这些玩家集中在低速、封闭场景，Robotaxi的积累和实力明显不足。\n可以说，丰田押注自动驾驶赛道，瞄准的是“皇冠上的明珠”——Robotaxi，技术难度最高但潜力也最大。但兜兜转转近十年下来，或因时局或因意外，少有积极正向的结果反馈。\n只有一个例外，那就是有“中国版Waymo”之称的小马智行。\n2019年8月，丰田与小马智行宣布建立战略合作伙伴关系，共同开发面向移动出行服务的自动驾驶车辆。双方首次采用丰田雷克萨斯RX车型与小马智行的自动驾驶系统，在中国公开道路开展测试项目。\n后续又有了资本绑定。2020年2月，丰田领投小马智行B轮融资，金额达4.62亿美元，成为其最大单轮产业投资者。\n2023年4月，搭载小马智行第六代L4自动驾驶软硬件系统的丰田赛那Autono-MaaS车辆在北京和广州启动公开道路测试，并于同年正式开展车内无人出行服务商业化试点，不仅验证了其车辆在复杂城市环境中的可靠性，也标志着自动驾驶产业正式进入造血阶段。\n同年8月，丰田中国、广汽丰田与小马智行宣布共同投资超10亿元成立合资公司“骓丰智能科技”，推动L4级Robotaxi前装量产。其中广汽丰田负责生产车辆平台，丰田提供冗余系统设计，小马智行负责自动驾驶系统与运营平台。\n这也是中国自动驾驶玩家探索，并被全行业模仿复刻的Robotaxi落地模式。\n在此期间，小马智行还在北京、上海、广州、深圳四大一线城市全部获得全无人驾驶测试与运营许可，4500万公里，每辆全无人Robotaxi日均订单量超15单……\n还在进行中的上海车展上，小马智行首次对外官宣了自己的Robotaxi量产项目——昆仑计划，在第七代自动驾驶软硬件系统套件上采用100%车规级零部件，设计寿命长达10年60万公里，并且采用平台化设计，具有极强的跨车辆跨车型的适配能力。\n小马智行也对外一次性发布了三款昆仑计划的Robotaxi车型，其中，丰田铂智4X是首位家族成员。\n从L4商业模型成立的角度出发，小马智行经过实践测算得出，1000辆左右车队规模，每车每天15单左右，就能支持Robotaxi的持续运营。\n而就在丰田官宣合作Waymo的前100小时左右，小马智行与丰田的第七代Robotaxi已在广汽丰田南沙工厂启动量产，2025年起计划部署规模突破千台。\n所以对于丰田来说，小马智行仍然是迄今为止在L4、Robotaxi赛道上唯一成功，且有规模，距离商业落地“最后一公里”的伙伴和案例。\n如何看待丰田此时提速Robotaxi？\n主观上，丰田需要在全球范围内不断寻找优质的合作伙伴。\n如果说小马智行是丰田对中国优秀自动驾驶标的投资，那么Waymo也一样，是丰田对北美优秀自动驾驶标的押注。\n甚至对于丰田这样的全球No.1主机厂来说，曲折反复这么多年才与Waymo建立合作关系，反而是一件令人诧异的事。\n当然，如果对Robotaxi的全球布局和竞争提速有关注，或许就更容易感知作为前沿黑科技，在地域和地缘环境下的挑战。\n换句话来说，丰田应该是在中国看到了Robotaxi规模化商用时刻正在到来，才如此紧迫地在美国落子布局。\n并且选择的也不是别人，正是Waymo——集齐了中国版Waymo和美国Waymo。\n除了Robotaxi，L4级自动驾驶技术带来的成果和双赢，实际也被丰田和小马智行在上海车展作出了宣示，双方在最大的出行市场——中国，展现出了不可替代性。\n首先是技术层面，中国复杂场景，对于任何自动驾驶玩家来说，都是不可替代的数据宝藏。\n其次是小马智行已经在这个场景最丰富、挑战最复杂、供应链最成熟的中国，巩固了自己的L4实力地位。\n第七代Robotaxi车型不光有丰田，还有和广汽、北汽合作的车型，而小马智行已经实现自动驾驶套件成本较前代下降70%，并实现前装量产（产线预装70%-80%的自动驾驶硬件）。\n尤其是自动驾驶核心部件（如激光雷达、计算单元）通过车规级认证。小马向我们透露，全车100%车规Robotaxi，目前是行业唯一。\n运营层面，北上广深全无人牌照全覆盖，2024年每辆车的日均订单量达到了15单，随着运营范围扩大，商业化运营增速明显提高，验证Robotaxi是真实出行需求而非技术尝鲜。\n第三个“不可替代”，是小马和丰田开创的车企新合资模式，以及由此而生的三角生态：车辆平台（丰田）+技术方案（小马）+运营服务（骓丰科技）。\n对于丰田来说，和小马智行合作，是技术反哺、商业变现的主体。小马智行已验证的商业模式+量产能力，是支撑丰田“智慧出行科技公司”转型的重要一环。\n丰田也在合作中，从有钱不知道怎么投的Robotaxi门外汉，到逐渐熟悉L4技术、商业命门，积累L4闭环流程经验，为如今和Waymo的合作提供了样板。\n这又怎么不算是中国自动驾驶玩家的标准、模式输出呢？\n从加州101公路到广州天河CBD，挂丰田标的Robotaxi背后，站着两个时代的影子：一个是硅谷的技术理想，一个是中国技术的商业领跑。\nRobotaxi的iPhone时刻正在来临，丰田不算“起个大早”，但在最关键的转折点，同时布局完成了中美“双版Waymo”。\n- 最强华为概念股冲刺香港IPO！市值2000亿2025-04-29\n- 广汽本田全矩阵亮相上海车展：油电同质同价，重塑智电价值标杆2025-04-29\n- 不怕迪子卖得猛，就怕迪子还能省2025-04-28\n- 上汽集团上海车展亮剑：技术平权驱动全球出行变革2025-04-27'}, 'https://www.qbitai.com/2025/04/279161.html': {'title': '自动化所：基于科学基础大模型的智能科研平台ScienceOne正式发布', 'url': 'https://www.qbitai.com/2025/04/279161.html', 'date': '2025-04-30', 'content': '自动化所：基于科学基础大模型的智能科研平台ScienceOne正式发布\n为科学研究打造全链条人工智能底座\n允中 发自 凹非寺\n量子位 | 公众号 QbitAI\n4月29日，中国科学院自动化研究所（以下简称“自动化所”）在第八届数字中国建设峰会上发布基于科学基础大模型的智能科研平台——ScienceOne。自动化所副所长曾大军研究员现场展示了首发的两个产品S1-Literature文献助手和S1-ToolChain科学工具调度台。\n应用AI技术加速科研发现、重塑科研范式已成为全球科技发展的制高点。自动化所牵头，联合中国科学院计算机网络信息中心、文献情报中心、数学与系统科学研究院、高能物理研究所等兄弟单位以及中科闻歌、中科紫东太初两个产业化平台联合攻关，率先构建了基于架构集成方案的科学基础大模型，并研发了以其为基座的智能科研平台ScienceOne，支持跨学科成果涌现，推动实现多学科协同的智能科研新范式。\n△发布现场\n从理解科学数据到自动干湿实验，专攻科学探索\n近年来，人工智能技术已大规模应用到科学研究中，但仍以各学科微调通用大模型和各自重复造轮子的作坊模式为主，难以解决通用大模型幻觉强、科学专识薄弱、逻辑能力差等挑战。作为专注于赋能科学研究的人工智能平台，ScienceOne依托科学基础大模型，瞄准各学科的共性科学研究需求，从数据理解、计算优化、推理评估三个维度实现了能力突破，可平台式、规模化地赋能“假设提出-方案规划-仿真推演-实验验证-规律发现”科研全流程。\n全能AI科研助手工具，加速科学发现\nScienceOne本次发布：S1-Literature文献助手和S1-ToolChain科学工具调度台。\nS1-Literature文献助手由自动化所联合中国科学院文献情报中心研发，依托国内最大的科技文献数据库和各类实时开源科技资料，可实现高水平的文献理解与综述自动生成，深度理解常用的科学数据类型，准确解读科学公式与专业表达。\n“请写一篇主题为……的文献综述”只需要发出简短的指令，文献助手即可自动整理综述骨架，一次性梳理上千篇文献，生成详细的综述内容。辅助用户精读论文时，文献助手可提供思维导图、引文回溯、研究图谱、关键技术路径抽取等工具。基于科学基础大模型，文献助手还可提供多学科领域知识问答、科学数据解读等功能。\n△S1-Literature界面\n目前，文献助手已完成数学、物理、材料等学科适配，未来将动态扩展并实现全学科覆盖。\nS1-ToolChain科学工具调度台实现了跨学科数据理解、科学计算与仿真等工具的自主协同调用，通过科学模型标准协议，支持接入各类通用与专业科学模型和工具，以智能体进行工具流编排和任务串联。当前，科学工具调度台已集成数理化与工程学科近300个多模态科学数据分析、微分方程求解、离散优化、跨尺度仿真等工具。\n“请完成蛋白质序列补全”，当科研人员输入科研需求，S1-ToolChain科学工具调度台通过科学基础大模型识别研究意图，调用自主研发的序列理解模型分析序列结构，做出补全序列任务的规划与编排，进而调用科学计算工具和ESM3专业模型完成蛋白质序列补全，实现科研工作的闭环。\n△S1-ToolChain界面\n汇聚建制化科研院所优势，加速AI赋能科研创新\n当前，人工智能与科学研究的深度融合，在生物、材料、制药等多个领域取得了突破性成果，正在加速催生形成新一代多学科协同的科研范式，进一步拓展人工智能与科学研究融合的深度与广度。自动化所瞄准这一科研范式变革关键点，充分发挥建制化学科体系和多学科顶尖科研队伍储备的优势，基于科学基础大模型及智能科研平台ScienceOne，为科学研究持续提供强大的人工智能技术供给和全学科的场景支持。\n下一步，研发团队将开源科学基础大模型S1-Base，并发布以此为基座的科学智能体工厂S1-Agent，共同形成平台化工具体系，助力打造AI4Science新范式。\n- DeepSeek新数学模型刷爆记录！7B小模型自主发现671B模型不会的新技能2025-05-01\n- 小扎回应Llama4对比DeepSeek：榜单有缺陷，等推理模型出来再比2025-04-30\n- 蚂蚁数科发布智能体开发平台Agentar 金融机构可“零代码”搭建专业智能体应用2025-04-29\n- RAG性能暴增20%！清华等推出以笔记为中心的深度检索增强生成框架2025-04-29'}, 'https://www.qbitai.com/2025/04/279146.html': {'title': '小扎回应Llama4对比DeepSeek：榜单有缺陷，等推理模型出来再比', 'url': 'https://www.qbitai.com/2025/04/279146.html', 'date': '2025-04-30', 'content': '小扎回应Llama4对比DeepSeek：榜单有缺陷，等推理模型出来再比\nLlama首次推出官方API\n梦晨 发自 凹非寺\n量子位 | 公众号 QbitAI\nMeta首届LlamaCon开发者大会开幕，扎克伯格在期间接受采访，回应大模型相关的一切。\n包括Llama4在大模型竞技场表现不佳的问题：\n开源基准测试存在缺陷，常偏向特定不常见用例，与产品实际使用场景脱节，不能真实反映模型的优劣。\n试图为这类东西进行过多优化会误入歧途。\n对于我们团队来说，搞一个冲到榜单顶部的Llama 4 Maverick版本相对容易，但是我们发布的版本根本没有对此进行调优，排名靠后是正常的。\n以及与DeepSeek的比较：\n我们的推理模型还没有出来，所以还没有和R1相应的模型去对比。\n与此同时，在Meta合作伙伴亚马逊的网站代码中，被扒出要即将推出的Llama4推理模型为17B参数的llama4-reasoning-17b-instruct。\n活动期间，有那么点Meta不语，只是一味地抛出Llama系列“亮点”的意思了（doge）：\n- 除即将推出超2万亿参数的Llama 4 Behemoth模型之外，代号“Little Llama”的80亿参数小模型可能会在未来几个月推出。\n- 推出官方Llama API平台\n- 推出一系列AI安全工具，包括检测和防止提示注入、越狱等风险。\n扎克伯格谈“智能爆炸”\n扎克伯格认为随着软件工程和AI研究的自动化推进，智能爆炸具备实现的可能性。从技术发展趋势来看，AI写代码能力不断提升，预计未来12-18个月，大部分相关代码将由AI完成。\n这不仅意味着开发效率的大幅提高，还可能带来代码质量的提升，因为AI能够基于大量的数据和先进的算法，生成更优化、更高效的代码。\n然而真正达到智能爆炸还面临着诸多现实层面的制约。在物理基础设施上，构建大规模计算集群复杂且耗时，从研发到稳定应用需要一定时间，同时还需要配套建设网络设施，确保数据的高速传输；建设专门的数据中心场地，要经过严格的审批流程；解决能源供应问题，无论是采用传统的燃气轮机发电还是绿色能源，都涉及到复杂的供应链体系，这些环节都需要耗费大量的时间和资源。\n在人机协同方面，人们对AI系统的适应和反馈同样需要时间。AI系统并非一经推出就能被用户熟练使用，而是需要一个相互学习的过程。用户在使用过程中逐渐掌握与AI交互的方式，AI则通过分析用户的行为和反馈，不断优化自身的功能和性能。\n在Meta广告团队的自动化排序实验中，尽管有大量的测试想法，但由于计算资源的限制，无法对所有假设进行充分测试；同时，为了保证测试结果的准确性和可靠性，需要大量的测试人力，这也在一定程度上限制了实验的推进速度。\n扎克伯格认为，人们已经开始与AI建立起多种类型的关系，如将AI作为治疗师倾诉或朋友分享生活等，产品开发者应该尊重用户的选择。\n虽然现阶段这类AI人际关系相关的产品在技术实现上还不够成熟，比如虚拟治疗师或朋友的形象往往只是简单的图片或粗糙的动画，缺乏真实的交互感，但随着技术的不断进步，为提升虚拟形象的真实感和交互性带来了新的可能。\n换句话说，AI和元宇宙战略在未来还有联动效应。\n在产品设计理念上，避免过度干扰用户是关键原则。Meta的Orion眼镜设计目标不仅仅是集成各种先进的技术功能，更重要的是要成为一副好用的日常眼镜。在不使用AI功能时，它要能像普通眼镜一样满足用户的基本需求，如佩戴舒适、外观美观；当用户需要使用 AI 功能时，又能便捷地提供服务，如语音交互、信息展示等。\n这种设计理念同样适用于增强现实未来的产品设计，即让物理世界和数字世界自然融合，在为用户提供丰富数字内容的同时，避免数字元素过度充斥用户的视野，造成视觉和心理上的负担。\n最后，扎克伯格回答了“如果软件生产力在两年内提高100倍”会怎么样。\n他认为从历史看，过去全人类大部分精力都用于养活自己，也就是从事农业为主。最近100多年来满足基本身体需求在人类精力中的占比越来越小。\n这种转变有两个影响：一个是越来越多的人在追求创意和文化。第二是人们花在工作上的时间更少，而花在娱乐和文化上的时间更多。\n但随着时间的推移，如果每个人都拥有这些超人类工具来创造大量不同的东西，就会出现令人难以置信的多样性。其中一部分成果将用于解决难题：攻克疾病、推动科学进步、开发让我们生活更美好的新技术。\nLlama首次推出官方API\n此前Meta只管开源模型，部署托管各凭本事，现在终于推出官方API平台。\n- 提供微调和评估Llama模型性能的工具。\n- 新型芯片供应商Cerebras和Groq合作，提供高推理速度的选项。\n- 承诺不会使用客户数据来训练自己的模型。\n目前属于邀请测试阶段，需要排队。\n不过手快的开发者在会场上就把Demo做出来了。\n利用多模态能力，描述相机拍到的画面，整体上描述准确，不过其实这根香蕉是玩具，对AI来说还是难了。\nLlama API：\nhttps://www.llama.com/products/llama-api/#llama-protections\nDemo试玩：\nhttps://llama-api-launch.craigsdemos.workers.dev\n参考链接：\n[1]https://www.dwarkesh.com/p/mark-zuckerberg-2\n[2]https://x.com/craigsdennis/status/1917365062165225544\n[3]https://x.com/btibor91/status/1917232574344384522\n- DeepSeek新数学模型刷爆记录！7B小模型自主发现671B模型不会的新技能2025-05-01\n- 自动化所：基于科学基础大模型的智能科研平台ScienceOne正式发布2025-04-30\n- 蚂蚁数科发布智能体开发平台Agentar 金融机构可“零代码”搭建专业智能体应用2025-04-29\n- RAG性能暴增20%！清华等推出以笔记为中心的深度检索增强生成框架2025-04-29'}, 'https://www.qbitai.com/2025/04/279124.html': {'title': 'AI卧底美国贴吧4个月"洗脑"100+用户无人察觉，苏黎世大学秘密实验引争议，马斯克惊呼', 'url': 'https://www.qbitai.com/2025/04/279124.html', 'date': '2025-04-30', 'content': 'AI卧底美国贴吧4个月“洗脑”100+用户无人察觉，苏黎世大学秘密实验引争议，马斯克惊呼\n二百多万网友围观\n西风 发自 凹非寺\n量子位 | 公众号 QbitAI\n哈？AI秘密潜入Reddit社区，“操纵”用户观点4个月。\n离谱的是，人类全程毫无察觉，而且被AI说服改变想法的概率，高达正常基准的6倍！\nReddit Lies在X上发布了一则帖子，引发二百多万网友围观。\n事情经过是酱婶儿的。\nReddit的r/changemyview（CMV）版主最近曝光了一项研究，称苏黎世大学研究人员在2024年11月至2025年3月期间，瞒着CMV社区用户，搞了一场未经授权的实验。\n他们违背CMV社区规则，部署了AI账号生成评论以研究AI如何影响和改变人们的观点。\nReddit Lies在服务器上查询了CMV版主曝光的13个实验用的机器人用户名，发现仅在几个月的时间里，这些机器人就发布了近1500条评论。\n超100位Reddit用户给这些AI账号授予了“∆”，这表明AI生成的论点成功改变了他们的观点，是基线水平的6倍。\n关键是，Reddit Lies还表示有的AI会直接向用户撒谎，散播虚假信息……\n且根据团队发布的研究，在实验期间，r/changemyview社区的网友完全没察觉到那些评论竟然是AI账号发出来的。\n消息一出，瞬间炸锅。马斯克也“天呐”一声冒了个泡。\n研究详情\n先来看一下这项实验。\n研究在Reddit平台上的r/changemyview社区进行，该社区拥有近400万用户，按规模位列Reddit子版块前1%。\n在r/changemyview中，用户就各类话题分享观点，通过提出论点和反驳观点来促使他人改变看法。\n如果原发帖人（OP）认为某条回复极具说服力，足以让他们重新思考或调整立场，就会授予一个“∆”，以表明自己观点发生了转变。\n实验设置方面，团队使用半自动化的AI账号在r/changemyview社区参与讨论，在干预阶段发布的每篇帖子，都被随机归入以下三种处理条件之一：\n- 通用条件：LLM仅接收帖子的标题和正文内容。\n- 个性化条件：除帖子内容外，LLM还会获取原发帖人（OP）的个人属性（性别、年龄、种族、所在地…），这些属性是通过另一个LLM从原发帖人的发帖历史中推断得出的。\n- 社区对齐条件：为确保回复符合社区的写作风格和潜在规范，回复由经过微调的模型生成，该模型使用实验前帖子中获得“Δ”的评论进行训练。\n发帖流程如图：\n研究指出，从2024年11月至2025年3月4个月里，AI账号共对1061个不同帖子发表了评论，团队剔除了后续被删除的帖子，最终得到478个有效观察样本。\n团队报告了每种处理条件下获得“Δ”的评论比例。\n结果在所有处理条件下，AI表现都大幅超越人类水平，说服率是人类基线水平3-6倍。个性化条件的说服率为0.18，通用条件为0.17，社区对齐条件略低，为0.09，但仍显著优于仅为0.03的基线水平。\n为了更好理解实验数据，团队还计算了每个用户得到“Δ”的评论占比，用这个结果和个人层面在说服这件事上的表现去做对比。\n下图展示了不同用户个体说服率的累积分布情况 ，有一部分是“专家用户”，他们之前在社区就得到过很多“Δ”。\n在个性化条件下，LLM表现特别突出，在所有用户里排到了前1%，在专家用户里排到了前2%；通用条件下，排在所有用户的前2%，专家用户的前4%；社区对齐条件相对弱一些，在所有用户里排在前12% ，专家用户里排在前25%。\n团队还表示，除了获得“Δ”之外，LLM生成的评论还在r/changemyview社区引发了大量互动，其账号积累了超过10000的评论karma。\n另外值得一提的是，团队指出本研究已获苏黎世大学伦理委员会批准，并在OSF进行了预注册。所有生成评论均由团队的一名研究人员审核，以保不会发布有害或不道德的内容。\n研究指出，实验仍在进行中，结束后会向社区妥善披露相关情况。\n单条帖子800条评论，争议爆表\n虽说研究团队有自己的说法，但一些网友们可不买账，对这种不经授权就进行AI实验的做法进行了谴责。\n有人还心有余悸地感慨，直呼这些AI账号在社交平台上到处乱窜，实在令人细思极恐。\n当然，也有人觉得，先不说实验合不合规矩、道不道德，单看这些研究成果，还是有价值的。\n有部分网友表现就更淡定了，他们坦言AI账号早已不是新鲜事，甚至早就察觉到社交平台上AI账号数量正不断攀升。\n目前，针对这项研究引起的热议，苏黎世大学和研究人员均给出了回应。\n你对这些在社交平台上“神出鬼没”的AI账号怎么看？\n参考链接：\n[1]https://x.com/reddit_lies/status/1916916134630117814\n[2]https://regmedia.co.uk/2025/04/29/supplied_can_ai_change_your_view.pdf\n[3]https://www.reddit.com/r/changemyview/comments/1k8b2hj/meta_unauthorized_experiment_on_cmv_involving/\n- 一次示范就能终身掌握！让手机AI轻松搞定复杂操作丨浙大&vivo出品2025-05-01\n- 又一开源AI神器！将机器学习论文自动转为可运行代码库2025-05-01\n- 全网首测！Qwen3 vs Deepseek-R1数据分析哪家强？2025-04-30\n- 无问芯穹夏立雪：让算力像水电煤一样成为标准化、高附加值的“拎包入住”基础设施｜中国AIGC产业峰会2025-04-29'}, 'https://www.qbitai.com/2025/04/278829.html': {'title': '全网首测！Qwen3 vs Deepseek-R1数据分析哪家强？', 'url': 'https://www.qbitai.com/2025/04/278829.html', 'date': '2025-04-30', 'content': '全网首测！Qwen3 vs Deepseek-R1数据分析哪家强？\n数势科技的SwiftAgent对Qwen3大模型进行整体测评\n允中 发自 凹非寺\n量子位 | 公众号 QbitAI\n昨天凌晨，阿里巴巴开源新一代通义千问模型Qwen3，AI Agent厂商数势科技的数据分析智能体SwiftAgent已率先完成全面适配，并发布了Qwen3与DeepSeek-R1的测评报告。\n下面是具体评测内容，一起来看看在企业级的数据分析和智能决策场景上，Qwen3与DeepSeek-R1到底有哪些差异？\n数据分析Agent深度测评总结\n(声明: 本次测评主要针对Qwen3-32B和Qwen3-235B-A22B,对比Qwen2.5-72B和R1效果)\n针对数据分析Data Agent，有如下关键节点(如图1），分别是改写，任务编排，工具选择和参数解析，工具运行和总结等。\n其中数据查询工具又涵盖了复杂的能力，例如如何将用户的查询语句解析成对应的语义层要素(时间，指标，维度，逻辑算子等）。不同节点的准确性对最终结果都会造成较大的影响。\n△图1：数据分析Agent流程概要\n当前在落地的过程中，不同厂商针对其中节点的准确性优化基本都是三种手段，分别是提示词工程、RAG增强判断和模型微调等。这三种手段的实施成本是递进的，效果也不可控。\n因此，数势科技一直秉持积极拥抱最先进的开源大模型的原则，践行第一时间适配，以提高Agent产品的效果，降低交付中的实施成本。\n先说结论，在上下文改写、任务编排和工具调用、数据查询、图表生成、总结反思五个方面，Qwen3对比Qwen2.5有极大的效果提升，对比DeepSeek-R1模型也不遑多让，甚至在某些环节上还有意外的惊喜。\n成本上，根据阿里官方的报告，Qwen3模型在整体部署上成本极大地降低，进一步降低了各个企业部署和使用的门槛。\n本次，数势科技的SwiftAgent产品针对其中的不同节点，对Qwen3大模型进行整体测评，并对比以往模型的效果。\n（1）上下文改写\nChat类产品首先接收的就是用户的输入语句，由于会话通常存在上下文干扰，以及用户的输入往往都是非标准的，因此必须对用户当次的输入语句进行改写判断，符合“优质进，优质出”的原则。\n以下测试分别把上下文带入到大模型中进行改写，让大模型判断用户问题的语境并进行改写的判断。\n总结：针对Case1的语境，不应该进行改写，出乎意料的只有Qwen3-32B回答准确；针对Case2，由于本轮提问的语境是绝对时间，Qwen2.5-72B会基于上轮时间进行推理，对本轮Query进行改写，其他模型则理解语境不会判断成改写。针对Case3，INV代表“当日库存量”的缩写，当大模型不理解该术语时，会擅自继承上轮内容并改写本轮Query，4个模型均没办法正确回答。\n（2）任务编排和工具调用\n总结：Qwen2.5-72B在数据分析任务拆解和工具调用选择上，均落后于其它三个模型。\n其中，Case2中期望通过子任务的拆解执行提高最终结果生成的准确性，DeepSeek-R1以及Qwen3-32B和Qwen3-235B-A22B推理和非推理模式均表现优秀，Qwen2.5-72B无法成功拆解相应任务，Case3中，Qwen2.5-72B在第5步任务中无法识别到应该调用归因分析工具，其它三个模型均能做到。可见Qwen3-32B做到了成本下降了，效果反而更好了。\n（3）数据查询\n数据要素解析中，对时间要素的识别往往是较难的，因为时间是带动态更新和逻辑推理特性的。例如：“我行销售额较去年增加多少”是时间的隐性推理，实际表达的时间是“今年”和“去年”。此外还有相对时间和绝对时间理解，以及周的开始和结束时间推理识别等。\n总结：在这三种时间难例Case下，DeepSeek-R1以及Qwen3-32B和Qwen3-235B-A22B推理和非推理模式均领先于Qwen2.5-72B，其中Qwen3-32B的效果已经完全接近R1的识别效果。\n数据要素解析中，对实体的抽取也是要素匹配的一个前提条件，实体抽取的质量好坏会干扰后面要素匹配的效果，针对以往的难例case，不同模型的测试情况如下：\n总结：DeepSeek-R1和Qwen3-32B在Case1和Case2的效果优于其他模型，然而DeepSeek-R1在Case3上漏识别了维度，总体来看，实体语义识别的效果差距不大，反而Qwen3-32B的Dense模型效果要优于其他模型。\n（4）图表生成\n本次评测中，采用Echart图表生成的方式来验证不同模型基于数据的理解后，生成并渲染图表的效果。\n总结：Qwen72B对于数据理解和代码生成的能力弱于Qwen3-32B, Case2和Case3中甚至出现了数据遗漏的现象。此外，Qwen3-32B在渲染排版上略逊色于Qwen3-235B-A22B和DeepSeek-R1模型。\n（5）总结反思\n这里，测试了针对生成的错误代码，大模型是否可以结合错误反思并生成准确的代码。\n总结：原始代码存在包括【类型错误】、【潜在的空列表错误】、【字符串与整数操作问题】等数据分析中常见的代码问题。\n经过四个不同模型反思优化后，Qwen2.5-72B选择直接丢弃不符合数值格式的数据，虽然能够跑通，但并不是数据预处理时的最佳选择，优化了潜在的空列表错误。DeepSeek-R1对数据进行了强制转换，但传入无法强制转换的类型时，依旧会报错，且并未解决潜在的空列表错误。Qwen3的两个模型对数据类型做了最符合预期地处理，优先尝试转换为数值，无法强制转换才选择抛弃，但同样并未解决潜在的空列表错误。\n关于潜在的空列表错误，在二次提示优化后，四个模型均给出优化方案，达到预期。\n此外，还测了一些其他和数据分析相关的大模型能力，例如数学推理计算能力，从网上借鉴了一些数学测试题，先说结论，DeepSeek-R1模型和Qwen3-235B-A22B在数学计算推理能力上要优于另外两种模型，符合Scale Law的认知。\n具体来说，Case1中，DeepSeek-R1模型和Qwen3-235B-A22B均回答正确，其他两个模型回答错误。Case2和Case3中所有模型均回答准确。\n综上所述，在数据分析Agent构建方面，Qwen3模型的发布对于Agent的构建有极大的提升作用。无论是在任务规划、代码生成、数学计算和语义识别等方面，Qwen3模型都表现较为出色，其中Qwen3-32B模型也远优于上一代模型，甚至接近于DeepSeek-R1模型，且部署成本更低，消费级显卡即可实现推理自由，对企业使用大模型来说，是重大的利好。\n在Qwen3模型发布的首日，数势科技SwiftAgent率先完成了对Qwen3的全面适配，并对Agent的中间环节进行了能力升级和创新性功能开发，为企业客户构建AI驱动的数据分析和智能决策提供了更高性能、更低成本的智能产品。\n- 一次示范就能终身掌握！让手机AI轻松搞定复杂操作丨浙大&vivo出品2025-05-01\n- 又一开源AI神器！将机器学习论文自动转为可运行代码库2025-05-01\n- AI卧底美国贴吧4个月“洗脑”100+用户无人察觉，苏黎世大学秘密实验引争议，马斯克惊呼2025-04-30\n- 无问芯穹夏立雪：让算力像水电煤一样成为标准化、高附加值的“拎包入住”基础设施｜中国AIGC产业峰会2025-04-29'}, 'https://www.qbitai.com/2025/04/279083.html': {'title': 'GPT-4o医学知识覆盖率仅55%？腾讯优图团队发布大模型医疗能力"体检报告"', 'url': 'https://www.qbitai.com/2025/04/279083.html', 'date': '2025-04-30', 'content': 'GPT-4o医学知识覆盖率仅55%？腾讯优图团队发布大模型医疗能力“体检报告”\nMedKGEval团队 投稿\n量子位 | 公众号 QbitAI\n医疗大模型知识覆盖度首次被精准量化！\n在医疗领域，大语言模型（LLM）的潜力令人振奋，但其知识储备是否足够可靠？腾讯优图实验室天衍研究中心的最新研究给出了答案。\n他们提出的MedKGEval框架，首次通过医疗知识图谱（KG）的多层级评估，系统揭示了GPT-4o等主流模型的医学知识覆盖度。\n该研究已被WWW 2025会议Web4Good Track录用为口头报告（oral）。目前，WWW 2025正在悉尼举行，会议时间从4月28日持续至5月2日。\n背景\n大语言模型（LLM）在医疗领域的快速发展凸显了其知识存储与处理的潜力，但其临床部署前的可靠性验证亟需更系统化的评估框架。\n当前主流的Prompt-CBLUE、Medbench和MedJourney等评估体系虽通过医学问答基准测试LLM的任务执行能力，却存在三个明显的局限：\n1）其长尾数据分布导致罕见病症覆盖不足，评测结果存在偏差；\n2）任务导向的设计聚焦疾病预测、用药咨询等单一场景，难以量化模型内在医学知识储量；\n3）传统问答形式局限于表面对错判断，无法捕捉医学概念间的复杂拓扑关联。\n为解决这些问题，本文提出基于医疗知识图谱（KG）的多层级评估框架MedKGEval。\n医疗KG通过结构化存储复杂实体关系网络，为评估提供天然基准。框架创新性地设计三级评估体系：实体层评估医学概念理解，关系层检验医学关联区分能力，子图层验证结构化推理水平。\n通过真伪判断和多选题形式，同时实现任务导向（task-oriented）的粗粒度性能评估与知识导向（knowledge-oriented）的细粒度三重覆盖度测量（实体/关系/知识三元组）。\n医疗知识覆盖度评估框架MedKGEval\n在MedKGEval中研究团队设计了多层级的任务体系，其中包含3个层级的9项核心任务，通过真伪判断（TFQ）与多选题（MCQ）任务形式，实现任务导向与知识导向的双重评测。\n具体评估流程框架见下图。\n任务架构设计\n基于医疗知识图谱的实体、关系、三元组结构，构建三级评估体系：\n实体层面（3项任务）：验证医学概念理解\n- 实体类型标注（ET）：通过多选题识别“糖尿病”等实体的分类标签（如疾病/症状）\n- 实体聚类（EC）：从5个实体中辨识类型异常项（如混入症状类别的药物实体）\n- 实体消歧（ED）：判断两个实体是否等价，比如“阿司匹林”与“乙酰水杨酸”是否为等价实体\n关系层面（3项任务）：检验医学关联认知\n- 关系类型标注（RT）：选择“并发症”关系可连接的实体类型对（如疾病→疾病）\n- 事实核验（FC）：判断三元组的真伪，比如“布洛芬-治疗-偏头痛”\n- 关系预测（RP）：补全实体之间缺失的关系，比如“冠状动脉硬化→(?)→心肌梗死”\n子图层面（3项任务）：评估结构化推理\n- 错误识别（ER）：从5个三元组中检测异常项（如错误药物禁忌关系）\n- 子图推理1（R1）：基于多跳关系推理，比如基于“高血压→并发症→脑出血→影像检查→CT”路径，推断“高血压→影像检查→CT”是否成立\n- 子图推理2（R2）：在相同推理链中，从候选关系中选择正确关联\n随着利用的KG信息增多，任务难度也在逐渐升高，这样阶梯式、多层级的评估更有利用全面了解LLMs的性能。\n任务导向和知识导向的评估机制\n在每项任务中均配备评估核心实体/关系映射（如上图 core E and R），实现细粒度知识覆盖分析：\n任务导向评估：计算准确率指标\n知识导向评估：\n- 实体覆盖率：实体正确率均值（CovAvg-E）、引入节点中心度加权（CovDeg-E）\n- 关系覆盖率：关系正确率均值（CovAvg-R）、按关系出现频次加权（CovDeg-R）\n- 三元组覆盖率Cov-T：反映知识单元整体掌握度\n实验及评估结果\nMedKGEval选用中文医疗领域主流知识图谱CPubMedKG和CMeKG作为基准，经下采样构建实验数据集。\n评估模型涵盖三大类：1）开源通用模型；2）医疗垂类模型；3）闭源模型。\n下表展示了11个LLM的任务导向评估结果，可以看到：GPT-4o以70.65%平均准确率领先；同架构LLM参数量翻倍带来3-5%准确率提升；大多LLM在实体层面任务上表现优于关系和子图层面；通用模型性能超越医疗垂类模型（归因分析：垂类模型微调数据侧重具体任务（如用药咨询、医患对话摘要），导致医学知识广度受限）。\n下表展示了11个LLM的知识导向评估结果，可以看到：GPT-4o在CPubMedKG (small)上覆盖了65.66%的实体、55.60%的关系、62.31%的三元组；更大的参数量通常会带来更高的知识覆盖度；CovAvg 和 CovDeg 的对比体现出了LLM对高关联度实体（如糖尿病）和高频关系（如鉴别诊断）的偏好性：CovAvg < CovDeg 说明 LLM 在高关联度实体的上表现更好、反之说明 LLM 在低关联度实体上表现更好。\n接下来，研究团队使用MedKGEval评估框架对四个示例LLM在关联度最高的15个实体和最高频的15个关系上的知识覆盖情况进行分析。\n以常用临床实体“超声”为例，可以看到GPT-4o以94.16%正确率领先，Qwen2-7B（88.83%）、WiNGPT2（85.41%）次之。\n在医学关系覆盖度上，4个LLM也表现出了类似的特点。\n分析结果表明，MedKGEval能有效定位LLM在特定医学知识领域的认知缺陷。\n这些发现对模型优化具有重要指导价值：如上图所示，WiNGPT在“肺结核”实体相关问答中表现欠佳、Baichuan2-13B在“相关（转换）”关系中存在明显短板。\n因此，在下轮微调中建议针对性补充结核病诊疗指南和病理转化机制相关数据，通过基于知识缺陷诊断的定向增强策略，可显著提升医疗领域LLM的整体性能。\n总结\n本文提出的MedKGEval框架通过医疗KG视角，构建了评估LLM医学知识覆盖度的多维度体系。\n该框架在实体、关系和子图三个层级展开评估，系统揭示了当前大语言模型在医学知识存储与推理能力方面的优势与局限。\n研究团队提出的的任务导向与知识导向双轨评估机制，不仅能够精准定位模型的知识薄弱环节，更为提升医疗领域LLM的可靠性和临床应用价值提供了量化依据。\n论文地址：https://dl.acm.org/doi/10.1145/3696410.3714535\n代码地址：https://github.com/ZihengZZH/MedKGEval\n— 完 —\n- 告别“图文不符”！FG-CLIP实现细粒度跨模态对齐，360开源模型重塑AI视觉理解2025-04-28\n- 7×24小时非人类科学家入场：当AI开始自主探索科学未知领域 | 多伦多大学2025-04-27\n- 开源垂直领域高质量数据合成框架！专业QA自动生成，无需人工标注，来自上海AI Lab2025-04-27\n- 北大团队引领3D生成与对齐革新：OctGPT打破扩散模型垄断2025-04-25'}, 'https://www.qbitai.com/2025/04/279033.html': {'title': '多邻国全面AI First！AI能胜任的工作，都不会再新招人', 'url': 'https://www.qbitai.com/2025/04/279033.html', 'date': '2025-04-30', 'content': '多邻国全面AI First！AI能胜任的工作，都不会再新招人\n不能等到技术100%完美时才行动\n明敏 发自 凹非寺\n量子位 | 公众号 QbitAI\n被AI带飞的小绿鸟，现在要彻底AI-first了。\n多邻国CEO最新全员信宣布：\n拥抱AI已经到了相当紧迫的时刻，哪怕技术没有100%成熟，也不能再等了，否则就要错失良机。\n第一步要做的，就是用AI替代人工外包。\n如果承包商的工作是AI能胜任的，那就会逐步被替代。\n岗位扩招也变得更加严格：只有当一个团队的工作实在没有办法进一步用AI自动化时，才能增加人员。\n此外，招聘、绩效评估这类工作，AI也将加入其中。\n但这不是要用AI取代员工。\nCEO在全员信中特意表示，是用AI来为团队提效，让人类更专注于创造性的工作。\n作为借力OpenAI商业化落地的典范，“邪恶小绿鸟”这两年赚得飞起。\n从2023年到现在，股价一路走高，最高时超过400美元，目前总市值达到174.98亿。\n近期发布的2024年第四季度业绩报告显示，日活用户达到4000万，同比增长51%。\n第四季度总预订量同比增长42%，收入同比增长39%，全年调整后的EBITDA利润率提高了约8个百分点。\n如此增长，使得小绿鸟成为这波AI大潮中的商业化典范。比如谷歌就在最近推出了基于Gemini的类似语言学习应用。\n那么，当它旗帜鲜明搞AI-first，又传递出哪些信号？\n不能等到技术100%完美时才行动\n在全员信中，CEO表示AI改变工作方式，是当下已经正在发生的趋势。\n在如此重大转变之前，最糟糕的做法就是等待。\n2012年，我们押注在移动终端，当时所有人都在为网站开发配套的移动端APP，但是我们却决定从设备入手，因为我们看到了这是未来趋势。这使我们获得了2013年iPhone年度应用，开启了后面的爆发式增长。\n现在全面押注AI，也是类似的思路。\nAI不仅能提升工作效率，还能实现更好效果。\n多邻国最近做出的一个“最佳决策”，就是用AI生成内容取代人工创作流程。\nCEO表示，如果没有AI，需要数十年才能将内容扩展到更多用户那里。\n此外，多邻国还推出了AI视频通话功能，让用户可以通过与AI角色聊天和玩游戏来学习语言，就像和真人老师对话那样。\n所以，现在的多邻国已经等不及了。\n我们宁愿在质量上做一些小妥协，但也不能错失AI这一良机了。\n由此，多邻国要将AI进一步引入到招聘、绩效考核以及内部工作方式变革等方面。\nCEO坦言，这种变化可能会令人感到害怕，但他坚信这对于多邻国而言是一个重大进步。\n而从更长时间维度来看，多邻国会做出这种决策也不意外。\n毕竟小绿鸟是从2021年就开始与OpenAI接触、合作，在应用中集成GPT-3的能力。GPT-4推出后，他们的行动也相当迅速。\n这种对AI的敏感嗅觉，也为其带来了切实的增长。\n2024年全年收入达到7.48亿美元，同比增长41%，这一增长主要得益于订阅收入的大幅增长。\n其中，第四季度收入为2.096亿美元，同比增长39%。\n2024年订阅收入同比增长50%，占总收入的比重超过70%。付费订阅用户则达到950万，同比增长43%.\n利润方面，2024年净利润达到8860万美元，较2023年的1610万美元大幅增长；调整后的EBITDA（息税折旧摊销前利润）为1.919亿美元，同比增长8个百分点，达到25.7%的利润率。\n用户方面，2024年第四季度，多邻国的日活跃用户（DAU）达到4050万，同比增长51%；月活跃用户（MAU）达到1.167亿，同比增长32%\n这些增长背后，AI的驱动功不可没。\n2024年，多邻国推出了多项创新功能，如Duolingo Max高级订阅服务和实时对话功能Video Call。\nVideo Call通过AI驱动的对话伙伴Lily，帮助用户练习口语，尤其是英语学习者对该功能的使用频率显著高于其他语言学习者。\n所以对于2025年的业务重点，小绿鸟也放在了AI上。在业绩报告电话会上，公司表示将利用生成式AI改善视频通话体验，尤其针对高级学习者。同时，使用AI和自动化工具更快地扩展语言、数学和音乐课程的内容，目前数学和音乐课程的日活用户合计达300万，增长空间大。\n这次CEO的告全员信，或许正是如此变革的一个新起点。\nOne More Thing\n不过，小绿鸟高层激情昂扬的变革，用户们却未必买账。\n在LinkedIn上，不少海外用户表示，这样的话我就要告别多邻国了。\n如果你这么做，我就要取消订阅了，我已经连续打卡1400天了。\n大家都担忧，这种AI战略听上去似乎像是裁员的一种婉转说法。以及对AI的靠谱程度也有所顾虑……\n所以，你觉得呢？更AI的多儿，会更好吗？\n参考链接：\n[1]https://www.linkedin.com/feed/update/urn:li:activity:7322560534824865792/\n[2]https://futurism.com/the-byte/duolingo-replacing-humans-ai\n[3]https://www.theverge.com/news/657594/duolingo-ai-first-replace-contract-workers\n- 大模型竞技场再被锤！Llama4私下测试27个版本，只取最佳成绩2025-05-02\n- 微软CEO和奥特曼失了和，OpenAI被“断粮”2025-05-02\n- 中关村科金喻友平： 平台+应用＋服务是企业大模型落地的最佳路径2025-04-28\n- 阿里Qwen3问鼎开源王座！8款模型全面开放，最大杯全方位超越R12025-04-29'}, 'https://www.qbitai.com/2025/04/278828.html': {'title': '10秒生成官网，WeaveFox重塑前端研发生产力 | 蚂蚁徐达峰@中国AIGC产业峰会', 'url': 'https://www.qbitai.com/2025/04/278828.html', 'date': '2025-04-30', 'content': '10秒生成官网，WeaveFox重塑前端研发生产力 | 蚂蚁徐达峰@中国AIGC产业峰会\n产品已在阿里和蚂蚁实际投产\n编辑部 整理自 AIGC产业峰会\n量子位 | 公众号 QbitAI\nAI入职大厂担当程序员编程助手，如今已非新鲜事。\n不过，随着实践的深入，新的问题正在出现：AI生成代码需要大量翻修、安全生产难以保障……\n“如果不能找到一个合适的切入点，可能会适得其反——用AI不如不用AI。”\n作为技术变革的一线亲历者，蚂蚁集团平台智能体验技术负责人徐达峰如是坦言。\n聚焦前端开发场景，徐达峰和他的团队打造了WeaveFox智能研发体系进行AI编码。主要有图生代码、意图生码和AI质检系统三大突破方向，让AI能根据用户输入的设计图，或者工程上下文补充逻辑代码，交付通过多模态技术检查产物质量。\n目前WeaveFox已在阿里和蚂蚁实际投产，据介绍在超500名前端工程师的参与下，目前在设计图交付动线场景下，AI已累计生成合并接近100万行代码；研发效率最高可提升5倍。\n在第三届中国AIGC产业峰会上，围绕“AI赋能软件研发周期”的话题，徐达峰带来更多前端从业者、开发者的第一视角实践与思考。为了完整体现徐达峰的分享，在不改变原意的基础上，量子位对演讲内容进行了编辑整理，希望能给你带来更多启发。\n中国AIGC产业峰会是由量子位主办的AI领域前沿峰会，20余位产业代表与会讨论。线下参会观众超千人，线上直播观众320万+，累计曝光2000万+。\n话题要点\n- AI前端研发如果不能找到一个合适的切入点，可能会适得其反——用AI不如不用AI。\n- AI辅助编码会带来思维方式的转变，从人产出代码AI配合优化，过渡到AI生成代码再人工进行检查。\n- 对面向开发者的产品来说，用户同时是开发者，是构成新质生产力的重要部分。\n（以下为徐达峰演讲全文）\nAI前端研发需要合适的突破视角\n大家下午好！很荣幸来到AIGC产业峰会，我叫徐达峰，来自蚂蚁集团平台智能体验技术团队，目前正在主导前端智能研发系统WeaveFox，同时我也是开源社区的深度参与者。\n在AI技术高速发展的今天，AI前端研发已然成为行业的共识，尤其在今年初以来，开源社区对技术的促进和推动，让我们发现整个软件研发生命周期里面，有非常多的环节有很大的提效空间。\nAI如何深度赋能软件研发周期呢？我会从自身作为前端从业者、开发者的第一视角给大家介绍蚂蚁前端技术团队的实践及思考。\n从前端视角来看，AI研发落地上的困难包括很多方面。整体的实践没有一个固定的标准，在AI编码方面有行级代码生成、片断级代码生成、需求级代码生成，还有另外一种范式是先完成单元测试的编写再反推实现。\n这样就带来多个瓶颈。首先，AI生成的大部分代码可能50%以上都需要后续二次修改或者大量翻修。\n其次，在安全生产方面，我们在使用AI工具的时候很容易将企业数据和敏感信息发出去，甚至提交到海外，这给企业带来了很大的风险，包括入侵风险。企业内部如何安全合规地使用AI能力进行AI生产，也是我们面临的问题。\n在现有软件研发体系上，很多工具经历十多年打磨，已经很方便、很成熟了，此时如果不能找到一个合适的切入点可能会适得其反——用AI不如不用AI。\n不是任何地方都需要智能化升级，我们需要找到一个可以突破的合适的视角。\n另外，AI研发也在平台和组织层面上带来了冲击和思维方式的转变。从以往更多是人来产出代码、AI配合优化，慢慢过渡到AI生成代码、人工来检查，这对现有人员的经验或者思维方式冲击还是很大的。\n我们主要从以下三个方面突破这些瓶颈：\n- 图生代码，通过图片直接生成生产级代码；\n- 意图生码，通过意图生成骨架代码，或根据工程上下文生成逻辑代码；\n- AI质检，通过多模态能力对产出检查并自动完善，帮助提升交付品质。\n图生代码\n图生代码解决的核心问题主要分为以下几个方面。\n第一，其最大的优势在于简化了流程，不再依赖上游的各种工具，不管是 Figma、Sketch 还是其他工具，直接将图片像素输入给多模态模型，它就可以理解并生成源代码，并且一定要一次成型。其好处在于减少了中间的人工干预，一次成形意味着自动化，自动化意味着可以规模化地使用，在产业的落地中具备了可行性。\n其次，在端侧研发过程中还有一个比较关键的技术项，那就是跨端。在现今的产业中，很多产品端是多端的，用在车机系统、手机、PC上，可能形式是小程序或者移动端网页等，这么多端如果每一套都做AI化的模型，成本非常高昂而且不便于复用，能否用一个模型解决所有端侧问题呢，让跨技术栈成为可以复用甚至可以一键切换的可能性？用户直接输入一个图片，通过模型推理在十几秒就生成整体代码，最终交付到代码仓库中。\n完成这样的能力需要用到GUI的领域多模态模型，生产这样模型并不容易，我们做了以下几方面工作。\n基座模型与数据\n首先是强化了基座模型。\n我们基于蚂蚁多模态基座模型对整个细粒度调节做了高强度强化，针对细颗度的Query Token叠加位置编码。这样的特性其实对grounding（基础训练）的任务有很大好处，生成在布局、准确度、精准度上会有很大优势。\n第二是在深度融合和预训练阶段使用海量数据，以提升大模型本身对于GUI风格的敏感度。\n第三方面涉及其他高分辨率的编码器，例如具备2K分辨率的数据窗口。对于一些常规的页面区域或界面，此类编码器能够轻松应对。\n数据处理方面，涵盖数据采集、标注以及精筛等环节，面临的挑战较大。\n以往在训练视觉小模型时，使用数千至上万个样本往往就能取得不错的效果。然而，如今训练大模型则需要动辄数百万的数据样本，这使得样本精筛和问题查找工作面临巨大挑战。例如，要从数百万数据中找出错误样本，可能需要训练专业的专家模型。为此，我们对整体的训练模型工具链进行了大幅升级，付出了诸多心血和努力。\n训练与评测\n接下来进入训练阶段，此阶段包括样本预处理以及二百万级别的后训练，并进行了相应的调试工作。\n评测部分从两个维度展开。\n其一为白盒的多维评测，我们每周都会对版本模型进行迭代。为了评估这些版本模型在各个维度上是得到了优化还是出现了劣化，我们设置了多个评测维度，如组件布局、颜色准确性等。\n其二是存图的泛化评测，主要用于评估大模型上一个版本的产出准确性和相似度。\nUI IR标准\n说到训练工作，不得不提到我们确立的IR（Intermediate Representation)）标准，作为模型训练备数和跨端消费的统一标准，完备描述GUI世界。目前，我们已支持60+ GUI语义单元的数据定义，能够涵盖行业流行标准和现代操作系统，基本涵盖了行业的流行的视觉组件包括流行的框架库，并适配现有的操作系统。\n作为模型训练以及后续消费的统一标准，我们去年添加了17个视觉可视化相关的标准，IR标准让整体跨端的实现成为了可能性。不仅能够生成如Vue等各种框架库，甚至可以后续生成鸿蒙、安卓界面类的代码。这些技术栈的操作和切换只需要一键操作。\n我们还开展了模型上下文的扩展与增强工作，包括对细节方面的处理。以颜色（如背景色、按钮背景色）为例，原本呈现为列表形式，存在组件混淆的问题。通过工程校准，我们基本实现了高度还原的效果。\n这在图生代码的演示中得到了体现，直接输入官网图片即可生成代码，生成的代码质量与人工编写的代码相近，能够满足测试标准。\n我们采用了这样的测试方法：将同一份代码展示给测试人员，让他们判断代码是通过辅助工具编写还是一次性自动生成。若大部分人难以分辨，则认为该代码达到了标准。\n接下来大家可以看一下我们“图生代码”的演示。仅需10秒，我们就用WeaveFox轻松生成了Claude的官网。\n接下来给大家介绍一下“交付设计图即交付代码”。\n在企业内部实践中，涉及众多业务线和产品线，会产生大量的设计图和设计稿。我们在设计稿平台上直接集成了相关能力，当上游生成设计资产后，可直接通过模型推理生成代码，下游工程师能够直接获取这些资产、代码片段甚至完整代码进行生产。这种模式有效降低了中间环节的成本，提高了效率。\n在图生代码方面，我们还将自身模型与行业内的优秀模型，如Claude-3.7-Sonnet、GPT-4o、Qwen2.5-VL 进行了对比。在列表、卡片布局、图片处理以及众多资源处理（包括SVG）方面，我们的模型展现出了显著优势。由于大模型对SVG不够敏感，我们针对这些方面进行了大量的细节优化。未来，我们将持续与行业内的SOTA模型进行参照和对比，不断提升自身能力。\n意图生码\n意图生码，主要是通过意图来生成骨架代码。\n然而，在实际的产业生产中，对话式编程这种模式较难落地，难以实现标准化和工业化。在实际需求中，企业通常不会要求技术团队开发类似坦克大战这样的演示项目，更多的是希望完成特定 APP 功能的开发。\n针对意图生码，我们进行了L3级别的产品封装，推出了意图生码智能体。该智能体旨在将研发场景的效率优势进行固化。例如，在多语言处理方面，对于已有代码上下文如何进行覆盖单侧处理，以及用户埋点行为相关代码等复杂工作，智能体能够借助AI技术一次性完成。\n当然，仅有这些能力还不够。为了将企业内部工程师转化为新质生产力，让每位工程师都能成为能力的贡献者，我们需要解决内部开放和接入的问题。为此，我们将开放面向工具的多种接入方式，包括API、WebUI以及IDE插件等，同时兼容标准化大模型通用的MCP协议标准。\n对面向开发者的产品来说，用户同时是开发者，是构成新质生产力的重要部分。\nAI质检\n在突破发展瓶颈方面，我们引入了AI质检技术。\n该技术充分复用了前文提及的多模态能力，旨在分析产品交付前原始需求与最终交付成果之间的差异，并通过 AI 分析和再次生成修复代码，以此提升交付环节的品质。\n目前，这一技术的实践和落地情况如下：我们耗时四个多月的工作日，邀请了500多位前端工程师，生成了一百万行代码。\n去年年底，我们进行了科学论证。行业中一直流传着“10倍速工程师”的说法，为了验证其“真实性”，我们邀请了几十位同学并将他们分成AB两组，其中一组使用智能研发动线和智能研发工具。最终的验证结果显示，工作效率大约有2.7倍的提升；在复杂场景下，效率提升可达5倍。\n虽然目前尚未达到10倍速，但这仍是我们努力的方向和目标。此外，我们还致力于为行业体系内已有的搭建平台工具提供赋能和接入支持。\n开放计划\n最后介绍一下WeaveFox开放计划，我们目前有公有SaaS版在测试中，会逐步扩大公测名单。下一步计划是通过蚂蚁开源社区进行开源，像大家使用Ollama一样，让每个人可以本地拥有这样的服务，持续开放代码生成器甚至模型训练的工具链，同时包括各种丰富的上下游工具生态。\n在面向产业应用方面，可以通过一个形象的比喻来理解。首先是一体化交付模式，就像前面提及的图生代码智能体或意图生码智能体，它们借助L3级别能力能够自动化完成任务。这类似于一体化压铸技术，直接完成某个大型部件的生产，之后无论是外观设计还是内饰配置，都可以根据需求自由选择。同样，在技术层面，跨端技术栈的切换和选择也能为用户提供这样的自主选择权，而无需重新训练模型。此外，在交付之前，具备AI检查和自动质检能力，以此确保交付成果的质量和效果。\n在当前产业蓬勃发展的背景下，我们前端研发或者外部技术研发所构建的智慧工厂，或许就蕴含在这样的模式之中。\n以上就是我今天分享的内容。\n- 大模型终于通关《宝可梦蓝》！网友：Gemini 2.5 Pro酷爆了2025-05-03\n- 粉笔CTO：大模型打破教育「不可能三角」，因材施教真正成为可能｜中国AIGC产业峰会2025-04-18\n- GPT-4.1淘汰了4.5！全系列百万上下文，主打一个性价比2025-04-15\n- SOTA自动绑骨开源框架来了！3D版DeepSeek开源月大礼包持续开箱ing2025-04-11'}, 'https://www.qbitai.com/2025/04/278640.html': {'title': '人人可用的超级智能体！100+MCP工具随便选，爬虫小红书效果惊艳', 'url': 'https://www.qbitai.com/2025/04/278640.html', 'date': '2025-04-29', 'content': '人人可用的超级智能体！100+MCP工具随便选，爬虫小红书效果惊艳\nAgent进入傻瓜相机阶段\n白交 发自 凹非寺\n量子位 | 公众号 QbitAI\nAgent赛道热闹非凡，周鸿祎力推的纳米AI搜索，体验上能有什么不一样？\n首先，依然很“挤”，一不小心就会挤爆服务器。\n但更进一步实测了一波之后，我们还是发现纳米AI搜索，不管从打开方式还是产品特点，其实都很“老周”……\n直接说结论——\n首先，它把MCP的使用门槛给打下来了。作为首个真正面向toC市场的MCP平台，普通人也能够真正体验到基于MCP的高阶智能体。以往的MCP都是面向专业人士，在开发者中流行。但现在纳米AI上的4亿用户都能调用海量MCP工具来完成真实世界的复杂任务。\n其次，真正意义上的MCP开放生态。纳米AI目前已有超100个自研和优选MCP工具，并且更多第三方MCP工具正在进驻中。\n而且还能看到360技术优势和产品风格的延续：选择本地部署和MCP工具集成，而不是通常的云端Host，大模型进行深度检索和社交平台操作的时候，更方便绕过登陆墙、广告墙，使用方便的同时还不用担心安全问题。\n具体的细节，咱展开来说。\n实测纳米AI万能工具箱\n使用纳米AI万能工具箱很简单，只需下载APP应用并注册登录即可，无需额外任何配置，入口就在左侧的「智能体」页面。\n除了本地部署而非云端这种入口不同以外，还有就是产品定位的不同。相信你也注意到了，其他平台都是直接亮相号称支持MCP的「超级智能体」，纳米AI则上线的是「万能工具箱」。\n虽然目标是一致的——\n通过对MCP协议的支持，让大模型、智能体可以调用各式各样的MCP工具。它支持多个工具并行运行，就像模拟人类在真实世界完成工作一样，执行复杂步骤，覆盖多样性和泛化的通用任务。\n但市面上其他平台，他们的MCP工具都是在封闭体系运行，工具也比较有限和固定。\n而纳米AI工具箱则是主打构建起一个开放的MCP生态体系，目前从官网上已经看到，支持超100个MCP工具。\nMCP工具一多，在此基础上的智能体也越多，从而整个智能体生态生生不息，最后纳米AI真就成为了所谓的万能应用。当然这些都是后话了。总之，开放是从纳米AI万能工具箱中看到的一个关键词。\n且进一步来看，在纳米AI万能工具箱基础之上，通过自由调用，自由组合MCP工具，来构建各种场景下的智能体。\n官方已经能看到一些智能体，有官方的，有第三方开发者的，也支持自己手捏一个。其中不少其他平台需要付费的，在纳米AI都支持免费集成和调用。\n免费，yes！\n既然如此，那就来实测一波。\n深度分析和研究，是智能体升级之后最喜闻乐见的一项技能。官方正好有个「深度研究智能体」，那就抛出一个问题给到它：2024-2025AI眼镜产品发展情况。\n给出提示词很简单，除此之外什么事情都不要做，也没有任何「联网搜索」、「深度思考」的按钮选择。\n来看结果。\n能够清晰地看到它从思考、规划到行动这么一个全链路流程体系：\n搜索资料、生成数据可视化图标、撰写研究报告。\n整个调取MCP工具的过程也清晰可见，包括sandbox_coder工具生成各种图标、summary工具撰写报告、gen_html工具生成网页版本……\n最后它直接给出了PDF、Word以及网页三个版本，大概是酱婶的。\n基本能力OK，那就来看看MCP开放生态赋予之下其他有意思的智能体。\n从中选出两个比较被惊艳到的智能体：小红书浏览机器人、专业论文搜索。PS，都是第三方开发者开发的哦，普通用户可以直接免费取用。\n先来看小红书浏览机器人。昨天北影节落下帷幕，来看看大家对于此次北影节的评价。\n搜索分析小红书用户对本次北京电影节的评价。\n除了中间有个需要自行登录的操作，其他一切过程都十分流畅。于是就可以看到它的花式操作。\n它自行输入关键词，进行逐个点击、查看小红书笔记、提取关键信息。整个操作像人一样，但又比人类完成更高效怎么回事？！\n最后从17篇小红书笔记中，得到这些关键信息。不知道关注北影节的读者们有没有感同身受到~\n而如果再本地搭建个小红书自动发布器，一句话从找热点、生成爆款内容、图片，甚至是视频，就连发布也能完成，用户零干预就能运营自己的小红书个人自媒体。\n再来看与我们日常工作更为相关的「专业论文搜索」这个智能体。这个智能体能调取纳米 AI 超级搜索、arXiv 搜索、谷歌学术、学术搜索等工具。\n最近需要与「模型压缩」研究方向的专家交流，想了解下最新论文进展。于是把这个问题抛给它。\n帮我检索关于「模型压缩」领域最新热门论文，并展示出每篇论文摘要，要求附上论文链接。\n最终它给出了四篇论文，并且附上了标题、摘要和论文链接。\n经过逐一校对发现，每一个论文链接都有效，且论文都是最近1-2个月的。\n这一点其实蛮惊喜的。这意味着现在智能体已经摆脱了大模型潜在的幻觉问题，完全实现了从理解到行动的闭环。\n要知道以往把这些问题抛给大模型（包括使用联网搜索），要么论文链接就是无效的，要么根本无法理解具体研究内容，也没有依照准确的时间轴，现在这些问题都已经被规避掉了。\n而除了官方、第三方，自己也可以根据需求手捏一个智能体，来调取各种工具。\n对于开发者来说也可以自行配置一个MCP工具/服务，仅需几个参数设置即可完成。\n整个过程可以看到，普通用户使用起来非常方便，甚至只需一个提示词，智能体就能够自动分析用户需求并拆解为多个子任务，自主调用MCP工具（如浏览器、代码编辑器等）执行任务，并输出完整的结果报告。\n而它所能覆盖的场景和能力到现在也还只是个冰山一角——\n据介绍，目前MCP生态已经覆盖了办公协作、学术、生活服务、搜索引擎、金融、媒体娱乐、数据抓取等场景。\n接下来随着更多MCP工具应用的入驻，大模型/智能体的价值边界将会无穷扩展。\n为什么选择做MCP开放生态？\n如今再回头看MCP，它给行业带来的影响，其实并不单只是通过一个统一的标准，让大模型能够使用各种工具。\n正如纳米AI所展现的，MCP带来的是从技术、功能和应用场景三重突破。\n首先，大模型和Agent功能扩展更轻松。开发者不用再费劲搭建各种接口、构建与外部数据通信方式。通过统一的MCP数据协议，大模型和AI Agent能直接对接海量外部工具，像拼乐高一样自由组合功能。\n其次，智能体学会更为高阶的自主思考，AI不再是只会按固定工作流程走的机器人。通过MCP协议，它们能像人类一样主动获取信息。比如从「万能工具箱」里挑选需要的功能（查天气/写代码等），通过试错积累经验，越用越聪明。就像实习生成长为专家，AI也能逐步建立自己的决策系统。\n最后，通过大模型和海量MCP工具的自由组合，从而完成真实世界的复杂任务，应用场景大大拓宽，真正做到「三生万物」。目前纳米AI生态已经有超百个真实可用的高质量MCP工具和技能，而且还是免费调用，不仅MCP工具数量领先同类产品，而且简单易用，普通人也可以快速上手。\n对于专业开发者来说， 这是国内最大最开放的MCP工具平台，能够在平台上自由组合MCP技能自建Agent+MCP，带来更多智能体产品的可能。\n所以再看MCP带来的行业影响，并非简单工具调用，而是给大模型、智能体应用更多的可能性。\n更具体地来说，就是整个大模型应用的生态。\n当大模型掌握了使用工具的能力，能够在复杂任务中游刃有余地处理，那么它在真实世界中的赋能也将被大大地推动。\n所以也就不难理解，为什么纳米AI选择的是「万能工具箱」这样一个产品定位——\n以简单、低门槛的方式，真正地以MCP开放生态为锚点，真正地面向广大的C端用户去做产品。\n不过想要真正实现，其实难度不小。这就需要说道说道纳米AI背后360过去技术与生态的积累。\n首先就是搜索能力。一方面基于360团队过去在搜索上的深厚积累，自建了千亿级的索引库和百亿级精品库。另一方面，加入了更多MCP协议的搜索工具，比如谷歌学术啊，ArXiv啊，GitHub啊这些常见好用的，多重buff叠加，搜索能力只会越来越强。\n而从小红书浏览助手的效果可以看到，它对页面各种模态内容的理解能力很强，这得益于SR、视觉语言模型（VLM）、PDF的版式分析、OCR模型等等等技术的部署。\n其次还有浏览器底层能力的积累。不同于大家云端运行的AI浏览器，他们专门为大模型打造了专用浏览器，本地计算机即可运行。\n为啥要这样做？一来，大模型需要频繁调用浏览器，只有对云、浏览器、OS等全方位改造，才可以实现在云原生环境下高性能大规模并发调用。二来，用户或者企业很难会想要将私人数据托管给第三方云服务器，而有些企业应用场景是在内网运行，那么这时候云端智能体更是无从下手，本地部署自然会成为主流。\n最后自然还有安全方面的部署，他们有推出隔离沙箱MCP，实时监测、预警和限制MCP客户端的本地计算机操作，用户可以放心地让大模型生成本地执行的指令，不用担心幻觉、失误、或恶意注入攻击导致数据丢失、信息泄漏、高危操作等。\n目前，纳米AI用户月度访问量突破4亿，随着对MCP协议全面支持，更多用户和开发者的用户使用，形成产品技术飞轮，更多高阶智能体也将会涌现。\nAgent进入傻瓜相机阶段\n已经形成共识的是，大模型本身发展到一定程度，下一个阶段使用工具的进化，也就是智能体这一范式。\n类比于人类，当人的身体、大脑进化到一定程度，使用工具才能与万物生灵互动来主导这个世界。随着大模型能力逐渐强大，就好像大脑拥有了思考的能力一样，但要与真实世界连接，从指令转化为行动，那就需要使用工具。\n而作为大模型与工具的连接器「MCP」这一共识正在全球汇聚、反应，掀起不可阻挡的浪潮。\n但以往这些尚且还属于开发者、技术圈的内部狂欢。现在以纳米AI为代表，大幅降低了使用门槛，让智能体的应用辐射到普罗大众之中。\n智能体进入到傻瓜相机的阶段。这其实也是技术发展周期的必然。\n现在人人都在谈论超级智能体，但什么时候会有超级智能体？\n或许从国内首个真正面向普通用户的开放MCP生态开始，或许从「万能工具箱」这个直白的词汇替代「MCP」技术词汇开始。\n总之，这个趋势已经开始，这个趋势还在持续，作为大模型下最核心的市场应用，Agent真正来到了爆发节点。\n- 当购物用上大模型！阿里妈妈首发世界知识大模型，破解推荐难题2025-05-01\n- OceanBase全员信：全面拥抱AI，打造AI时代的数据底座2025-04-27\n- 网易有道张艺：AI教育的规模化落地，以C端应用反推大模型发展2025-04-27\n- 英伟达H20不让用？全国产算力推理模型升级，4张华为卡即可部署2025-04-22'}, 'https://www.qbitai.com/2025/04/278751.html': {'title': '上海车展探馆：国产百万级越野限量发售，武汉造，太尊了！', 'url': 'https://www.qbitai.com/2025/04/278751.html', 'date': '2025-04-29', 'content': '上海车展探馆：国产百万级越野限量发售，武汉造，太尊了！\n猛士917长轴版的改装升级\n一凡 发自 上海车展\n智能车参考 | AI4Auto\n东风猛士罗伦士M900星际战车与蛟龙战甲加长版近日在上海车展上市并交付。\n两款车都是限量发售，其中星际战车价格为128.8万元，全球限量66台。\n蛟龙战甲加长版稍微“便宜一些”，价格为109.8万元，放的量也比较多，为199台。\n购买两款车的车主，下订都将获赠双人极限路书，价值8万元。\n实际上，两款车都是对猛士917长轴版的改装升级，增程式动力，搭载三电机，轮边扭矩可达12938N·m，妥妥的性能怪兽。配合后轮线控转向，驾驭这只性能怪兽也更加灵活。\n区别是内饰和服务上，主打一个：尊。\n蛟龙战甲加长版\n这是国内第一款电影联名车型，顾名思义联名的是《蛟龙行动》，加长版在外观上延续了917的设计，车头整体有“龙颜”那味儿了：\n- 进气格栅是龙牙\n- 隆起的双棱线像龙须\n- 机盖的通风罩犹如龙鳞\n然后是车内，加长版座舱的二排空间当然更大，整车使用了大量北欧牛皮，经过12道光学检测，覆盖率超过了95%，\n座椅则采用Pasubio顶级半苯胺真皮，20道纯手工工序差不多要经过3天时间才能造出来，，从植据说触感就像天鹅绒，嗯，挺尊的。\n蛟龙战甲加长版也支持改装，提供个性化服务，用户可定制皮质的纹理和缝线颜色等细节。还有绿松石，青金石、黑曜石、紫水晶等材质选订，每台蛟龙战甲加长版还随赠一整张高品质原皮，你可以拿去做个手包或者背垫。\n有车主在交付现场畅想起爱车改装：“比如座椅纹样，可以用我这次在西藏看到的藏式八吉祥图腾纹样， 门把手和中控扶手，换成手工捶打的藏银纹样，或是用唐卡的矿物颜料原石装点，这样每次开车都像行驶在西藏。”\n星际战车\n星际战车的线条更有未来感，配备了独特的“星际蓝”车漆，能够随着角度从璀璨星蓝到墨色变幻显得更有立体感，还加高车顶配备了车顶探照大灯。\n全车有4个座椅，配备16向电动调节，三档按摩及一键躺平功能采用绗缝工艺，造型精准模拟战机机翼。方向盘、换挡手柄等处的“龙鳞”纹路压花。\n采用进口头层小牛皮，既彰显尊贵气质，又确保出色的握持手感；门饰板、中控饰条、前后扶手箱饰板、冰箱饰板等部位运用古老而精湛的非遗螺钿工艺，选用深海贝，由经验丰富的匠人耗时3个多月，经30多道工序拼嵌并抛光至镜面，螺片可纤薄至0.08毫米，流光溢彩，散发东方艺术的独特魅力；1818颗LED组成的星空顶，搭配多种动效与星座呈现，营造出沉浸式宇宙遨游体验感。\n二排还配备了车载智能冰箱支持-10℃低温储存，隐私密码箱为贵重物品提供安全保障。\n- 上海车展见证历史：从「西为中用」到「中为西用」，行业风向标携手Momenta2025-05-01\n- 上海车展探馆：本田涨智慧靠中国，Momenta辅驾护航，DeepSeek赋能座舱2025-04-29\n- 上海车展对话：高阶辅驾普及改变座舱需求，7B成模型上云分水岭2025-04-29\n- 蔚来李斌：一年减少了数十亿英伟达芯片采购2025-04-27'}, 'https://www.qbitai.com/2025/04/278737.html': {'title': '上海车展探馆：本田涨智慧靠中国，Momenta辅驾护航，DeepSeek赋能座舱', 'url': 'https://www.qbitai.com/2025/04/278737.html', 'date': '2025-04-29', 'content': '上海车展探馆：本田涨智慧靠中国，Momenta辅驾护航，DeepSeek赋能座舱\n搭载一段式端到端模型\n座舱接入DeepSeek，辅助驾驶用Momenta，电池选择宁德时代。\n这就是本田在上海车展发布的最新进展，将转型的希望全部寄托在本土优秀玩家。同时，本田旗下纯电动品牌“烨”第二弹“GT”也亮相展台。\n本田智电靠中国，烨GT首秀\n本田跟进了全民辅助驾驶，透露今后在华所有新车型都将搭载辅助驾驶，满足消费者对新出行方式的需求。为了落地辅助驾驶，本田选择了与「全球品牌的共同选择」Momenta合作，打造基于一段式端到端大模型的辅助驾驶方案，实现全场景覆盖，包括高速NOA、城区NOA、自动泊车辅助和记忆泊车领航辅助，在国内规模化落地应用。\n至于座舱，本田同样选择接入DeepSeek，尤其是新能源品牌烨，旗下所有车型都将接入DeepSeek，让用户的语音交互体验更加自然，至于此前已上市的东风本田S7和广汽本田P7都将同步进行OTA升级。\n电动化方面，本田将携手宁德时代，上车CTB（Cell To Body电芯集成到车身）提高车内空间利用率，使用磷酸铁锂电池，将在烨品牌第三弹车型上搭载应用。\n烨品牌是本田中国的纯电动品牌，由本土年轻化团队主导打造，近日，烨品牌旗下的东风本田S7和广汽本田P7先后上市，新车型“GT”紧跟着亮相。\nGT是本田烨品牌的旗舰车型，兼顾“驾驶乐趣”与“舒享体验”，并不是主要面向日常出行体验，强调驾驶乐趣。\n主驾采用以驾驶者为中心的AI沉浸式运动座舱，通过浓厚运动氛围的营造，激发驾驶激情，让驾驶者尽享操控乐趣；而副驾驶则为最重要的人打造了惬意舒享移动时光的”款待空间”，带来全新的出行体验。\nGT还将采用Momenta的一段式端到端辅助驾驶系统，预计至少可实现城区NOA，座舱还会接入DeepSeek，为用户提供全新的智能化出行体验。\nF1赛车和架构亮相\n搭载**本田动力单元的“Oracle Red Bull Racing RB21” F1赛车惊喜登场**\n作为本田运动基因和挑战精神的象征，搭载了本田动力单元的“Oracle Red Bull Racing RB21”世界一级方程式锦标赛（简称：F1）赛车在现场展示。本田坚信“只有参加赛车运动，才能造出更好的汽车”因此本田多年以来始终致力于通过赛车运动磨炼和提升自身的技术实力，并将其活用到量产车上。消费者可以近距离与其互动，切身感受 本田 的赛事基因和传承。\n本田云驰架构和解剖车，坚守安全和品质传承\n近日上市的本田烨品牌第一弹车型东风本田 S7与广汽本田 P7也亮相上海车展。现场还展示了本田专为中国消费者打造的新一代纯电动车专属的本田云驰智能高效纯电架构，以及烨品牌第一弹车型的解剖车，展示在关于安全和品质上“本田看不见的标准”。\n本田云驰智能高效纯电W架构，本田烨品牌第一弹解剖车\n本田将初心注入中国速度和优势，与中国市场同频，加速技术和产品的升级进化，结合最新生产技术，打造独具本田特色的移动出行价值。\n- 上海车展见证历史：从「西为中用」到「中为西用」，行业风向标携手Momenta2025-05-01\n- 上海车展探馆：国产百万级越野限量发售，武汉造，太尊了！2025-04-29\n- 上海车展对话：高阶辅驾普及改变座舱需求，7B成模型上云分水岭2025-04-29\n- 蔚来李斌：一年减少了数十亿英伟达芯片采购2025-04-27'}, 'https://www.qbitai.com/2025/04/278729.html': {'title': '上海车展对话：7B成模型上云分水岭，高阶辅驾普及引发座舱需求变动', 'url': 'https://www.qbitai.com/2025/04/278729.html', 'date': '2025-04-29', 'content': '上海车展对话：高阶辅驾普及改变座舱需求，7B成模型上云分水岭\n降本需从产品定义阶段开始\n一凡 发自 上海车展\n智能车参考|AI4Auto\n舱驾一体融合，成本不降反升？\n最近，北京芯势力芯驰科技在上海车展发布了两大新品：\n- 新一代AI座舱芯片X10系列，NPU算力40TOPS，带宽154 GB/s\n- 高端MCU产品E3系列焕新，进入国产“无人区”\n两大新品发布，正处于行业新趋势的爆发前夜。一方面，底层电子电气架构走向集中式，一些功能开始跨域整合。另一方面，上层应用高阶辅助驾驶走向普及，渲染场景的需求和底层的架构都对座舱提出了新的需求。\n全民AI座舱与全民辅助驾驶交汇的时代，需要一颗怎样的座舱芯片，需要什么样的MCU？\n在新品发布会后，芯驰科技CTO 孙鸣乐、副总裁 陈蜀杰、MCU产品线总经理 张曦桐接受群访，分享了车载芯片领域的最新认知：\n1.谈MCU：功能和性能越发复杂， 降本要从产品定义期考虑\n2.谈座舱：新品主推AI座舱，高阶辅助驾驶普及引发座舱变化\n3.谈趋势：舱驾一体成本不降反升，Chiplet应用大算力芯片\n4.谈优势：平台化加速量产，本土量产铺垫海外\n以下为对话实录，经编辑：\n谈MCU：功能和性能越发复杂， 降本要从产品定义期考虑\nQ：MCU正在SoC化，芯驰如何平衡性能、成本和功耗？\n张曦桐（芯驰科技MCU产品线总经理）：当前汽车电子电气架构正向中央计算和区域控制方向发展，整车对高端MCU的需求快速上升，功能相对简单的MCU也在逐步升级。这正是我们发布会上强调聚焦智能化、电气化和软件定义汽车的原因。未来我们认为价值量较高的MCU主要集中在几大场景：\n- 最重要的是区域控制器，今年的车展上可以看到区域架构已在逐步落地\n- 其次是要求非常高的动力和底盘系统\n- 还有汽车安全相关领域，包括辅助驾驶。\n在这些场景中，MCU的功能和性能要求确实远超传统定义，或可称为MPU。在当前的汽车行业形势下，成本控制至关重要。我们认为今年对每一个车厂而言，都已无法承担过度的“豪华堆料”。芯驰内部一直强调“懂芯更懂车”，当前的产品需要我们为每个应用场景寻找最优解，既要保证性能，又要平衡成本。\n如何有效控制成本？我们认为最关键的环节在于产品定义阶段。许多人认为产品推出后，通过压低供应链或后道封装测试的价格来降本，但这样做的空间非常有限，每年可能仅有个位数的降幅。然而，在产品定义阶段，如果我们能确保产品是为特定应用量身定制，每一个功能特性、每一个IP都针对该业务场景精心打磨，去除所有不必要的功能，让车厂不为他们不需要的功能买单，这才是最有效的降本方式。对芯驰而言，我们将产品定义放在极其重要的位置，坚持“专为应用定制，专为场景打磨”的原则。\n其次，管控成本并非意味着芯片越简单越好，关键在于定义的精准度和研发能力。以芯驰为例，虽然是一家相对年轻的国内公司，但我们通过领先的架构设计以及底层的软硬件设计能力，可以确保在实现同样功能模块或IP时，芯片面积（Die Size）做到业界领先，甚至优于部分国际友商。这种高效率的设计能力，使得我们能在设计阶段就将成本控制到非常极致的水平。总而言之我们认为芯片降本，最大的工作量和价值体现在早期阶段。\nQ：有没有软硬件一体的规划？\n孙鸣乐 （芯驰科技CTO）：我们一直以来都比较注重生态合作。整个汽车产业链非常长，参与其中的有做操作系统、协议栈、工具链等各类软件公司，众多环节并非一个公司能全部完成。芯驰的核心会聚焦在芯片本身及其底层软件，例如MCU的MCAL（Microcontroller Abstraction Layer），SoC的Linux/Android BSP（Board Support Package），以及与芯片密切相关的上层工具链，比如AI工具链。\n我们认为不必所有环节都自己做。就像我们与众多算法伙伴、操作系统伙伴的合作，即使操作系统或算法来自合作伙伴，我们也可以通过从芯片定义阶段就开始的紧密沟通，以及在开发过程中双方研发人员的协同调试，最终实现软硬一体带来的更高效率和更好性能。并非所有事情都得自己承担才能达到目标。\nQ：芯驰如何看待这一波车载操作系统开源的浪潮？如何将芯片适配到这些操作系统？\n孙鸣乐（芯驰科技CTO）：适配工作是操作系统与硬件结合的过程，需要一个中间层——驱动程序，这部分主要由芯片公司负责实现。操作系统本身是抽象的，可以适配各种芯片，但每款芯片的硬件模块设计各不相同。驱动程序的作用就是解决硬件差异，并与操作系统定义的标准化接口进行对接。\n我们所做的主要工作就是开发和优化驱动程序。首先要实现基本功能，然后基于此与特定操作系统进行适配，确保所有功能都能运行起来，之后再进行优化。优化的目的是针对特定操作系统的特性（例如它调用硬件的方式可能不同）来提升性能。\nQ：这个适配过程和以前基于例如AUTOSAR标准的操作系统相比，有哪些不同？\n孙鸣乐：AUTOSAR本身是一个标准，追求的是一种非常极致的标准化，对各个部分都有非常严格的规定。但每个操作系统在实际使用中，可能会遇到规则过多或某些方面不够易用的情况，开发者会根据自己的场景需求进行修改和优化。我们的E3系列MCU已经适配了理想汽车自研星环OS，我们适配了；普华基础软件最早启动开源“小满”计划时，我们也进行了适配。我们非常支持这类开源行动。\n开源的过程体现了一种技术共享的心态，对整个行业的进步是有帮助的。举个例子，如果某项功能在一个操作系统上实现得很好并且开源了，那么其他开发者就能看到其实现方式，借鉴优秀的思路和做法，从而应用到自己的产品中。这是一种技术外溢。当技术成熟后，将好的理念和技术与整个行业共享，我们是非常支持这种做法的。\nQ： 高阶辅助驾驶有什么布局？\n张曦桐（MCU产品线总经理） ：我们为高阶辅助驾驶系统提供的是安全MCU，并非承担核心算力，而是负责辅助驾驶系统内的许多系统管理任务，包括通信管理、安全管理，以及部署一些安全相关的算法。\nQ：当国外厂商提供更新的功能时，客户为什么选择芯驰？\n张曦桐（MCU产品线总经理）： 我认为到今天为止，行业内无论是芯片厂商还是一二级供应商，竞争的核心在于对用户需求的理解深度以及产品与应用的契合程度。当前竞争已不再是单纯比拼谁的技术更前沿，比如堆砌多少核、采用多少纳米工艺。我们观察本土车厂，其整体电子电气架构和智能化发展速度非常快。这对国产芯片厂商而言是一个利好，因为我们离客户更近，可以进行更深入的交流，自身的迭代速度也更快。\n对芯驰来讲，一个很大的优势在于我们第一代量产产品已经积累了大量的客户和应用经验，覆盖了车身、动力、底盘、区域控制、辅助驾驶安全以及座舱等多个领域。我们下一代产品的设计经验正是来源于前一代产品和客户反馈。我们曾在客户量产阶段，派驻工程师在一线与客户团队一起工作，无论早晚。通过这样紧密的合作，芯驰对客户的需求和痛点理解得非常深入。这就是为什么我们在今天的发布会上强调“场景驱动”。\n我认为接下来几年，业界的竞争将围绕对每一个细分应用的理解深度展开。例如，动力系统可能需要RDC（旋转变压器解码）相关的专用处理单元；座舱需要的功能又不同；区域控制器则对通信模块有特殊要求。我们提供的模块，其核心价值并非仅仅在于技术有多先进，而在于能否将功能做得恰到好处，精准满足特定场景的需求。\n一是对客户的理解。另外一个优势，我认为是芯驰整体的系统级设计能力，这也是我们区别于国内外一些厂商的地方。我们是从更复杂的SoC设计开始，采用更先进的工艺向下延伸做MCU的。正如刚才另一位记者提到的，现在的MCU越来越像SoC，复杂度不断提升，这恰好发挥了芯驰的优势。我们熟练运用多核、多操作系统、虚拟化等技术，掌握在先进工艺下平衡性能与功耗的方法，以及整体系统设计能力。这也是为什么芯驰能在高端车规MCU市场占据较高份额的原因，很多经验是从SoC设计继承下来的。\n此外，芯驰的核心IP自研率非常高。除了像CPU核以及博世GTM这类行业标准IP外，大部分核心IP，包括您提到的那些专用模块，如我们的通讯引擎、电机控制专用单元等，基本都是自研的。除了那些非常标准的IP，其余大部分MCU产品线的IP我们基本都坚持自研。\nQ：每个细分应用场景对MCU的要求不同。今天我们去看了底盘域相关的展台，他们提到线控驱动、线控制动最终会融合到一个底盘域控制器，甚至可能再与动力域融合。如果是这样融合的趋势，那么对于底盘域控制器、运动域控制器，或者驱动电机控制器中的MCU，它们更偏向于哪些性能参数的要求？比如是内核、内存、还是通讯能力等？\n张曦桐（MCU产品线总经理）：它们都会有要求。首先，功能融合增多后，算力肯定需要更强，这可以通过更高主频或更多内核来实现。对CPU能力的要求自然更高。相应的，存储容量（如Flash、RAM等）也需要增加，这很容易理解，因为功能变多了。\n底盘功能融合之后，对整个系统的实时性要求也会提高。这不仅包括内核的实时性，还可能需要整个处理链路上的加速引擎来满足需求。此外，底盘系统（如制动、转向）的功能安全要求非常高，通常需要达到ASIL D级别，对芯片的可靠性要求也可能提升至极高水平。基本上是对芯片整体性能的全方位提升。\n我认为，未来功能融合较多的场景，例如底盘跨域融合动力或车身，还有可能用到虚拟化等先进技术。但需要注意的是，底盘域使用的虚拟化，与我们通常理解的座舱或信息娱乐系统中的虚拟化有所不同。它需要更强的实时性、更高的安全性，并且对资源的开销要求非常低，毕竟MCU的资源不像SoC那样充裕。要实现整个运动控制域的集成，肯定需要专门的技术来优化系统，使其高效运行。\nQ： MCU虚拟化在国内的发展程度如何？\n张曦桐（MCU产品线总经理）：MCU虚拟化技术本身并非处于早期，而是其应用需求的普及节奏问题。为什么现在需要在MCU中引入虚拟化？这与整车架构向域控制器方向发展密切相关。虚拟化解决了一个核心问题：能够隔离不同安全等级、不同迭代频率、不同需求的软件功能。\n之所以现在这个需求变得强烈，是因为域控制器融合的功能越来越复杂。以前未集成时，车身、底盘各司其职，互不影响。但现在同一个域控制器里，可能既有需要长期稳定、很少OTA的底盘相关软件（如AUTOSAR CP），又有需要频繁更新的车身相关软件（如AUTOSAR AP或其他需要OTA的功能）。因此，市场的需求推动了虚拟化技术在MCU上的应用。技术本身没有太大的瓶颈，但成功应用确实需要丰富的经验。\n虚拟化不是简单地运行一个Hypervisor软件。它涉及到整个系统架构的设计，包括外设分配、存储管理、内核选择以及Hypervisor本身的优化，是一个系统性的工程。这需要芯片厂商具备相当的经验积累。\nQ： 目前MCU在整个汽车市场内的国产化程度大概有多高？\n陈蜀杰（芯驰科技副总裁）：一辆车里MCU用量很大，可能多达上百颗，种类繁多。要看具体分类。但我想有一点是肯定的：基本上绝大多数种类的MCU都已经有国产化方案。最终车厂的选择，我认为更多还是取决于产品的性能、技术、性价比以及服务。因此，很难给出一个统一的国产化率统计数字。\n目前座舱SoC市场的统计数据显示，芯驰的出货量排名在国内厂商中领先，也有市场调研机构（Canalys)报告显示国内有两家进入全球前十冠军厂商，芯驰是其中之一。座舱领域相对集中，容易统计。但MCU市场太分散了，目前没有看到一个权威的整体统计。\n但是，我们可以肯定的是，在高端车规级MCU领域，也就是面向未来架构、我们现在讨论的这些核心应用场景（如区域控制、动力底盘、辅助驾驶安全等），芯驰在国内是绝对领先的。很多这类产品，其他国内厂商甚至还没有推出。我们在高端MCU领域相当于进入了“无人区”，这在国产MCU上是很少见的。\nQ：国内MCU厂商的发展路径似乎有两种，一种是像一些模拟芯片厂商那样向MCU拓展，或者从简单的车身MCU入手，再一步步向上走；另一种就是像芯驰这样，直接面向高端。高端MCU到底应该怎么做，才能在全球打响我们国产品牌的名头？\n张曦桐（MCU产品线总经理）：您描述的第一种路径，即从低端往上走，可能看到别人有什么产品，就做一个功能相似、价格更低的产品。\n我们做的产品，是行业在这些高端领域非常需要的，并且此前缺乏强大的国产供应商，现在几乎没有。我们为车厂带来价值，他们也非常需要像芯驰这样的公司。芯驰走的是一条非常有前瞻性的路。我们做的产品是随着整个汽车电子电气架构向前演进而设计的，是跟着行业趋势往前走的，而不是看别人家做了什么，我们再做一个差不多的、改改规格的产品。\n那么，如何确保这种面向高端、具有前瞻性的产品定义是准确的？正如我们今天发布会上强调的，与车厂、以及上下游生态伙伴的协同至关重要。我们需要与他们紧密合作，同时自身需要对整车架构有非常深入的理解。否则，我们如何能确保产品定义是符合未来需求的？芯驰内部要求团队具备领先Tier1和车厂的系统能力，我们自己就在研究整车的电子电气架构，甚至会搭建虚拟整车模型进行研究。我们需要对系统有深刻的理解。\n通过与客户（尤其是领先的Tier1和车厂）以及上下游生态伙伴进行非常深度的交流，大家一起把未来的需求趋势、当前的痛点理解得非常清楚。通过这样的方法，虽然有点像摸索前进，但从我们目前的成绩来看，这条路是比较成功的。\n我们这一代产品，无论是E3650还是今天发布的E3620，都是在产品尚未正式发布时就已经与车厂进行了深入的联合定义。可以说，产品定义刚完成、样品刚出来，就有客户基于我们的产品启动项目开发。这证明了我们的产品定义是比较成功的。\n谈座舱：新品主推AI座舱，高阶辅助驾驶普及引发座舱变化\nQ：电子电气架构走向中央集成，芯驰是否会针对更高级别的集成（比如走向小SoC的技术路线）去做进一步延伸，甚至推出类似“舱驾一体”概念的芯片？\n张曦桐（MCU产品线总经理）：架构演进可能有两个方向：一种是将车身、动力、底盘等大量功能融合成一个大的区域控制器；另一种是将所有线控底盘功能（制动、转向、悬架、驱动）和动力系统集成在一起，形成一个强大的底盘/动力域控制器，而区域控制器相对轻量化。\n无论是哪种架构，芯驰的E3系列产品都能为这些核心的域控制器提供合适的解决方案。我们在设计E3产品时，已经具备了相当的前瞻性，面向的是未来3到5年的架构需求。我们相信，车厂选用E3产品，能够高效地实现他们下一代架构的设想。我们在设计产品时，并非闭门造车，而是与中国市场大部分头部车厂都进行过深入交流，了解他们下一代架构的核心需求后才进行设计的。因此，E3系列产品能够覆盖未来整车架构中的核心节点，无论是区域控制器、线控底盘域，还是未来的运动控制域。\n至于中央计算层，我们今年发布的X10系列，正是面向未来中央计算架构中极具竞争力的下一代AI座舱产品。\nQ：X10的NPU算力是40TOPS，足够做舱驾一体吗？\n孙鸣乐（CTO）： X10这款产品的主要定位是AI座舱。其NPU的主要优化方向是支持AI大模型在车端的部署。我们做出这个选择基于两个考虑：\n第一，我们认为AI大模型在车内的部署，将是近期（至少未来半年到一年内）比舱驾融合更强烈的市场需求。融合主要解决的是成本问题，希望将功能集成以降低硬件成本。而AI大模型部署在车内，能够带来全新的用户体验和产业变革机会，催生更多创新应用，这是一个驱动增长的重要方向。\n第二，X10没有特别侧重考虑集成辅助驾驶功能的原因在于，辅助驾驶本身变化非常快。回顾过去一年，车厂对辅助驾驶功能的定位发生了显著变化，用户需求也在演进。同时，头部车企的技术路线规划对整个产业影响巨大。在这种需求和技术路线都不稳定的情况下，我们贸然进行集成并非一个好的选择。\nQ：当大模型和多模态交互真正在车上普及时，对座舱芯片的算力或其他性能要求有多高？40TOPS算力是否仍是一个合理或最优的解决方案？\n孙鸣乐（CTO）：根据我们目前对市场的理解，车端部署7B（70亿参数）左右的大模型是一个比较合适的规模。X10的40 TOPS算力，配合相应的内存带宽，能够很好地满足运行这类模型的需求。如果端侧需要运行远超7B规模的模型，那么部署在云端可能会更合适。\n我们希望端侧的7B模型能扮演“车内智能管家”的角色，能够理解用户指令并执行车辆相关操作，甚至根据环境进行规划和车辆设定调整。我们认为这是7B规模模型可以胜任的任务范围。\nQ： 为什么芯驰不重点投入辅助驾驶？\n孙鸣乐（CTO）：关于舱驾融合和辅助驾驶投入，正如我之前提到的：\n第一，辅助驾驶的需求尚不稳定。无论是车厂对辅助驾驶功能的期望，还是用户的实际需求，都还在快速演变中。\n第二，辅助驾驶的技术路线本身变化也很快。例如，关于是否需要高精地图的争论持续了几年；关于是否需要激光雷达也存在不同意见；前两年Transformer架构流行后，许多技术都在发生变化。技术本身尚未完全稳定。\n在这种情况下，对于在辅助驾驶领域没有太多前期积累的芯驰来说，立即大规模投入并非一个好的选择。我们应发挥自身在座舱领域的现有优势。我们拥有大量的量产经验，非常了解这个市场，并且有良好的客户基础。当前座舱领域最迫切的需求是解决AI大模型上车的问题，我们应首先把这个做好。也许未来几年，当辅助驾驶市场和技术路线都趋于稳定时，我们再考虑推出集成方案或独立的辅助驾驶芯片都是有可能的，但不是现在。\n陈蜀杰（副总裁）：从公司的整体考量来说，大家可以看到辅助驾驶领域竞争已经非常激烈，“非常卷”，参与的厂商也很多。对于一家芯片硬件公司而言，要做好辅助驾驶，还需要投入巨大的人力物力进行软件开发，包括操作系统等。我们需要从整体市场格局的角度来考虑自身的定位。\n相反，大家可以看到，芯驰一直在走自己的路：\n扎扎实实地把座舱做到顶尖水平。在座舱领域，我们目前已有超过五十款量产上车车型，这在行业内是领先的。对于高端车规MCU，我们没有参与低端市场的价格战，而是直接定位在技术要求非常高的高端市场，这样才能保证我们的技术领先性和合理的利润空间。我们认为这种扎扎实实、基于实际出货量和客户选择的发展路径，比仅仅讲述宏大的故事更为重要。这是一个企业的战略选择问题。对于别人现在投入做辅助驾驶，我们并不羡慕。核心是把我们选择的事情做成功，这点最重要。\nQ ：座舱领域有什么明显的变化和趋势吗？\n孙鸣乐（CTO）： 我们看到了一个明显的需求变化，是来自于辅助驾驶系统对座舱功能的影响。随着高阶辅助驾驶功能的渗透率越来越高，在座舱内部进行“环境现实（Surrounding Reality, SR）”渲染的需求变得越来越普遍。\n这意味着，座舱系统需要将辅助驾驶系统感知到的周围环境信息（例如，本车位置、周围车辆、行人、自行车、车道线、导航路径指引等）实时地、逼真地渲染出来，并显示在仪表盘、中控大屏或者HUD（抬头显示）上。目前，至少在仪表端，显示本车及周边车辆、变道提示等是最基本的需求；而在中控屏上，许多高阶辅助驾驶系统会要求渲染出非常精细的周围环境，包括检测到的行人、自行车等各种目标。\n这个渲染任务通常是在座舱域完成的，它导致了对座舱SoC的CPU，特别是GPU（图形处理器）的计算能力和图形处理性能提出了更高的要求，会比以前单纯的信息娱乐系统需求高很多。\n谈趋势：舱驾一体成本可能不降反升，Chiplet应用大算力芯片\nQ：如何看待“舱驾一体”？\n孙鸣乐（CTO）： 一个是我刚才讲到的，就是辅助驾驶的需求和技术路线不是很确定，另外它和座舱的迭代速度也不一样。\n单纯抛开市场因素，从技术角度看融合。合在一起的好处是可以共享一些资源，比如内存、接口等，这样理论上可以节省一些成本。\n但是合在一起也面临诸多挑战。一个挑战在于，如何避免共享资源带来的安全风险。座舱和辅助驾驶的安全等级（ASIL）是不同的。虽然可以通过例如ASIL D级别的Hypervisor来运行两个不同安全等级的系统，但这会使得整个系统设计比原来分离式方案更为复杂。原本各自独立的系统，融合后就需要承担集成带来的额外复杂性和需要考虑的安全隔离问题。\n另外，从大的逻辑上看，最终座舱和辅助驾驶都属于高性能计算的范畴。从计算资源通用性的角度讲，如果未来某一天计算资源极其充裕，那么在上面部署座舱或辅助驾驶应用确实是可行的。但目前状况还没到那一步。现在你问任何做辅助驾驶的，他通常不会觉得芯片资源很丰富，反而觉得不够用；做座舱的也常常觉得资源紧张。那么，要把两者拼在一起，需要做多大的芯片才能让双方都觉得资源“够用”？这就回到了之前讲的问题：当需求和技术路线都未完全确定，大家还在以不同方式快速迭代时，强行融合就会遇到很多挑战。\n这些挑战从技术层面讲并非不能实现，只是目前可能需要付出的代价有点大 。大厂在探索实践，这对行业发展是好事。但对于芯驰而言，立即将此作为主要方向去实施，是有些挑战的。\nQ：“舱驾一体”成本不会下降反而会上升？\n孙鸣乐（CTO）： 有这个可能。你可以这样理解：所有的研发成本最终都要分摊到每一台量产设备上。如果舱驾一体方案主要应用在一些高端车型上，或者在整个市场中的渗透率不高，那么其量产规模就不会很大。在这种情况下，高昂的研发费用分摊到有限的量产数量上，单位成本就可能相对较高。虽然硬件的BOM成本可能有所降低，但加上研发成本摊销后，最终的总成本可能并不便宜。\nQ：X10如何实现舱泊一体？\n孙鸣乐（CTO）： 对X10来说，如果涉及泊车功能，采用外挂MCU的方式可能会更常见。原因有几个：第一，芯驰自家的MCU产品线在座舱域的应用越来越广泛，市场份额在提升。我们在X9量产时，可能还没有非常适合搭配X9的座舱MCU；但到X10量产的时候，我们在座舱周边MCU市场应该已经有了较大的份额，很多方案会比较成熟。我们现在已经在好几个车厂的座舱项目中出货MCU了。这种情况下，自然的方案选择就是在MCU端实现泊车等功能，我们的产品和方案都会比较成熟。\n第二，我觉得对于X10这个级别的SoC来说，舱泊一体可能并不是一个特别重要的核心功能。通常搭配X10这种规格处理器的车型，其辅助驾驶系统本身也不会太弱。在这种情况下，泊车功能一般会在辅助驾驶域控制器中完成，而不会放在座舱SoC（X10）上来实现。虽然X10拿来做舱泊一体技术上没问题，但我并不认为大部分客户会选择这样做。\nQ： X10如何平衡性能与成本之间的关系？是否考虑引入Chiplet技术来降低成本？\n孙鸣乐（CTO）： 我们没有在X10这款芯片上使用Chiplet技术，仍然是单Die（Monolithic）设计。虽然X10的算力已经很大，但得益于采用了相对先进的4纳米工艺，其晶体管密度和功耗控制都比较好。我们评估认为，在单芯片上就能够很好地实现所需的功能和性能，目前没有必要引入Chiplet。采用Chiplet会带来额外的封装复杂度和潜在成本增加，我们考虑过不同的方案，目前看来单芯片是更合适的选择。\n谈优势： 平台化加速量产，本土量产铺垫海外\nQ：芯驰的效率优势如何实现？\n孙鸣乐（CTO）：我觉得在SoC领域，我们的平台化做得非常好。在芯驰X9这个产品系列上，我们用一套核心的软件和硬件架构，覆盖了从10K DMIPS到100K DMIPS的性能范围，提供了六七个不同的产品型号，客户可以根据具体规格需求来选择。相比之下，有些厂商单个产品系列内通常没有这么大的性能跨度。\n在MCU领域，我觉得平台化和系列化是所有主流MCU厂商（包括国际大厂）通用的做法，这方面我们与大家类似。\n但是，芯驰的快速量产优势，除了平台化带来的兼容性和效率提升外，更多是来自于我们与客户进行的更深入、更早期的互动。我们会在芯片定义阶段，就与客户一起商讨和规划各项功能。在软件实现过程中，会与生态伙伴和客户共同进行方案的开发和验证。这样，当芯片样品出来的时候，我们就已经有了一个相对稳定和成熟的软件基线（baseline）。再配合我们完善的硬件参考设计，使得量产过程能够非常快。\n相比之下，一些国际大厂在国内市场，这种深度的早期合作可能做得比较少。他们可能在国外与其全球的核心客户有类似的配合，但那些客户的开发周期通常比较长。因此，相对而言，我们的整体开发和量产速度会快很多。\n陈蜀杰（副总裁）：平台化的设计，是当前车厂提高效率的一个主流趋势和选择。例如，当车厂车型不多时，可能一个车型就做一套独立的系统设计。但现在车厂车型非常多，他们通常会构建几个核心平台（比如高端平台、中端平台），基于这些平台通过差异化配置衍生出多种车型。一个平台可能对应十几个甚至更多的车型。\n因此，车厂在选择一个供应商作为其平台化开发的基础时，对其产品的质量、技术和可靠性要求非常高。芯驰能够被众多车厂选为平台化设计的基础，这本身就考验并证明了我们的技术能力和产品实力。\nQ： 我们看到车展前期芯驰发布了与博世的合作，采用了博世的CAN 技术，这是一种高传输速率、高可靠性的通信协议。我们想了解，芯驰采用了CAN 的MCU，大概会用在哪些汽车系统上面？或者说，芯驰是如何考虑MCU与这种高速传输技术的结合的？\n张曦桐（MCU产品线总经理）：我们与博世的合作，除了CAN XL，还包括集成了最新的GTM（通用定时器模块）4.1版本。这两项技术，我们都会率先在今天发布的E3620系列产品上应用。\n具体来说，我们今天发布的E3620P型号，主要针对的是像电驱和动力总成系统。这些系统未来也在走向融合，形成域控制器。以前可能是“三合一”电驱，或者一个单独的电机控制器，未来可能会发展成“八合一”甚至更多功能的动力域控制器。我们在E3620P上集成CAN XL和GTM 4.1，正是面向未来动力域的大融合趋势。\n当动力域融合了更多功能后（例如，有时会并入底盘的部分功能，或者VCU整车控制器等），系统内部就需要更高的通信速率。CAN XL技术正是为此而生，在车身、动力、底盘系统中都有应用潜力。而GTM 4.1则有助于提升电驱控制的精度和效率。\n因此，我们目前规划率先将这两项技术应用在E3620系列，特别是面向动力域的型号。后续会根据整个市场的需求情况，考虑是否在其他产品系列中也进行标配。不过，对于功能更复杂、集成度更高的域控制器，它们可能因为需要更高的带宽而直接采用百兆甚至千兆以太网。所以我们觉得，CAN XL技术在E3620P这类有规模化应用需求的平台上更有价值。\nQ：芯驰出海有什么样的竞争优势？\n孙鸣乐（CTO）：我们在海外市场仍然处于相对比较早期的拓展阶段。从优势的角度来看，我认为有几点：\n第一，我们依托于一个非常庞大且快速发展的中国市场。中国的整个汽车行业，尤其是在新能源、智能化（包括座舱、AI等）方面的发展速度，比许多国外市场要快很多。我们的很多新产品，首先在中国市场经过了大量车企的验证和应用，用过之后就变成了一个已经是量产成熟的产品。\n第二，对于海外的客户（车企）来说，当他们看到一款产品已经在中国市场（包括他们自己的在华合资品牌）被广泛使用并且证明是稳定可靠的，他们采用这款产品的风险就会小很多。海外企业通常对风险控制得比较严格，非常看重供应商产品的量产稳定性和质量记录。我们在中国市场的大量出货基础，以及快速发展的行业环境，使得我们的产品质量和整体解决方案（Total Solution）得到了充分验证。\n第三，当海外企业与我们沟通时，他们会发现我们的解决方案在技术上可能比他们现有供应链体系中的方案更领先（因为我们紧跟中国市场的快速迭代），同时又是一个经过验证的、稳定可靠的选择。这对于他们来说，可能比在其原有的供应链体系内从头开始开发一个新方案要更快、更有吸引力。\n另外，从全球化的角度讲，现在大家都希望在全球范围内寻找最好的解决方案。我们对自己当前解决方案的综合竞争力，包括技术领先性、成本效益以及整体方案的稳定性、可靠性等方面，还是比较有信心的。\n我们做出在德国、日本等地设立办公室的安排，也不是单纯的决策，而是在此之前已经与欧洲、日本的很多客户进行了非常深入的沟通，确认他们确实有这样的需求。\n- 上海车展见证历史：从「西为中用」到「中为西用」，行业风向标携手Momenta2025-05-01\n- 上海车展探馆：国产百万级越野限量发售，武汉造，太尊了！2025-04-29\n- 上海车展探馆：本田涨智慧靠中国，Momenta辅驾护航，DeepSeek赋能座舱2025-04-29\n- 蔚来李斌：一年减少了数十亿英伟达芯片采购2025-04-27'}, 'https://www.qbitai.com/2025/04/277848.html': {'title': '数学家们仍在追赶天才拉马努金', 'url': 'https://www.qbitai.com/2025/04/277848.html', 'date': '2025-04-27', 'content': '数学家们仍在追赶天才拉马努金\n解题靠做梦？\n如果有这么一个人，写下这样的复杂公式，并声称是受女神梦中启发所得，大家伙儿通常会送他两个字：民科。\n但当这个人一生中数千次写下类似的数学公式和命题，并在此后的100年间，不断地被证实正确，那么就只有一个可能——\n他是拉马努金。\n之所以再度火爆，是因为直到今天，数学界还不断有最新发现，在验证他当年留下的“谜题”。\n拉马努金，一位全数学界公认的神人，被认为是数学史上最伟大的天才之一：\n没有接受过正统数学教育，在印度挂科到本科学位都没拿到，却凭借自己惊人的数学直觉征服数学大师G.H.哈代，使得剑桥大学三一学院的大门破例向他打开。\n32岁就英年早逝，职业搞数学的时间只有短短6年，但他的数学笔记至今仍是传奇——留下了近4000个公式，很多都在后来被证明正确。\n他的恩师哈代甚至开玩笑说，自己对数学最大的贡献就是发现了拉马努金：\n和拉马努金的交往是我一生中唯一的浪漫事件。\n直到今天，后辈数学家们仍在追赶着拉马努金的步伐。\n就在2024年9月，弗吉尼亚大学的数学家小野肯（Ken Ono）和他的合作者们，还在PNAS（美国国家科学院院刊）上发表了一篇关于罗杰斯-拉马努金恒等式的应用论文，将其用于检测质数。\n“梦中女神的启示”\n拉马努金传奇故事的构成要素之一，是他独特的做数学的方式。\n简单来说就是三个字：凭直觉。\n毕竟以常规思维来评判，你很难理解一个20世纪10年代的数学家，是怎么写出那么多看上去只有计算机才能搞定的表达式的。\n他写给哈代的第一封信，就让哈代惊呼“我从未见过像这样的东西”，其中的数学结果长这样：\n而拉马努金自己也常常声称，他的直觉和灵感来自于女神托梦（他是一位婆罗门教徒），他在梦中得到灵感，醒来后就在笔记中记下这些表达式。\n在今天，拉马努金影响最深远的研究包括罗杰斯-拉马努金恒等式。\n这是与基本超几何级数和整数拆分相关的两个恒等式。\n第一个恒等式是：\n第二个恒等式是：\n后世的数学家们发现罗杰斯-拉马努金恒等式与其他数学领域，比如统计物理学和表示论，存在深切的关联。\n比如，在20世纪80年代，罗格斯大学数学家James Lepowsky和Robert Wilson利用顶点算子代数理论，为罗杰斯-拉马努金恒等式提供了一个新的表示论证明。\n顶点算子代数理论在弦论的发展过程中发挥了重要作用，也在群论最大成果之一——怪兽月光理论的证明中发挥了关键作用。\n拉马努金猜想，则是数论和模形式研究中的一个重要里程碑。现代数学研究中最大的单项项目朗兰兹纲领也和拉马努金猜想有着紧密的联系。\n拉马努金猜想通常是指关于模形式的τ函数系数大小的猜想。拉马努金提出，对于：\n其中，对于素数p，τ(p)的绝对值不会超过某一个数。\n简单来说，就是这个数列中的数字虽然会变大，但不会变得太快或太大。\n这个猜想在1973年由皮埃尔·德利涅（Pierre Deligne）证明。\n朗兰兹纲领的核心是函子性猜想，这一猜想描述了不同代数群的自守表示之间的深刻联系。函子性猜想包含很多著名的猜想，拉马努金猜想就是其中之一。\n自学成才的数学鬼才\n总而言之，这位受到女神眷顾的数学家，在今天的数学史上，已经成为一个绕不开的、金光熠熠的名字。\n但在他出生的1887年，他的父母可能怎么也没想到，他们这个没落的印度婆罗门家庭里，会成长出这样一位传奇的数学鬼才。\n拉马努金出生于印度泰米尔纳德邦埃罗德县，父亲是一位收入微薄的小职员，母亲则是家庭主妇。\n年幼的拉马努金很快展现出了自己的天赋，在小学里取得了优异的学业成绩，但直到他进入中学，他才算真正接触到了正规数学，那一年他10岁。\n在这样的环境中，实际上，从接触数学到发展出属于自己的数学研究，拉马努金最主要是靠自学。\n一开始，他是跟着家里的两个大学生租户学习数学知识，但在11岁时，两位大学生就没什么能再教他的了。于是，他们借给了拉马努金一本高等三角学的书，让他能够继续自学。\n13岁时，拉马努金啃透了这本书，甚至还自己发现了一些复杂的定理。\n在以全区最好成绩升入当地高中后，凭借个人直觉和逻辑思维，他独立推导了《纯粹及应用数学的基本成果概要》中的大量数学公式。\n具体来说，在仔细研究书中的5000个数学定理后，他发现了伯努利数，并里程碑式地将欧拉-马斯切罗尼常数计算到了小数点后15位。\n至高中毕业时，他被授予了K. Ranganatha Rao数学奖，校长还夸赞他的成绩远在满分之上。\n只可惜，拉马努金对数学的过度专注让他在大学时期遭遇了挫折。\n这一阶段的求学经历只能用“混乱”来形容，期间经历了换校、学位考试两度失败（数学只答自己感兴趣的，其他科目成绩不佳），最终肄业，没有拿到学位证。\n大学失败后，沮丧的他选择了离家出走，以至于母亲还在报上登了一份寻人启事。\n之后他一直陷于生活窘迫之中，不过仍未放弃独立数学研究。\n直到23岁那年，他认识了税务部门公务员V. Ramaswamy Aiyer，后者曾创立印度数学会，不过当时已结束数学会第一任秘书职务。\n命运的齿轮就此转动。\n一开始，无业游民拉马努金只想进入税务部门工作，于是向Aiyer展示了自己的数学笔记本。\n看完笔记后， Aiyer立即深感不能在税务底层部门埋没拉马努金的才华，于是写了一封介绍信将他推荐给了自己的数学家朋友们。\n这群人也非常看好他，层层举荐后，拉马努金来到了印度数学会秘书R. Ramachandra Rao面前。\n这位秘书对他的研究印象深刻，但鉴于拉马努金的知识背景，于是怀疑他作者身份的真实性。\n经过多方努力，最终拉马努金拿到了一次面谈机会：\n在这位秘书面前，他侃侃而谈椭圆积分、超几何级数和发散级数理论……\n而这，也最终征服了对方。当得知拉马努金迫切需要工作和财政支持后，这位秘书把他推荐到了一所大学担任研究员，并为他的研究提供经济资助。\n后来，拉马努金的研究成果发表在《印度数学会杂志》上。\n这中间还发生了一件有意思的事：\n当时他将一个无限嵌套根式的方程，以谜题的形式投稿给期刊，想看看能收到哪些回答。\n结果等了3个月，没有任何人理他。\n无奈之下，拉马努金只能自己上场，咔咔一顿操作后，最终在第一本笔记的第105页上，写下了解决无限嵌套根式方程的解决方案。（自己挖坑自己填第一人）\n总之在这一时期，拉马努金一边工作，一边业余搞数学研究，生活还算相对平稳。\n再到后来，为了将一些工作成果更广泛地传播，拉马努金开始给几位英国数学家写信：\n我是一名职员…… 我并未受过大学教育…… 但我正在为自己开辟一条新道路……\n信中还有几页数学推演，其中一些内容之前有人推导过，还有一些不完全正确。\n最先接到信的是HF Baker和EW Hobson这两位教授，在没有发表任何评论的情况下，他们直接退回了信件。\n不过这没有让拉马努金退缩，他继续将信投给了那个“命中注定般的人”——数学家哈代。\n虽然哈代初看这份手稿也以为是欺诈，但最后3个陌生公式吸引了他的注意力：\n我以前从未见过这些东西，它们完全打败了我。它们一定是真的，因为如果它们不是真的，就没有人有想象力来发明它们。\n震惊过后，哈代起了惜才之心，于是邀请拉马努金前往剑桥大学一同研究。（提供剑桥奖学金）\n于是从1914年开始，两人和哈代的另一同事李特尔伍德开始了长达5年的合作研究。\n仅就拉马努金和哈代来说，二人的合作并不容易：哈代追求严谨的证明，而拉马努金更相信直觉。\n不过期间二人还是发生了不少有趣的小故事：\n一次，拉马努金生病住院了。哈代为了帮他解闷，告诉他出租车的编号是1729，“一个看起来没什么意思的数字”。\n这可激起了拉马努金的反驳，“不，这是个非常有趣的数字。”\n他进一步解释，“在所有能用两种方式写成两个自然数立方和的数字中，它是最小的那个。”\n1729=1^3+12^3=9^3+10^3\n这个故事后来被用来定义“的士数”。（不是太懂这些数学家的乐趣doge）\n后来，拉马努金因在高度复合数方面的工作拿到了研究型文学学士学位（博士学位的前身），并当选伦敦数学会会员。\n31岁那年，他更是凭借“对椭圆函数及对数论的贡献”当选史上最年轻的英国皇家学会会员，还是该机构认可的第二位印度人。\n不过令人意外的是，刚刚取得巨大成就的拉马努金，却很快走向了故事终局。\n在因身体不适返回印度后。1920年，拉马努金32岁英年早逝。\n当时人们认为可能的死亡原因是结核病，直到1994年，后来有医生对拉马努金的医疗记录和症状进行了分析，得出的新结论是肝阿米巴病。\n理由是拉马努金离开印度前曾患过两次痢疾，而阿米巴痢疾可能会潜伏数年，并导致肝阿米巴病。\n后来的医生表示，如果当时能得到正确诊疗，这种病通常可以被治愈。\n这也让后人一直感到无比遗憾：\n而为了纪念他，人们也专门设立了“拉马努金奖”，每年由位于他的故乡贡伯戈讷姆的Shanmugha文理工研究院（SASTRA）所颁发，奖金为10000美元。\n获奖者需满足两个条件：\n- 在拉马努金研究领域做出杰出贡献的数学家\n- 获奖时年龄需在32岁以下（正好是拉马努金去世时候的年纪）\n该奖自2005年颁发以来，至今已有22位获得者，包括陶哲轩、詹姆斯·梅纳德等多位菲尔兹奖得主，以及张伟、恽之玮、刘一峰等等出身于北大数院的数学家们。\n△图源：Wikipedia\n数学家们仍在追赶拉马努金\n从1914年到1920年，实际上，拉马努金作为职业数学家仅工作了6年的时间，但就像前文提到过的，他的成果至今影响着数学界的后辈们。\n1976年，人们还在剑桥大学三一学院的图书馆中找到了拉马努金生命最后一年的“笔记本”。\n这个“笔记本”由138页散乱的纸张组成，上面记录了600多个数学公式，但没有证明的过程。其中包括拉马努金对模拟θ函数的研究——这个函数对计算黑洞的熵很有用。\n包含这本“遗失的笔记本”在内，拉马努金留下的手稿笔记中，总共3900余个公式和定理。\n尽管拉马努金本人并没有在笔记中留下明确的思路，但后辈数学家们依然认为，“他为重要理论的开端奠定了基础”。\n直到今天，数学家们仍在循着拉马努金的遗产，追赶着这位传奇人物的脚步。\n巴黎西岱大学的数学家侯赛因·莫尔塔达（Hussein Mourtada）就是其中之一。\n他从博士起就在研究奇点理论。他发现，能证明奇点深层基础结构的方法，就来自于拉马努金在一个世纪以前写下的数学陈述。\n简单来说，莫尔塔达在研究名为“胖点”的简单奇点的弧空间时，发现弧空间的结构可以用罗杰斯-拉马努金恒等式来描述。\n在此基础之上，他还和他的学生Pooneh Afsharijoo一起，探索了许多更复杂的奇点及其弧空间。Afsharijoo现在在马德里康普顿斯大学担任博士后研究员，他还发现了新的条件，扩大了拉马努金原始恒等式的范围。\n拉马努金故事片《知者无涯》（The Man Who Knew Infinity）的副制片和顾问、弗吉尼亚大学数学家小野肯，更是认为自己的职业生涯一定程度上得益于拉马努金的洞察。\n2014年，小野和Michael J. Griffin、S. Ole Warnaar联合发表论文，为罗杰斯-拉马努金恒等式及其算术性质提供了一个框架，解决了一个源自拉马努金工作的长期谜团。\n2024年9月，他和William Craig和Jan-Willem van Ittterum一起，采用整数拆分方法来检测素数——同样是基于拉马努金的工作。论文已发表在PNAS上。\nOMT：更多相关资料\n除了上面这些，如果你对拉马努金感兴趣，还有以下资料可作补充：\n从相关传记来看，英国电影《The Man Who Knew Infinity》（2015）专门讲述了拉马努金和哈代教授之间的友谊，以及他在学术领域的生涯。\n另外，他也出现在了两位印度数学家Narendra Kumar Govil和Bhu Dev Sharma的回忆录中。\n而对于那些难缠的数学公式，油管也有一系列详细推演。\n最后，还有网站收录了拉马努金所有已发表和未发表的论文。\n感兴趣就学起来吧！今日份劝学KPI达成（doge）~\n- 用多模态LLM超越YOLOv3！强化学习突破多模态感知极限｜开源2025-05-03\n- OpenAI最新技术报告：GPT-4o变谄媚的原因万万没想到2025-05-03\n- Qwen3真香！通义App满血接入，一手实测在此2025-04-30\n- 不到2年，AI PPT赛道第一！像素绽放CEO赵充：今年是AI应用创业最佳时期 | 中国AIGC产业峰会2025-04-27'}, 'https://www.qbitai.com/2025/04/277843.html': {'title': '7×24小时非人类科学家入场：当AI开始自主探索科学未知领域 | 多伦多大学', 'url': 'https://www.qbitai.com/2025/04/277843.html', 'date': '2025-04-27', 'content': '7×24小时非人类科学家入场：当AI开始自主探索科学未知领域 | 多伦多大学\nuniversea 投稿量子位 | 公众号 QbitAI\n自主通才科学家（AGS）正成为现实！\n来自多伦多大学、IIT、清华大学、浙江大学、罗格斯大学、哈佛大学、佐治亚理工学院和伦敦大学学院的跨学科团队的最新研究指出，融合人工智能与机器人技术的“自主通才科学家（AGS）”不仅能独立完成从文献综述到实验验证的全流程，更可能以指数级速度推动科学发现，突破人类能力的物理与认知边界。\n除此之外，其团队还构建了将AI大脑与机器人躯体深度融合的通用科研系统概念框架，展示了机器人与AI科学家在自然科学、形式科学、应用科学、人文科学，以及跨学科科学等全科学领域的原创性发现的潜力。\n超级智能的曙光：AI与机器人科学家引领科研新时代\n相比AI在工业生产或家庭生活中替代人类劳动，其在科学发现中的应用更能体现通用人工智能的真正价值——引领并超越人类水平的科研成果，或许正是衡量超级智能的关键标准。\n机器人与AI科学家正携手突破科学的边界，迎来一个全新的扩展定律（Scaling Laws），开启一个自主科学探索的新时代。\n一、当AI大脑邂逅机器人躯体：通才自主科学家的诞生\n自主通才科学家（AGS）正成为现实，这种系统将AI的智能与机器人的物理操作完美融合，能够独立完成从问题提出到实验验证的全过程。\nAGS的核心在于五大模块：\n文献综述，它能自主检索全球数据库；\n提案生成，设计创新实验方案；\n实验执行，跨越数字虚拟模拟与物理操作；\n论文准备，撰写严谨的研究报告；\n反思与反馈，通过自我优化提升能力。这种架构让AGS不仅能模仿人类科学家，还能超越人类的速度与广度。\n当前，AI科学家擅长推理、数据建模与分析；而机器人科学家则能执行物理任务。\n但二者单独存在时都有局限：AI缺乏动手能力，机器人缺乏场景泛化能力和灵活思维。\n从自然科学到社会科学，每个领域都需要虚拟分析和物理实验的结合，但比例各不相同。\n当前各种AI科学家和机器人科学家系统的能力仍然是单域的，专注于特定学科，仍有很大局限。\n而未来的融合Agentic AI 和具身智能机器人的AGS系统有望在各个方面实现全面突破，成为真正的通用科学家。\n二、科学发现的新扩展定律：突破物理与智慧的界限\n传统科研受限于人类的能力：全球科学家数量有限，每人每天专注时间不过数小时，且多局限于单一领域。相比之下，AI与机器人科学家可以几乎无限复制、永不疲倦，并跨越学科壁垒。\n这种能力催生了“知识飞轮”效应：每次发现都为下一次研究铺路，形成加速循环。\n比如，一个AGS系统在研究气候变化时，不仅能分析海量气象数据，还能设计新型碳捕集材料，每一步成果都推动后续突破。\n这种指数级增长将科学发现的速度推向新高度。\n更重要的是，AGS突破了双重边界。\n物理边界：机器人能在深海或火星表面开展实验，探测与研究各种极端环境，这些能力使科学研究可以拓展到之前无法涉足的领域；\n知识边界：AI整合多学科知识，可能催生全新领域，质与量的提升，实现人类难题突破的知识界限。工业革命解放了生产力，这场科研革命将解放人类的想象力。\n三、非人类科学家的研究成果管理：知识可控与规范化\n当AGS系统以惊人速度产出成果时，传统学术体系无法适应AGS时代的需求，难以消化海量论文。\n为此，科学家们提出了aiXiv平台——一个专为AI与机器人研究设计的预印本服务器。\naiXiv不仅加速发表，还革新评价体系。\n它摒弃了传统引用计数无法适应AI驱动成果规模的局限，而是结合AI与人类专家评估的多层评审机制，确保成果的质量与发表效率兼顾。\n无论是AI科学家还是机器人科学家，都可以在平台上发布研究提案和成果文章，供人类及非人类科学家评估和使用。\n经过平台验证的研究提案有机会被采纳并进行实验，而成果还可进一步提交至传统期刊接受严格评审。\n同时，平台支持成果持续更新，如同一个“活的知识库”，让科学发现不再是静态快照。\n伦理问题也在考虑之中：AI研究的署名归谁？责任如何划分？aiXiv通过透明机制，确保每项成果可追溯、可验证，为非人类科学家的时代铺平道路。\n四、超级人工智能的标准：科学研究的洞察力、创造性与系统性思维\n超级智能的关键标志之一，或许是机器智能可以进行原创性和突破性科学发现。\n论文提出了AGS能力分级，从0级（无AI）到5级（先驱者）。\n当前系统多处于1-2级，如辅助数据分析；少数达3级，能协作实验。真正的超级智能在5级：完全自主，超越人类。\n5级：先驱者： 能够在所有环境中完全独立运作，进行开创性研究而无需任何人类干预。\n它们不仅综合跨学科知识，还创新并制定全新的科学原理。它们的工作将带来前所未有的科学发现。\n科学发现为何是超级智能的标准？它需要洞察力、创造性和跨领域整合——智能的终极体现。\n然而，这也带来挑战：如何验证AI的发现？如果其理论超乎人类理解，我们如何信任？这些问题提示我们，超级智能的到来不仅是技术飞跃，更是哲学与伦理的考验。\n结语\nAI与机器人的融合正将科学推向新巅峰，不仅加速发现，更拓展了人类无法触及的领域——从微观粒子到宇宙奥秘。\nAGS不是人类的替代者，而是伙伴，AI的计算能力、记忆容量和跨领域整合能力，以及人类的创造性思维、直觉和道德判断，共同推动科学边界的扩展。\n这场革命已拉开帷幕。未来，当我们回顾今日，或许会发现，超级智能的AI与机器人科学家不仅改变了科学研究范式，更照亮了人类文明的新篇章。这是一个值得期待与参与的时代。\n你准备好迎接这场变革了吗？\nArxiv论文链接： https://arxiv.org/abs/2503.22444\nAwesome AI Scientist Papers仓库： https://github.com/openags/Awesome-AI-Scientist-Papers.git\n— 完 —\n版权所有，未经授权不得以任何形式转载及使用，违者必究。\n- GPT-4o医学知识覆盖率仅55%？腾讯优图团队发布大模型医疗能力“体检报告”2025-04-30\n- 告别“图文不符”！FG-CLIP实现细粒度跨模态对齐，360开源模型重塑AI视觉理解2025-04-28\n- 开源垂直领域高质量数据合成框架！专业QA自动生成，无需人工标注，来自上海AI Lab2025-04-27\n- 北大团队引领3D生成与对齐革新：OctGPT打破扩散模型垄断2025-04-25'}, 'https://www.qbitai.com/2025/04/278031.html': {'title': '全栈AI基础设施支撑，跑出全球首个开放使用视频生成DiT模型', 'url': 'https://www.qbitai.com/2025/04/278031.html', 'date': '2025-04-28', 'content': '全栈AI基础设施支撑，跑出全球首个开放使用视频生成DiT模型\n背后是商汤大装置在发力\n“连续4周千卡不间断训练、2个月完成模型迭代，先于Sora半年开放使用……”\n2024年初，Sora的惊艳亮相，将文生视频技术推向AI领域竞争的新高地。\n彼时，成立仅一年多的智象未来，凭借在生成式AI和多模态领域的技术积累迅速响应，仅用短短2个月时间便推出全球首个上线开放使用的图像和视频生成（DiT）架构模型，并迅速在vivago.ai上线向全球用户提供视频生成服务，把握了行业发展先机。\n作为智象未来的坚实后盾，商汤大装置为其提供了超稳定、超高效的AI基础设施支持，以极致的资源利用助力智象未来快速完成模型迭代冲刺，在新一轮竞争中巩固核心竞争力、开拓应用新场景。\n智象未来技术总监潘滢炜博士表示：“作为AI创业公司，我们深知快速响应行业变化的重要性。智象未来的模型迭代节奏快、训练强度大，对算力基础设施的响应速度、稳定性和服务能力都有着极高需求。商汤大装置‘灵活、稳定、专业’的支持能力，为我们实现模型的多元化场景应用、打通商业闭环提供了坚实基础，是我们值得信赖的长期合作伙伴。”\n训练节奏按月迭代，算力需求“既要也要”\n2023年3月，当行业还在惊叹于ChatGPT震撼的对话式体验时，刚刚成立的智象未来凭借在视频内容理解和生成领域的厚积薄发和敏锐洞察，前瞻地瞄准了图像和视频赛道的多模态技术方向，并在创立之初就制定了“1+3+N”的商业化布局策略，以1个大模型为基础，通过3条产品线形成市场触点，满足N种使用场景。\n早在2024年初Sora发布前，智象未来自研的智象大模型便已具备15秒的文生视频能力。在Sora发布之后，其迅速推出智象大模型2.0及3.0版本，将模型架构从U-Net升级至Diffusion Transformer (DiT)，不仅将视频生成时长提升至分钟级别，画面自然度、内容和角色一致性亦有显著提升。更重要的是，智象大模型2.0率先实现开放使用，成为全球首个开放使用的图像和视频生成（DiT）架构模型。目前，智象大模型已迭代至3.0版本，在架构和应用层面进一步突破。通过引入全新扩散自回归架构（DiT+AR），在提升生成质量的同时降低推理能耗。在应用层面，可广泛应用于运动镜头捕捉、影视特效制作、自然风光模拟以及物理世界的数字重现等多个领域，展现了人工智能在创意产业与视觉艺术中的巨大潜力与应用价值。\n不同于语言等单一模态模型，多模态模型的训练更加复杂。其不仅需要融合文本、图像、音频等多种模态信息，实现跨模态的深度理解与交互，而且训练任务更加多样。不仅如此，智象多模态大模型还几乎保持每月进行小版本迭代，每半年开展大版本升级的节奏，更对算力提出了“既要也要”的严苛要求：\n一是要高效：大模型训练，效率就是一切，每一次版本升级都是一场与时间的赛跑。尤其是面对智象大模型版本迭代时的扩容需求，需要迅速调度充足算力资源，支持模型迭代冲刺。\n二是要灵活：智象大模型具备图片生成、视频生成、图像和视频编辑等多种功能，不同模态信息的训练任务对算力需求各有不同，需要算力系统具备高度灵活性，能够随时根据训练任务的具体需要，匹配最优算力方案。\n三是要稳定：大模型的训练需要连贯且稳定的系统运行，任何一次系统中断都可能导致训练失败和资源浪费，因此算力系统必须具备7×24小时不间断运行的绝对稳定性，为模型迭代提供坚实后盾。\n灵活、稳定、专业，为模型迭代稳定护航\n作为“最懂大模型的AI基础设施”，商汤大装置以“灵活、稳定、专业”三板斧，通过灵活的算力资源调度，连续4周千卡不间断训练和专业高效的专家服务，助力智象未来实现了20%的资源利用率提升，让每一份算力都发挥到极致。\n灵活：千卡算力按需调度，实现最高投入产出比\n充足的算力储备、极速灵活的响应能力是商汤大装置的核心优势之一。在2024年初，商汤大装置运营算力规模已达到12,000 PetaFlops，目前更已提升至23,000 PetaFlops。\n为满足智象未来的模型迭代冲刺需求，商汤大装置不仅快速调度了千卡级别的算力资源，还提供了弹性的算力支持，可按需分配资源规模，通过灵活调度为智象未来提供最适配的算力方案。针对图片生成、视频生成、图像和视频编辑等不同训练任务，都能通过资源自主划分、灵活任务抢占机制，按照任务优先级灵活进行资源分配，保证最大资源利用率，实现更高投入产出比、更高经济性的基础。\n稳定：千卡4周不间断，99.99%可靠性稳定护航\n在基于千卡集群的模型训练任务中，计算卡故障、通信异常等潜在问题如同暗礁，随时可能会导致训练中断等稳定性问题，影响训练进度。如果说算力是大模型训练的核心“生产力”，那么稳定性则代表着“安全感”。有安全感的生产力，才能真正提升生产效率。\n从全程动态监控到多项保障机制，商汤大装置以99.99%的可靠稳定性，做到算力“零闲置”。在模型训练过程中，可实时监控设备状态，精准定位故障节点，并在第一时间发出告警；通过故障节点自动剔除机制，能够迅速将问题节点隔离，减少训练中断风险；通过空闲节点无缝接入机制，让训练任务能够从断点处迅速续训，避免时间浪费。\n得益于动态监控、异常检测等多种手段，商汤大装置以分钟级的训练容错能力，助力智象未来成功实现了连续4周千卡不间断训练的超稳表现，为模型迭代稳定护航。\n专业：全链条专家服务支持，全程守护满满安全感\n凭借在模型训练、AI Infra、模型量化推理等方面积累的深厚经验与专业知识，商汤专家服务团队以敏捷、专业的支持能力，协助智象未来高效精准地完成问题定位和溯源，高效完成各类故障排查，并助力优化训练流程、提升资源利用率。\n全链路文生视频解决方案，打通从数据到价值“最后一公里”\n商汤大装置解决方案专家孟凡笑认为：随着文生视频模型研发和应用需求不断涌现，行业所需的将不仅仅是高效、稳定的算力支持，而是从数据处理、到模型训练，再到推理部署的全链路解决方案。\n基于对文生视频模型研发与应用需求的深刻理解，商汤大装置已形成涵盖底层算力服务、IaaS服务以及文生视频数据处理平台的全链路文生视频解决方案，以端到端的AI Infra能力打通从数据到价值的“最后一公里”。\n在数据层面，可提供定制化的数据评估、视频编码、视频超分等数据服务，助力客户应对高质量数据缺乏、数据处理难、存储空间大等难题。同时提供私有化部署和公有云服务两种灵活的服务模式，可满足不同客户需求。\n在训练层面，可提供超大规模算力资源，并能根据任务需求进行灵活调度，且支持多芯混训、资源提效、性能优化，实现极致的算力资源利用和模型训练效果提升。同时，还通过智能异常检测、分钟级自动容错等多种手段组合，为模型训练提供极致稳定性保障。\n在推理层面，可提供从负载均衡调度、弹性扩缩容到服务优化、模型压缩、算法优化的全方位、分层推理优化方案，实现高吞吐、低时延的推理性能，有效满足文生视频场景对推理的实时性要求。\n同时，作为全栈式解决方案的坚实后盾，商汤大装置的全链条AI专家服务以全流程技术支撑和行业深度适配为核心，全面覆盖业务场景洞察和定义、数据处理与构造、大模型评测与能力选型、模型微调、模型蒸馏，再到模型部署与维护等AI模型开发和应用全生命周期环节，助力企业高效实现 AI 应用落地，在智能化转型之路上稳步迈进。\n深化合作、共探场景升级，推动文生视频持续爆发\n得益于模型的快速迭代，智象未来的商业化进程迅猛发展，成立短短两年以来，已累计服务100多个国家和地区的1000多万用户和4万多家企业，智象大模型已广泛应用于影视、文旅、通信、营销、教育等场景。\n未来，商汤大装置与智象未来还将进行更深层次、更多维度的合作。除了算力层面，双方还将针对视频筛选、视频编码、视频超分等数据处理，以及模型推理优化等方面展开交流与合作探讨，打造更优质、更高效、更易用的文生视频服务，满足各行业客户日益增长的多样化需求。\n- 14.9万元，满血流畅运行DeepSeek一体机抱回家！清华90后初创出品2025-04-29\n- 全球第一车企，集齐中美双版Waymo2025-04-30\n- 亚马逊云计算Troy Cui：敦煌网飙升AppStore第二，企业如何应对激增流量是关键 | 中国AIGC产业峰会2025-04-27\n- 智能车速度刷新：仅10个月，首个纯端侧大模型上车量产！2025-04-24'}, 'https://www.qbitai.com/2025/04/277968.html': {'title': '蔚来李斌：一年减少了数十亿英伟达芯片采购', 'url': 'https://www.qbitai.com/2025/04/277968.html', 'date': '2025-04-27', 'content': '蔚来李斌：一年减少了数十亿英伟达芯片采购\n李斌笃定Q4盈利，蔚来想办法省钱\n一凡 发自 上海\n智能车参考 | 公众号 AI4Auto\n“我们对四季度盈利很有信心”。\n“我对中国汽车最终占全球40%市场份额很有信心”。\n“智能汽车新三大件是：智驾芯片，整车全域OS和智能底盘”。\n这是蔚来三大品牌首次齐聚上海车展，李斌接受采访时的最新分享。\n其中，蔚来和萤火虫共用一个展台，紧邻宝马和MINI。乐道则隔层相望，单独设立展台，悄悄地派发起冰棍，倒不是为了致敬某事件，单纯为了秀一下L60的超大冰柜…吧。\n乐道最新车型L90也迎来首秀，秀了一波超大前备箱，近看起来确实夸张:\n李斌甚至都能坐进去钓鱼了:\n接受群访的李斌似乎也表现出“稳坐钓鱼台”，灵魂拷问超充，再次强调蔚来做辅助驾驶的优先级是减少事故，还谈到了当下的关税风暴和蔚来整体规划：\n今年是蔚来的技术大年，产品大年，基建大年，我们笃定四季度盈利，会坚决做到。\n以下为采访对话实录，经编辑，文章较长，阅读指引如下：\n1.谈辅助驾驶：优先减少事故，严谨宣传口径是好事\n2.谈补能：换电和超充不对立，增程意义越来越小\n3.谈新品：自研芯片上“5566”，产品大年提毛利\n4.谈技术创新：自研有助于降本，一年少花几十亿买英伟达\n5.谈“蔚乐萤”：共用展台为省钱，蔚来不相信大招\n6.谈出海：趋势向好，但过程肯定是曲折的\n7.萤火虫专题：蔚来富养“三胎”，兼顾中欧需求\n谈辅助驾驶：优先减少事故，严谨宣传口径是好事\nQ：蔚来在L3上有什么规划？\n李斌：最近可以看到，监管机构要求严谨辅助驾驶和自动驾驶的宣传口径。我认为这是好事。\n不然大家都是各自表述，搞不清楚基线到底在哪里，我们蔚来也是新势力第一批做L3试点的。每个企业的宣传有自己的标准，比如ET9有七重冗余，有很多号称L4能力的车都做不到，但我们没有说ET9已经是L4了。\nQ：蔚来智能辅助驾驶的优势是什么，接下来的大版本会给用户带来什么体验？\n李斌：蔚来智能辅助驾驶最重要的指标，是减少事故的能力。去年整个行业都在做端到端，我们也在做，但是我们首先用端到端做主动安全。据不完全统计，现在AES(自动紧急避让)每周就可以替用户至少降低了几百次可能碰撞的风险，当然不是说完全杜绝，而是降低了事故概率。\n有四个保险公司已经给我们做了认证，降低了25.4%的事故概率。\nQ：目前行业在推广智能辅助驾驶时，有哪些问题需要解决？\n李斌：汽车事关到人的生命安全，所以我相信所有的车企，最终都会把安全放在一个非常高的位置上。我认为智能辅助驾驶的技术是能够提升安全能力的上限，包括主动安全和智慧安全，我们会把这个放在高优先级。然后再去看可用性，智能辅助驾驶肯定也会越来越理性的。\n谈补能：换电和超充不对立，增程意义越来越小\nQ：近期比亚迪和宁德时代先后发布兆瓦超充，现在充电速度越来越快，如何看待充电跟换电的关系？\n蔚来联合创始人、总裁 秦力洪：搬运一下沈斐博士（原蔚来换电负责人，现乐道品牌负责人）的答案：\n不要管他怎么说，过几年看他建不建再来评价。\n我们已经有三千多座换电站，给用户换了七千多万次电，在我们了解的范围之内，布局广泛的换电网络是最好的能源解决方案。\n李斌：不要被带入别人的节奏，我是这么看的：\n第一，充电和换电不对立。\n蔚来也有750kW液冷超快充站，26000根充电桩，我们是布充电桩最努力的公司。\n先来个灵魂拷问：谁建的充电桩比我们多了？\n第二，再快的超充不可能比换电快，而且换电不需要下车，不怕刮风下雨天气冷。\n**第三，超快充可以不可以经常用？超快充可不可以做10年甚至15年的质保？如果能，我服。我这是技术流派的回复，沈斐那个被带节奏了。\nQ：有ET9车主提车以后说，他的电池在换电站是专用的，好多换电站没有这个电池，为什么会有这个问题，如何解决？\n李斌：因为ET9用的是900V、100度的电池包，一开始来不及上，有一些换电站电池库存周转不过来，现在已经基本解决了。\nQ：换电联盟有什么进展？\n李斌：换电联盟的一些公司在基于乐道标准包的开发换电车型，从开发车辆到最后量产是需要时间的。\nQ：去年不是说有车型在冬测吗？\n李斌：有的公司会做两年的冬测，这个对我们来说不是重点，重点是他们有在开发就可以了。\nQ：蔚来今年换电有什么规划？\n李斌：第三个就是基建大年，4月底会在广东实现“换电县县通”，我准备做一天直播，验收一下。广州的用户，珠三角的用户畅行广东，真的是加电无忧，里程无忧。\n我们今年会在27个省级行政区实现“换电县县通”，任务非常艰巨。技术大年，产品大年，基建大年，再加上管理坚决地去降本提效，提高整个公司的运营效率，所以我们对蔚来今年四季度盈利非常有信心的，很笃定。\nQ：如何看待当前增程车型增长放缓？\n李斌：我从增程在中国畅销里学到了很多东西，比如说在过去充换电不便捷时，可油可电确实是一个非常大的卖点。它可以解决不少用户里程和充电焦虑的问题。\n所以之前我回答有什么后悔的事情，其中有一个是如果时光倒流，我应该在2020年那两年更积极布换电站。\n蔚来在长三角有一半用户，有1/3的换电站，会出现这种情况，很重要的原因是换电在那里已经形成了一个网络，充电和换电没有那么焦虑了。\n今天充换电比以前方便很多了。我去年去新疆喀什，那边充电条件都很好了，纯电用户晚上在酒店一天充一次电就行。\n增程用户反而一天要充两三次电，因为新疆太大，从乌鲁木齐开到喀什用油要1600块钱。增程用户为了省钱选择多用电。\n所以原来充换电基础设施不那么好，我认为选增程插混是有很大合理性的。但是今天充电桩和换电站越来越多了，用户可以根据自己的需求，更开放来看选择什么车。\n我们还可以看到一个趋势，现在增程的电池越来越大，所以增程的意义不是越来越小了嘛。\n我们做换电可能是超前了一些，但是今天如果往前看和往将来看，投入的收获期总会到来，也会赢得越来越多用户的认可。\n谈新品：自研芯片上“5566”，产品大年提毛利\nQ：剧透一下新款“5566”（蔚来ET5、ET5T、ES6和EC6）？\n李斌：像ET9搭载的神玑NX9031的芯片会上车2最新款的5566，Sky · OS也会同步复用上车。\nQ：接着上一个问题，今年新品都会用自研芯片，那底层变动会不会引起上层架构变动，如何跟之前NT2.0和1.0平台兼容？\n李斌：肯定是有很多功能可以复用的，特别是数据这一层。NT2.0平台用的就是800万像素的智驾摄像头了，所以很多数据的复用度是非常高的。我们NT3.0的智能辅助驾驶功能比NT2.0上车的时间要短很多，基本几个月就能做完所有事情。\nQ:理想和小鹏都做了MPV，蔚来考不考虑造呢？\n李斌：他们都造了也不缺我一个。我这几年估计最不听劝的就是没有造MPV，每次见到用户压力都非常大，说“斌哥感觉不听劝”，说了多少年都没有造。\n其实MPV总体市场并没有那么大的增长，相对来说，像L90和第三代ES8这种大型SUV的优先级肯定更高，并不是MPV不重要，也不是MPV商业上没有可能性，主要还是资源优先级的问题。\nQ：今年蔚来产品上有什么规划？\n李斌：今年也是蔚来产品的大年，一共有九款全新车型上市，每个季度都有重磅的新车。ET9是第一款，4月底Firefly萤火虫就交付了。后续二季度还有2025款的ET5T，ES6和EC6，然后是全新的ES8还有乐道的L90，L80。\n去年蔚来只有一款新车，今年我们有九款新车，产品大年肯定可以提升销量，增加毛利率。\n谈技术创新：自研有助于降本，一年少花几十亿买英伟达\nQ：新的三大件是否会提高用车成本，如何平衡技术升级和车价？\n李斌：智能汽车新三大件智驾芯片，智能底盘和整车全域操作系统会降低用车成本。比如我们的芯片，一颗抵四颗，省不少钱，所以技术创新能够降本，这其实挺重要的，我们当然可能会选择有一部分给到用户，但是我们毛利率也需要提升。\nQ：蔚来在配置和功能上如何取舍，尤其是今年要降本增效实现盈利的节点上，之后如何构建差异化能力？\n李斌：智能汽车三大件可以帮助我们降本增效。比如说我们自研的芯片，过去几年投入很高的研发费用。但是今年它可以帮我们省很多成本。\n因为去年光买英伟达的Orin芯片就花了几十亿人民币，今年性能上一颗抵四颗，毛利率都是蔚来自己的，可以帮助我们降本的，包括我们的操作系统，原来用第三方操作系统也是要付钱。今年因为技术降本，毛利率肯定有更好的表现。\n所以为什么要投资研发，前期要投很多钱，一旦量产就进入到一个收获期，一方面提高用户体验上限和安全上限，另外一方面研发能够降本。\nQ：Sky·OS天枢系统对蔚来用户、蔚来和中国汽车产业，有什么深刻的意义呢？\n李斌：现在看得见的创新，应用级的创新，大家很容易同质化。车展里面很多车都已经有冰箱彩电大沙发了，乐道L60还有52升的超大冰柜。\n看不见的核心技术的创新，投入周期长，用户感知也没有那么强，但是它是智能汽车的一个底座，就像我们盖楼打地基。\n新三大件虽然用户一下子没有办法直接感知到，但是它们决定了体验的上限和安全的上限。\n比如ET9的天行之舞，实际上就是因为整车全域操作系统Sky·OS天枢加上智能底盘能力，把集成式的液压全主动悬架能力组合到一起，可以让非常大的ET9变得非常的灵动。\n再比如说L60的超低的电耗，其实也都是得益于整车全域操作系统。我认为中国汽车产业如果还有哪个地方跟全球最领先的公司有一些差距，就是这些底层核心技术。\n今天通过ET9和L90让大家看到了这些底层的核心技术，能够转换成用户的体验。\n还有就是安全上限，我们并不能杜绝所有事故，但是有一个基本的逻辑，传感器能力越强，能够处理的数据越多，从感知到决策控制的延时就越短，它的安全上限肯定就越高。\n我自己去测了150km/h的高速爆胎，安全机制背后反映的是包括Sky·OS带来能力的提升。\n今天讲智能汽车，希望大家更加关注核心的底层技术，不像冰箱彩电大沙发，内饰氛围灯这些，一下子可以看到。\n谈“蔚乐萤”：共用展台为省钱，蔚来不相信大招\nQ：乐道的组织架构最近有什么调整？\n秦力洪：乐道确实最近调整了管理团队的调整，乐道现在没有定具体的销量目标，定的目标就是每一周比上一周要好，一步一步走一段，让销售趋势可预见性变得更好，再谈一个具体的目标问题。\nQ：蔚来三大品牌展现了什么趋势？\n李斌：今年上海车展也是首次三个品牌集体亮相，乐道品牌第一次参加上海车展，萤火虫品牌第一次参加车展，蔚乐萤组合算是集齐了。\n车展两个展台这么多车，展示的到底是什么东西？有一个共同的词其实是技术。不管是L90还是萤火虫，或者技术旗舰ET9，像L90这样的技术创新成就非凡的空间，萤火虫作为高端小车安全各个方面有极致的体验，其实背后的底层能力都是蔚来过去十年持续坚决地投入底层技术创新，今天开始进入到了收获的阶段。\n所以我想技术创新其实一直是蔚来的底色，也是每一款车的本色。\n今天讲到了智能汽车新三大件，智驾芯片、全域操作系统、智能底座。新三大件决定了智能汽车体验的上限和安全的上限，只能通过像飞跃天际线还有天行车舞展示给大家，大家可以在很小的点上看到核心的技术。\nQ：蔚来三大品牌的资源共享和降本有什么可以透露的吗？\n李斌：我跟力洪都被共享出来了（笑），原来整个乐道也是直接向我汇报的，现在我更深度参与到乐道的研发和供应链业务当中。\n力洪跟沈斐一起管蔚来的销售服务体系。所以已经是集公司优势资源去协同提高乐道的产品和服务。\n其实这些共享以前也有，比如说换电站，我们现在乐道有接近两千多座换电站可以用，蔚来其实才3200多座，其实已经相当于60%左右已经都是共享给这个乐道的这个用户了。服务体系第一天开始就是共享的，我们区域一些团队，我们开始加强共享了。\n萤火虫和蔚来的共享还是比较彻底的，我们现在有332家蔚来门店能够去展示和试驾萤火虫。所以萤火虫上市以后能够很快遍布全国。\n研发方面也有很多底层的共享，比如L90的后驱电机，其实和ET9共享。\nQ：为什么萤火虫和蔚来共用展台，但乐道是单独的？\n秦力洪：我们本来是三个展台，后来为了省钱，我们把蔚来和萤火虫放在一起了。\n李斌：效果挺好，我几个朋友说萤火虫放这里感觉相得益彰。\n秦力洪：乐道跟蔚来之间的关系类似于大众集团的大众和奥迪，或者丰田集团的丰田和雷克萨斯，乐道跟蔚来品牌定位不一样，所以用户端有区隔。不过展台运用的团队是同一个。\n李斌：欢迎三个品牌的用户来展台二楼的休息区，都可以来。\nQ：乐道后续有什么大招，应对竞品比如Model Y的压力？\n李斌：我觉得汽车行业靠什么大招，一招致胜不太现实。从（我进入）汽车行业到现在做了15年，看到很多公司真的是十年如一日，持续投入坚持做对的事情，没有一个公司靠大招突然怎么样了。\n乐道的交付数据距离我们的期待有一些差距，但我想强调在20万-30万价格区间里，我们在号称围攻Model Y各路豪杰中算中等偏上的水平。至少前2-3名。\n作为一个新品牌，有这样的成绩基础，给我们一个很大信心。现在乐道用户满意度非常高，转介绍率也非常高。不管是对技术、产品、空间、安全、电耗、换电便利性各个方面。\nL90这个招够大吗？我认为非常大，真实切中三排大SUV的用户痛点。比如以前去超市购物挪半天车，把车放那里开出来再打开后备箱，总之很尬。\n品牌需要慢慢积累用户口碑，去赢得用户。所以乐道做的事情很简单，把基本功做好，让更多人了解到我们的车，为什么让沈斐负责乐道，沈斐就是一个下笨功夫的人，过去换电站一座一座建，充电桩一座一座装，装了3000多座，不容易，就是基本功，全都是大招，没有小招。\n谈蔚来出海：趋势向好，但过程肯定是曲折的\nQ：如何看待欧洲关税？\n李斌：欧洲关税的变化，现在（2024.4.23）还没有确定的消息，我们当然希望中国和欧盟能在汽车关税上达成双赢合作，中国汽车市场也是一直对欧洲对全球开放的，我们认为好的产品应该让全世界用户都可以体验，可以使用，希望他们可以早一点找到解决方案。\nQ：欧美关税会对出海带来什么影响？\n李斌：中国已经成为全球最大的（汽车）生产国，年产能超三千万辆，也是最大的汽车出口国。\n现在因为关税带来一些影响是非常正常的，不会一帆风顺，中国在全球的汽车市场里面，一定会获得越来越高的份额，核心是三个因素：\n技术创新，供应链的优势，最大的本土市场。\n中国汽车的产品技术有竞争力，那最后不管是全球哪个用户，他只会为好的产品，好的服务买单，趋势是这样，但过程肯定是曲折的，我们也交了很多学费。蔚来也因此有所改变，我们从最早完全自营，转变为依托于当地合作伙伴去拓展销售和服务网络。\n所以这次车展有很多合作伙伴来到了现场，我们也在向奇瑞，比亚迪，长城这样的公司（学习）。\n其他\nQ：今年上海车展有哪些趋势，哪些变化呢？\n李斌：现在上海车展确实是全球最大的车展，我相信也是技术含量最高的车展。大家都在展示最新的技术，如何用技术增强产品的竞争力，更能符合用户需求。\nQ：蔚来最近价格调整后销量非常高，但是有说法说销量高可能亏得多，是这样吗？\n李斌：最近促销清库存，五年免费换电，确实很多用户觉得特别好用，政策比原来更简单直接一些，用户反响不错，在财务边界范围内是可以承受的，这一波清库公司还是有钱赚的。\nQ：前一阵子去北京五棵松牛屋，感觉蔚来牛屋维护老客户挺好，发展新客户似乎不太够，是这样吗？\n秦力洪：五棵松牛屋客流量数据还比较正常，在各地牛屋中排名靠前，销售端客流量波动性比较大，跟地段有关系。\n蔚来更加看重用户区域能否充分利用。因为对蔚来的牛屋来说，用户区域的装修维护成本非常高，如果大家用的多，我觉得就值回本钱了。\n萤火虫专题：蔚来富养“三胎”，兼顾中欧需求\nQ：后续会不会开发性能版萤火虫，适合驾驶爱好者的那种？\n李斌：我们知道用户对小车有一些需求，确实后续会有一些特别的版本，但肯定不是完全以性能为取向的。电器输出功率会有一些特别版本，增加可玩性。\nQ：萤火虫的换电接入宁德时代的巧克力换电，第一代车主是否会有一些牺牲？\n李斌：当时说的是后续车型会适时接入，我们自己的第五代站也会兼容萤火虫。\nQ：萤火虫出海，首批为什么选择荷兰、挪威和新加坡？\n蔚来副总裁、萤火虫品牌总裁 金舸：其实萤火虫下半年会进入 16 个国家，为什么是这些国家，而且有先后顺序，主要基于2点：\n第一个其实是政策友好度，当地关税特别低或者当地有比较好的补贴政策。\n第二个就是市场相对成熟，比如说比利时和卢森堡，这些地方的（新能源）渗透率远超欧盟平均水平。\nQ：萤火虫和海外市场的主流小车相比竞争力怎么样？\n金舸：萤火虫是有代际领先优势的。萤火虫有全球最高的安全标准和领先的智能化技术赋能，又兼具一定驾驶性能，这个定位在（欧洲）市场上没有的。\nQ：如何兼顾不同国家地区，从用户的需求去做到平衡？\n金舸：早期萤火虫团队跑遍全球17个国家，40多个城市，确实全球各地小车需求不一样：\n欧洲是操控，中国追求空间和舒适，东南亚希望成本比较低……\n那我们怎么做？首先瞄住自己高端小车的定位，拉出一个基线：\n第一是用中欧双五星的最新标准来作为硬件基线。\n第二，全球一根软件基线，用的是现在蔚来比较新的技术，确保数字化技术、智能座舱、辅助驾驶它的功能基线比较高的。这两个都是全球一个标准。\n其他方面，比如说底盘调校这是两套标准，因为欧洲跟中国对舒适性的需求不一样。\n还有地方不能做两套，做了适当平衡，比如说后排空间跟后备箱，欧洲要后备箱，中国是要第二排，我通过工程上的巧思，比如座椅的机械架构和底盘架构，兼顾中欧的需求。\nQ：蔚来对萤火虫是“富养”吗？\n金舸：是的，就像家里面最小的孩子会得到额外照顾，萤火虫集成了蔚来10年的研发工艺，站在巨人的肩膀上。比如说软件能力，智能座舱其中85%的代码和蔚来是完全一样的，只改了15%的代码，包括上层应用层和UI交互。\n数据中台和云是完全打通的，几乎没有额外投入，再比如说我们的营销体系直接放在蔚来展厅以外。\n车展萤火虫就放在蔚来展台正中心的位置，也是把最好的资源给到了萤火虫，而且放进去没有任何违和感。\nQ：有没有考虑打造你个人的IP？\n金舸：我是个I人（内向），我会密切关注在媒体当中收到的声音和反馈，所以现在呈现出的都是我本人真实状态。\nQ：为什么萤火虫没有NOMI（蔚来品牌语音助手），是不想要还是蔚来不想给？\n金舸：是我们自己没有选择NOMI。我们认为NOMI是跟蔚来品牌强绑定的，有极强的品牌特色。乐道也不叫NOMI，叫小乐。\n还有几个原因，第一个是每个车有自己的车格，每个品牌有自己的品牌特性，可以看到萤火虫的语音助手LUMO形态百变，有时候是圆，或者爱心，或是一朵花。它是根据当下氛围决定的，这个设计也符合萤火虫的DNA巧思。\n为什么叫LUMO，第一个原因是萤火虫品牌理念“自在发光”，而发光的拉丁语词根就是LUMO。\n第二个原因是我们团队讨论的时候，哈利波特里面有一个荧光魔法叫LUMO，我们就注册下来了，我们后续也会增加自定义唤醒词，这样叫NOMI也不是不行。\nQ：萤火虫的销售体系是怎样的？\n蔚来助理副总裁 、萤火虫品牌营销负责人 浦洋：销售在国内国外有两套团队，在中国由蔚来销售团队负责所有销售，现在为止已经有超过400个门店、400多台试驾车的服务，总体来说已经覆盖绝大多数用户群体。\n海外团队基本上一国一策，有一些国家直营体系不错，我们就会优先考虑直营。\nQ：萤火虫是否会在海外布局换电？换电网络有什么规划？\n金舸：萤火虫在国内会并入五代站，但在海外建换电站的时间成本还有投入是中国的很多倍，比如说去申请基建需求，中国可能一个月搞定了，海外很长，可能要一年时间，所以海外布局换电的代价很高，我们铺换电站会相对比较克制。\n然后萤火虫主要在城区内用，从补能角度看换电可以成为补充补能，而不需要成为主导补能模式。\n目前海外的换电站布局也是一国一策，不同国家策略不一样，有的国家都是一家总代理商负责，他们非常愿意引用萤火虫的换电站，我们会帮助他们在当地构建换电能力，一些国家没有太强的能力和意愿去布非常广泛的换电站，我们也接受。\nQ：萤火虫坚持对标宝马MINI，不过MINI分中低版本，萤火虫也会分吗？\n金舸：高端小车的市场没有被打开，我们坚持对标MINI，意思是一起把蛋糕做大。之所以选择对标MINI，是因为这种类比可以让用户get到你的定位，MINI产品线比较丰富，但也不是一开始就这也。\n我们会先把第一款车做好，把基盘做的足够大，然后做更多衍生车型。向上延伸或者向下延伸，都是存在机会的。\nQ：现在没有换电站，怎么说服大家用BaaS（电池租用服务）方式去买萤火虫？\n金舸：萤火虫现在就可以换电，不是换电版车型8月1日才出，只是政策做了时间区隔。\nQ：萤火虫会有更大的电池包吗？\n金舸：电池包在设计之初可以兼容两种电芯，现在出了一个420公里的标准续航版本，未来可能会再做一个大电池版。我们先看上市的表现，再看大家的呼声，同时也还会考虑和其他车型的一些共用，来决定上还是不上，什么时候上。\nQ：萤火虫国内订单符合预期吗？\n金舸：符合预期，门店现在每天萤火虫试驾从早上九点排到晚上十点，基本是爆满的状态。区域已经说想再增加试驾车，现在资源还在进行调配。\nQ：萤火虫海外如何做品牌建设？\n金舸：海外的品牌建设确实是一个绕不过去的坎儿，像mini、smart在海外的认知也不是一朝一夕建立的，蔚来从2021年进挪威到现在已经4年了，品牌认知度跟当地还是有差距的，萤火虫更是这样。\n也正是如此，我们在海外布局渠道策略很灵活，不会完全坚持自营模式，会依靠总代或者经销商。\n在海外特别是成熟的西欧国家，一个4S店、一个经销商有当地非常深厚的关系，通过他们的网络可以很快构建品牌认知，我也说过萤火虫在海外销量上限比较高，但是过程长。中国相对来说上限不会有海外高，但是会很快上去。\nQ：萤火虫出海会做增程吗？\n金舸：不会。\n- 上海车展见证历史：从「西为中用」到「中为西用」，行业风向标携手Momenta2025-05-01\n- 上海车展探馆：国产百万级越野限量发售，武汉造，太尊了！2025-04-29\n- 上海车展探馆：本田涨智慧靠中国，Momenta辅驾护航，DeepSeek赋能座舱2025-04-29\n- 上海车展对话：高阶辅驾普及改变座舱需求，7B成模型上云分水岭2025-04-29'}}